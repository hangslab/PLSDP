{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "import math\n",
    "from itertools import product\n",
    "import argparse\n",
    "import sys\n",
    "from utils_cnn_CS import *\n",
    "import calendar\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "damaged-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eachseq(seq,pssmfile,mask_seq,new_pssms):\n",
    "    if os.path.exists(pssmfile):  #如果pssm文件存在\n",
    "        print(\"found \" + pssmfile + \"\\n\")  #输出找到pssm文件+换行\n",
    "        pssm = readPSSM(pssmfile)  #读取pssm文件\n",
    "    else:  #否则\n",
    "        print(\"using Blosum62\\n\")  #输出使用Blosum62+换行\n",
    "        pssm = convertSampleToBlosum62(seq)  #把Blosum62矩阵当作pssm用\n",
    "    pssm = pssm.astype(float)  #对pssm的数据类型转换为浮点型\n",
    "    PhyChem = convertSampleToPhysicsVector_pca(seq)  #将样本转化为物理向量\n",
    "    pssm = np.concatenate((PhyChem, pssm), axis=1)  #物化指标和pssm对应行进行数组拼接\n",
    "    seql = len(seq)   #序列长度  \n",
    "    if seql <= 1000:  #如果序列长度小于等于1000\n",
    "        padnum = 1000 - seql  #pad大小为1000-序列长度\n",
    "        padmatrix = np.zeros([padnum, 25])  #pad矩阵为行数为padnum，列数为25的全0矩阵，即用0填充不足的地方\n",
    "        pssm = np.concatenate((pssm, padmatrix), axis=0)  #物化指标和pssm进行数组拼接 \n",
    "        new_pssms.append(pssm)  #新的pssm空列表中添加pssm矩阵\n",
    "        mask_seq.append(gen_mask_mat(seql, padnum))  #mask序列空列表添加gen_mask矩阵，序列长度为行数，padnum为列数？？？\n",
    "    else:  #如果序列长度大于1000\n",
    "        pssm = np.concatenate((pssm[0:500, :], pssm[seql - 500:seql, :]), axis=0)  #pssm矩阵为前500行和后500行矩阵的拼接\n",
    "        new_pssms.append(pssm)  #新的pssm空列表中添加pssm矩阵\n",
    "        mask_seq.append(gen_mask_mat(1000, 0))  #mask序列空列表添加1000行0列的？？？gen_mask矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metric-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpad(seqfile, labelfile, pssmdir=\"\", npzfile = \"\"): #定义endpad(序列文件，标签文件，pssm路径，npz文件)\n",
    "    if not os.path.exists(npzfile):  #如果npz文件不存在，建立新的pssm空列表，标签空列表，mask序列空列表，id空列表\n",
    "        new_pssms = []\n",
    "        labels = []\n",
    "        mask_seq = []\n",
    "        ids=[]\n",
    "        seqs=[]\n",
    "        f = open(seqfile, \"r\")  #f为打开序列文件\n",
    "        f2 = open(labelfile, \"r\")  #f2为打开标签文件\n",
    "        line = f.readline()  #读取序列文件的第一行\n",
    "        while line != '':\n",
    "            pssmfile = pssmdir + line[1:].strip() + \"_pssm.txt\"  #pssm文件名=pssm地址+id名+_pssm.txt\n",
    "            if line[0] == '>':  #如果该行第一个字符为>\n",
    "                id = line.strip()[1:]  #id为去掉>的字符\n",
    "                ids.append(id)   #在id空列表中添加id\n",
    "            label = f2.readline().strip()  #标签为f2（标签文件）中去掉首尾空格的内容\n",
    "            labels.append(label)  #在标签空列表中添加标签\n",
    "            seq = f.readline().strip()  #第一次seq为第2行的内容，实际seq为>行的下一行\n",
    "            #seql = len(seq)   #序列长度  \n",
    "            process_eachseq(seq,pssmfile,mask_seq,new_pssms)\n",
    "            line = f.readline()  #继续读取下一行，即>行\n",
    "        x = np.array(new_pssms)  #把new_pssms列表变为数组，赋给x\n",
    "        y = [convertlabels_to_categorical(i) for i in labels]  #把标签列表转化为类别(i)\n",
    "        y = np.array(y)  #再把类别转化为数组\n",
    "        mask = np.array(mask_seq)  #把mask_seq（标注的序列？）转化为数组\n",
    "        np.savez(npzfile, x=x, y=y, mask=mask, ids=ids)  #保存多个数组到同一个文件中,保存格式是.npz\n",
    "        return [x, y, mask,ids]  #返回pssm矩阵，类别，标注序列，名字id\n",
    "    else:  #如果上述都存在，直接转化为数组\n",
    "        mask = np.load(npzfile)['mask']\n",
    "        x = np.load(npzfile)['x']\n",
    "        y = np.load(npzfile)['y']\n",
    "        ids=np.load(npzfile)['ids']\n",
    "        return [x, y, mask,ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "warming-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MULocDeep(lv1_dir,lv2_dir,pssm_dir,output_dir,foldnum):\n",
    "    # get small data\n",
    "    [train_x, train_y, train_mask, train_ids] = endpad(\n",
    "        lv2_dir+\"lv2_train_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv2_dir+\"lv2_train_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv2_train_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    [val_x, val_y, val_mask,val_ids] = endpad(\n",
    "        lv2_dir+\"lv2_val_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv2_dir+\"lv2_val_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv2_val_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "\n",
    "    # get big data 训练10分类的多分类\n",
    "    [train_x_big, train_y_big, train_mask_big, train_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv1_train_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    [val_x_big, val_y_big, val_mask_big, val_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv1_val_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model_big, model_small = singlemodel(train_x)  #模型为singlemodel\n",
    "\n",
    "    filepath_acc_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_acc_small_lv2 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_small_lv2_acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_loss_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_loss-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_loss_small_lv2 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_small_lv2_loss-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "    checkpoint_acc_big_lev1 = ModelCheckpoint(filepath_acc_big_lv1, monitor='val_accuracy', save_best_only=True,\n",
    "                                          mode='max',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "\n",
    "    checkpoint_acc_small_lev2 = ModelCheckpoint(filepath_acc_small_lv2, monitor='val_lev2_accuracy', save_best_only=True,\n",
    "                                          mode='max',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    checkpoint_loss_big_lev1 = ModelCheckpoint(filepath_loss_big_lv1, monitor='val_loss', save_best_only=True,\n",
    "                                          mode='min',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    checkpoint_loss_small_lev2 = ModelCheckpoint(filepath_loss_small_lv2, monitor='val_lev2_loss', save_best_only=True,\n",
    "                                          mode='min',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    \n",
    "    for i in range(20):\n",
    "        # train small model\n",
    "        print(\"epoch \"+str(i)+\"\\n\")\n",
    "        '''fitHistory_batch_small = model_small.fit([train_x, train_mask.reshape(-1, 1000, 1)],\n",
    "                                                 [train_y,getTrue4out1(train_y)],\n",
    "                                                 batch_size=batch_size, epochs=1,\n",
    "                                                 validation_data=(\n",
    "                                                 [val_x, val_mask.reshape(-1, 1000, 1)], [val_y,getTrue4out1(val_y)]),\n",
    "                                                 callbacks=[checkpoint_acc_small_lev2,checkpoint_loss_small_lev2],verbose=1)'''\n",
    "        \n",
    "        # train big model  \n",
    "        fitHistory_batch_big = model_big.fit([train_x_big, train_mask_big.reshape(-1, 1000, 1)],\n",
    "                                             [getTrue4out1(train_y_big)],  #为何大模型没有train_y_big\n",
    "                                             batch_size=batch_size, epochs=1,  #等于1？？\n",
    "                                             validation_data=(\n",
    "                                             [val_x_big, val_mask_big.reshape(-1, 1000, 1)], [getTrue4out1(val_y_big)]),  #也没有val_y_big\n",
    "                                             callbacks=[checkpoint_acc_big_lev1,checkpoint_loss_big_lev1], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alert-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_var(input_var,pssm_dir,output_dir,foldnum):\n",
    "    # get small data\n",
    "    [train_x,train_y,train_mask,train_ids]=endpad(input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_seq\",\n",
    "                                        input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_label\",\n",
    "                                        pssm_dir,\n",
    "                                        \"D:/deeploc/deeploc_40nr_8folds/train_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    [val_x,val_y,val_mask,val_ids]=endpad(input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_seq\",\n",
    "                                  input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_label\",\n",
    "                                  pssm_dir,\n",
    "                                  \"D:/deeploc/deeploc_40nr_8folds/val_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model = var_model(train_x)   #这里的模型是var_model\n",
    "\n",
    "    filepath_acc = output_dir+\"fold\" + str(foldnum) + \"acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "    checkpoint_acc = ModelCheckpoint(filepath_acc, monitor='val_accuracy', save_best_only=True, mode='max',\n",
    "                                 save_weights_only=True, verbose=1)\n",
    "    fitHistory_batch = model.fit([train_x,train_mask.reshape(-1,1000,1)],getTrue4out1(train_y),\n",
    "                                 batch_size=batch_size, epochs=20,\n",
    "                                 validation_data=([val_x,val_mask.reshape(-1,1000,1)], getTrue4out1(val_y)),\n",
    "                                 callbacks=[checkpoint_acc],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spiritual-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''我们常常可以把argparse的使用简化成下面四个步骤\n",
    "       1：import argparse\n",
    "       2：parser = argparse.ArgumentParser()\n",
    "       3：parser.add_argument()\n",
    "       4：parser.parse_args()\n",
    "       上面四个步骤解释如下：首先导入该模块；然后创建一个解析对象；然后向该对象中添加你要关注的命令行参数和选项，\n",
    "       每一个add_argument方法对应一个你要关注的参数或选项；最后调用parse_args()方法进行解析；解析成功之后即可使用'''\n",
    "    \n",
    "def main():\n",
    "    #加default\n",
    "    # description= 这个参数简要描述这个程度做什么以及怎么做\n",
    "    parser=argparse.ArgumentParser(\n",
    "        description='MULocDeep: interpretable protein localization classifier at sub-cellular and sub-organellar levels')\n",
    "    #MULocDeep_model  UniLoc-train-20nr\n",
    "    #--lv1_input_dir/--lv2_input_dir 亚细胞训练数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--lv1_input_dir', dest='lv1_dir', type=str, \n",
    "                        default=\"D:/mulocdeep/mul_data\",\n",
    "                        help='sub-cellular training data, contains 8 folds protein sequences and labels', required=False)\n",
    "    parser.add_argument('--lv2_input_dir', dest='lv2_dir', type=str,\n",
    "                       default=\"D:/mulocdeep/mul_data\",\n",
    "                       help='sub-cellular training data, contains 8 folds protein sequences and labels', required=False)\n",
    "    #--MULocDeep_model 添加它来训练MULocDeep模型，否则训练一个var模型\n",
    "    parser.add_argument('--MULocDeep_model', dest='modeltype', action='store_false',  #触发，store_true会触发DeepLoc\n",
    "                        #如果是store_false,则默认值是True，如果是store_true,则默认值是False  \n",
    "                        help='Add this to train the MULocDeep model, otherwise train a variant model', required=False)\n",
    "    #--model_output 受过训练的模型存储的目录的名称  需自己添加\n",
    "    parser.add_argument('--model_output', dest='outputdir', type=str, \n",
    "                       default=\"D:/mulocdeep/lv1_result\",\n",
    "                       help='the name of the directory where the trained model stores', required=False)  #由True改成False\n",
    "    \n",
    "    parser.add_argument('-existPSSM', dest='existPSSM', type=str,\n",
    "                        default=\"D:/mulocdeep/mulocdeep_pssm\",\n",
    "                        help='the name of the existing PSSM directory if there is one.', required=False)\n",
    "    \n",
    "    #var_model  deeploc_40nr_8folds\n",
    "    #--input_dir 训练var模型的数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--input_var', dest='var_dir', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_40nr_8folds\",\n",
    "                        help='data for traing the variant model, contains 8 folds protein sequences and labels', required=False)\n",
    "    #改true  并且还需要加一个model_ouput  一个是deeploc  一个是MULocDeep\n",
    "    parser.add_argument('--var_model_output', dest='var_outputdir', type=str, help='the name of the directory where the trained model stores', \n",
    "                        default=\"D:/deeploc/var_model_result1\",\n",
    "                        required=False)  #由True改成False\n",
    "    parser.add_argument('-var_existPSSM', dest='var_existPSSM', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_pssm\",\n",
    "                        help='the name of the existing PSSM directory if there is one.', required=False)\n",
    "    parser.set_defaults(feature=True)\n",
    "    #args = parser.parse_args()   #改\n",
    "    args = parser.parse_known_args()[0]   #jupyter下运行解析需要此代码\n",
    "    model_type=args.modeltype\n",
    "    input_lv1=args.lv1_dir\n",
    "    input_lv2 = args.lv2_dir\n",
    "    outputdir=args.outputdir\n",
    "    existPSSM = args.existPSSM\n",
    "    input_var=args.var_dir\n",
    "    var_outputdir=args.var_outputdir\n",
    "    var_existPSSM = args.var_existPSSM\n",
    "\n",
    "    if model_type==True:\n",
    "        if not input_lv1[len(input_lv1) - 1] == \"/\":\n",
    "            input_lv1 = input_lv1 + \"/\"\n",
    "        if not input_lv2[len(input_lv2) - 1] == \"/\":\n",
    "            input_lv2 = input_lv2 + \"/\"\n",
    "        if not outputdir[len(outputdir) - 1] == \"/\":\n",
    "            outputdir = outputdir + \"/\"\n",
    "        if not os.path.exists(outputdir):\n",
    "            os.mkdir(outputdir)\n",
    "        if existPSSM != \"\":\n",
    "            if not existPSSM[len(existPSSM) - 1] == \"/\":\n",
    "                existPSSM = existPSSM + \"/\"\n",
    "        if ((existPSSM == \"\") or (not os.path.exists(existPSSM))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            pssmdir = outputdir + str(ts) + \"_pssm/\"\n",
    "            if not os.path.exists(pssmdir):\n",
    "                os.makedirs(pssmdir)\n",
    "            process_input_train(input_lv1 + \"lv1_train.txt\", pssmdir)\n",
    "            process_input_train(input_lv2 + \"lv2_train.txt\", pssmdir)\n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, input_lv2, pssmdir, outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, input_lv2, existPSSM, outputdir, foldnum)\n",
    "    elif model_type==False:\n",
    "        if not input_var[len(input_var) - 1] == \"/\":\n",
    "            input_var = input_var + \"/\"\n",
    "        if not var_outputdir[len(var_outputdir) - 1] == \"/\":\n",
    "            var_outputdir = var_outputdir + \"/\"\n",
    "        if not os.path.exists(var_outputdir):\n",
    "            os.mkdir(var_outputdir)\n",
    "        if existPSSM != \"\":\n",
    "            if not var_existPSSM[len(var_existPSSM) - 1] == \"/\":\n",
    "                var_existPSSM = var_existPSSM + \"/\"\n",
    "        if ((var_existPSSM == \"\") or (not os.path.exists(var_existPSSM))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            pssmdir = var_outputdir + str(ts) + \"_pssm/\"\n",
    "            if not os.path.exists(pssmdir):\n",
    "                os.makedirs(pssmdir)\n",
    "            process_input_train(input_var + \"processed_deeploc_train_S_seq\", pssmdir)\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, pssmdir, var_outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, var_existPSSM, var_outputdir, foldnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "associate-hearts",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing 0th fold\n",
      "WARNING:tensorflow:From C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1000, 25)     0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1000, 25)     650         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000, 25)     100         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 25)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1000, 25)     0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1000, 25)     1900        lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000, 25)     100         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 25)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1000, 25)     0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1000, 25)     3150        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1000, 25)     100         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000, 25)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1000, 25)     0           dropout_4[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1000, 25)     5650        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1000, 25)     100         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1000, 25)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1000, 25)     0           dropout_5[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1000, 25)     9400        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1000, 25)     100         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1000, 25)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1000, 25)     0           dropout_6[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1000, 25)     13150       lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 25)     100         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 25)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1000, 25)     0           dropout_7[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 180)    223560      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1000, 180)    720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1000, 180)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1000, 180)    0           dropout_8[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 180)    390960      lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1000, 180)    720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1000, 180)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1000, 180)    0           dropout_9[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 181)    0           lambda_9[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 41, 180)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1000, 25)     0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1000, 25)     650         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000, 25)     100         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 25)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1000, 25)     0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1000, 25)     1900        lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000, 25)     100         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 25)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1000, 25)     0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1000, 25)     3150        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1000, 25)     100         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000, 25)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1000, 25)     0           dropout_4[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1000, 25)     5650        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1000, 25)     100         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1000, 25)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1000, 25)     0           dropout_5[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1000, 25)     9400        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1000, 25)     100         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1000, 25)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1000, 25)     0           dropout_6[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1000, 25)     13150       lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 25)     100         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 25)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1000, 25)     0           dropout_7[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 180)    223560      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1000, 180)    720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1000, 180)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1000, 180)    0           dropout_8[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 180)    390960      lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1000, 180)    720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1000, 180)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1000, 180)    0           dropout_9[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 181)    0           lambda_9[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 41, 180)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 131s 8ms/step - loss: 0.7268 - accuracy: 0.6883 - val_loss: 0.6789 - val_accuracy: 0.8013\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80131, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67892, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.6339 - accuracy: 0.8200 - val_loss: 0.6107 - val_accuracy: 0.8335\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80131 to 0.83354, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.67892 to 0.61070, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.5949 - accuracy: 0.8529 - val_loss: 0.5748 - val_accuracy: 0.8592\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83354 to 0.85918, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.61070 to 0.57481, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.5659 - accuracy: 0.8687 - val_loss: 0.5499 - val_accuracy: 0.8721\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85918 to 0.87211, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57481 to 0.54993, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.5401 - accuracy: 0.8793 - val_loss: 0.5256 - val_accuracy: 0.8855\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87211 to 0.88552, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54993 to 0.52557, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 132s 8ms/step - loss: 0.5156 - accuracy: 0.8885 - val_loss: 0.4953 - val_accuracy: 0.8863\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88552 to 0.88630, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52557 to 0.49529, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.4934 - accuracy: 0.8937 - val_loss: 0.4743 - val_accuracy: 0.8957\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88630 to 0.89571, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49529 to 0.47427, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.4738 - accuracy: 0.8980 - val_loss: 0.4551 - val_accuracy: 0.9038\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89571 to 0.90376, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47427 to 0.45510, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.4547 - accuracy: 0.9021 - val_loss: 0.4429 - val_accuracy: 0.9016\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90376\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45510 to 0.44290, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.4378 - accuracy: 0.9045 - val_loss: 0.4231 - val_accuracy: 0.9112\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90376 to 0.91117, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44290 to 0.42308, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 116s 7ms/step - loss: 0.4211 - accuracy: 0.9085 - val_loss: 0.4086 - val_accuracy: 0.9114\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91117 to 0.91141, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42308 to 0.40863, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.4053 - accuracy: 0.9109 - val_loss: 0.3943 - val_accuracy: 0.9121\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91141 to 0.91211, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40863 to 0.39429, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.3896 - accuracy: 0.9135 - val_loss: 0.3776 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91211 to 0.91885, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39429 to 0.37761, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.3756 - accuracy: 0.9157 - val_loss: 0.3756 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91885\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37761 to 0.37563, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.3621 - accuracy: 0.9183 - val_loss: 0.3548 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91885 to 0.91988, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37563 to 0.35482, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.3492 - accuracy: 0.9210 - val_loss: 0.3457 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91988 to 0.92307, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35482 to 0.34566, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.3373 - accuracy: 0.9222 - val_loss: 0.3375 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92307\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34566 to 0.33750, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.3259 - accuracy: 0.9240 - val_loss: 0.3264 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92307 to 0.92393, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from 0.33750 to 0.32645, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.3153 - accuracy: 0.9261 - val_loss: 0.3162 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92393 to 0.92405, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32645 to 0.31619, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.3056 - accuracy: 0.9271 - val_loss: 0.3064 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92405 to 0.92622, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31619 to 0.30644, saving model to D:/mulocdeep/lv1_result/fold0_big_lv1_loss-weights.hdf5\n",
      "doing 1th fold\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1000, 25)     0           dropout_12[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1000, 25)     650         lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1000, 25)     100         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1000, 25)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1000, 25)     0           dropout_13[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1000, 25)     1900        lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1000, 25)     100         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1000, 25)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1000, 25)     0           dropout_14[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1000, 25)     3150        lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1000, 25)     100         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1000, 25)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1000, 25)     0           dropout_15[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1000, 25)     5650        lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1000, 25)     100         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1000, 25)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1000, 25)     0           dropout_16[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1000, 25)     9400        lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1000, 25)     100         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1000, 25)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1000, 25)     0           dropout_17[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1000, 25)     13150       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1000, 25)     100         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1000, 25)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1000, 25)     0           dropout_18[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 180)    223560      lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1000, 180)    720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 1000, 180)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1000, 180)    0           dropout_19[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 180)    390960      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1000, 180)    720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 1000, 180)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1000, 180)    0           dropout_20[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1000, 181)    0           lambda_18[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 41, 180)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1000, 25)     0           dropout_12[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1000, 25)     650         lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1000, 25)     100         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1000, 25)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1000, 25)     0           dropout_13[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1000, 25)     1900        lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1000, 25)     100         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1000, 25)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1000, 25)     0           dropout_14[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1000, 25)     3150        lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1000, 25)     100         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1000, 25)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1000, 25)     0           dropout_15[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1000, 25)     5650        lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1000, 25)     100         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1000, 25)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1000, 25)     0           dropout_16[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1000, 25)     9400        lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1000, 25)     100         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1000, 25)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1000, 25)     0           dropout_17[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1000, 25)     13150       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1000, 25)     100         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1000, 25)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1000, 25)     0           dropout_18[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 180)    223560      lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1000, 180)    720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 1000, 180)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1000, 180)    0           dropout_19[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 180)    390960      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1000, 180)    720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 1000, 180)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1000, 180)    0           dropout_20[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1000, 181)    0           lambda_18[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 41, 180)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 124s 7ms/step - loss: 0.7404 - accuracy: 0.6648 - val_loss: 0.7091 - val_accuracy: 0.8170\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81697, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70913, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.6407 - accuracy: 0.8205 - val_loss: 0.6440 - val_accuracy: 0.8428\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81697 to 0.84282, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.70913 to 0.64398, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 116s 7ms/step - loss: 0.5958 - accuracy: 0.8515 - val_loss: 0.5875 - val_accuracy: 0.8560\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84282 to 0.85603, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.64398 to 0.58753, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.5632 - accuracy: 0.8698 - val_loss: 0.5526 - val_accuracy: 0.8799\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85603 to 0.87992, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.58753 to 0.55256, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.5358 - accuracy: 0.8840 - val_loss: 0.5289 - val_accuracy: 0.8826\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87992 to 0.88262, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55256 to 0.52894, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.5131 - accuracy: 0.8892 - val_loss: 0.5040 - val_accuracy: 0.8881\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88262 to 0.88810, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52894 to 0.50400, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.4914 - accuracy: 0.8957 - val_loss: 0.4928 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88810 to 0.88830, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50400 to 0.49280, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 111s 6ms/step - loss: 0.4712 - accuracy: 0.9000 - val_loss: 0.4636 - val_accuracy: 0.9001\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88830 to 0.90008, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49280 to 0.46361, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 111s 6ms/step - loss: 0.4519 - accuracy: 0.9044 - val_loss: 0.4533 - val_accuracy: 0.9036\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90008 to 0.90356, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46361 to 0.45329, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 111s 6ms/step - loss: 0.4344 - accuracy: 0.9071 - val_loss: 0.4316 - val_accuracy: 0.9053\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90356 to 0.90528, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45329 to 0.43165, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 120s 7ms/step - loss: 0.4176 - accuracy: 0.9109 - val_loss: 0.4154 - val_accuracy: 0.9091\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90528 to 0.90908, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43165 to 0.41540, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 111s 6ms/step - loss: 0.4014 - accuracy: 0.9138 - val_loss: 0.4045 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90908\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41540 to 0.40447, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.3861 - accuracy: 0.9160 - val_loss: 0.3922 - val_accuracy: 0.9085\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90908\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40447 to 0.39224, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.3713 - accuracy: 0.9185 - val_loss: 0.3789 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90908 to 0.91166, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39224 to 0.37895, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.3570 - accuracy: 0.9214 - val_loss: 0.3687 - val_accuracy: 0.9160\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91166 to 0.91595, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37895 to 0.36870, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.3448 - accuracy: 0.9225 - val_loss: 0.3559 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91595\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36870 to 0.35587, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.3327 - accuracy: 0.9246 - val_loss: 0.3474 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91595\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35587 to 0.34736, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.3208 - accuracy: 0.9269 - val_loss: 0.3357 - val_accuracy: 0.9169\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91595 to 0.91689, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34736 to 0.33565, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 123s 7ms/step - loss: 0.3098 - accuracy: 0.9286 - val_loss: 0.3230 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91689 to 0.91885, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33565 to 0.32299, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.3000 - accuracy: 0.9302 - val_loss: 0.3175 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91885\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32299 to 0.31747, saving model to D:/mulocdeep/lv1_result/fold1_big_lv1_loss-weights.hdf5\n",
      "doing 2th fold\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1000, 25)     0           dropout_23[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1000, 25)     650         lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1000, 25)     100         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 1000, 25)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1000, 25)     0           dropout_24[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1000, 25)     1900        lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1000, 25)     100         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 1000, 25)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1000, 25)     0           dropout_25[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1000, 25)     3150        lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1000, 25)     100         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1000, 25)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1000, 25)     0           dropout_26[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1000, 25)     5650        lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1000, 25)     100         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1000, 25)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1000, 25)     0           dropout_27[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1000, 25)     9400        lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1000, 25)     100         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1000, 25)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1000, 25)     0           dropout_28[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1000, 25)     13150       lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1000, 25)     100         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 1000, 25)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1000, 25)     0           dropout_29[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 180)    223560      lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1000, 180)    720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 1000, 180)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1000, 180)    0           dropout_30[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 180)    390960      lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1000, 180)    720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1000, 180)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 1000, 180)    0           dropout_31[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 181)    0           lambda_27[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 41, 180)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1000, 25)     0           dropout_23[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1000, 25)     650         lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1000, 25)     100         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 1000, 25)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1000, 25)     0           dropout_24[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1000, 25)     1900        lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1000, 25)     100         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 1000, 25)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1000, 25)     0           dropout_25[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1000, 25)     3150        lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1000, 25)     100         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1000, 25)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1000, 25)     0           dropout_26[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1000, 25)     5650        lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1000, 25)     100         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1000, 25)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1000, 25)     0           dropout_27[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1000, 25)     9400        lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1000, 25)     100         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1000, 25)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1000, 25)     0           dropout_28[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1000, 25)     13150       lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1000, 25)     100         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 1000, 25)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1000, 25)     0           dropout_29[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 180)    223560      lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1000, 180)    720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 1000, 180)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1000, 180)    0           dropout_30[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 180)    390960      lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1000, 180)    720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1000, 180)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 1000, 180)    0           dropout_31[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 181)    0           lambda_27[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 41, 180)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 122s 7ms/step - loss: 0.7207 - accuracy: 0.7013 - val_loss: 0.6996 - val_accuracy: 0.8268\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82676, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69960, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 112s 7ms/step - loss: 0.6335 - accuracy: 0.8246 - val_loss: 0.6085 - val_accuracy: 0.8470\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82676 to 0.84702, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.69960 to 0.60847, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 113s 7ms/step - loss: 0.5929 - accuracy: 0.8507 - val_loss: 0.5772 - val_accuracy: 0.8648\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84702 to 0.86475, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.60847 to 0.57721, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 112s 7ms/step - loss: 0.5623 - accuracy: 0.8683 - val_loss: 0.5564 - val_accuracy: 0.8744\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86475 to 0.87438, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57721 to 0.55639, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 124s 7ms/step - loss: 0.5350 - accuracy: 0.8816 - val_loss: 0.5311 - val_accuracy: 0.8902\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87438 to 0.89025, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55639 to 0.53107, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 117s 7ms/step - loss: 0.5118 - accuracy: 0.8875 - val_loss: 0.5085 - val_accuracy: 0.8951\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89025 to 0.89515, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53107 to 0.50852, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 112s 7ms/step - loss: 0.4894 - accuracy: 0.8942 - val_loss: 0.4754 - val_accuracy: 0.8947\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89515\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50852 to 0.47539, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 118s 7ms/step - loss: 0.4700 - accuracy: 0.8984 - val_loss: 0.4568 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89515 to 0.89962, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47539 to 0.45684, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 121s 7ms/step - loss: 0.4505 - accuracy: 0.9020 - val_loss: 0.4401 - val_accuracy: 0.9038\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89962 to 0.90376, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45684 to 0.44014, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 117s 7ms/step - loss: 0.4321 - accuracy: 0.9065 - val_loss: 0.4362 - val_accuracy: 0.9049\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90376 to 0.90494, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44014 to 0.43618, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 121s 7ms/step - loss: 0.4156 - accuracy: 0.9087 - val_loss: 0.4124 - val_accuracy: 0.9120\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90494 to 0.91199, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43618 to 0.41244, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 124s 7ms/step - loss: 0.3989 - accuracy: 0.9125 - val_loss: 0.3979 - val_accuracy: 0.9109\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91199\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41244 to 0.39794, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 120s 7ms/step - loss: 0.3844 - accuracy: 0.9141 - val_loss: 0.3887 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91199 to 0.91435, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39794 to 0.38872, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 118s 7ms/step - loss: 0.3701 - accuracy: 0.9160 - val_loss: 0.3695 - val_accuracy: 0.9163\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91435 to 0.91625, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38872 to 0.36951, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 125s 7ms/step - loss: 0.3564 - accuracy: 0.9191 - val_loss: 0.3609 - val_accuracy: 0.9169\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91625 to 0.91693, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36951 to 0.36092, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 121s 7ms/step - loss: 0.3442 - accuracy: 0.9210 - val_loss: 0.3475 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91693 to 0.91731, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36092 to 0.34749, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 115s 7ms/step - loss: 0.3321 - accuracy: 0.9238 - val_loss: 0.3418 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91731\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34749 to 0.34183, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 113s 7ms/step - loss: 0.3217 - accuracy: 0.9244 - val_loss: 0.3244 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91731 to 0.92250, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34183 to 0.32444, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17214/17214 [==============================] - 117s 7ms/step - loss: 0.3100 - accuracy: 0.9269 - val_loss: 0.3181 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92250 to 0.92355, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32444 to 0.31814, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 116s 7ms/step - loss: 0.3006 - accuracy: 0.9281 - val_loss: 0.3082 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92355 to 0.92448, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31814 to 0.30824, saving model to D:/mulocdeep/lv1_result/fold2_big_lv1_loss-weights.hdf5\n",
      "doing 3th fold\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1000, 25)     0           dropout_34[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1000, 25)     650         lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1000, 25)     100         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 1000, 25)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 1000, 25)     0           dropout_35[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1000, 25)     1900        lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1000, 25)     100         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 1000, 25)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1000, 25)     0           dropout_36[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1000, 25)     3150        lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1000, 25)     100         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1000, 25)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 1000, 25)     0           dropout_37[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1000, 25)     5650        lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 1000, 25)     100         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1000, 25)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1000, 25)     0           dropout_38[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1000, 25)     9400        lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 1000, 25)     100         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 1000, 25)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 1000, 25)     0           dropout_39[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1000, 25)     13150       lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1000, 25)     100         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 1000, 25)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 1000, 25)     0           dropout_40[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1000, 180)    223560      lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1000, 180)    720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 1000, 180)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 1000, 180)    0           dropout_41[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1000, 180)    390960      lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1000, 180)    720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 1000, 180)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1000, 180)    0           dropout_42[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1000, 181)    0           lambda_36[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 41, 180)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1000, 25)     0           dropout_34[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1000, 25)     650         lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1000, 25)     100         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 1000, 25)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 1000, 25)     0           dropout_35[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1000, 25)     1900        lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1000, 25)     100         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 1000, 25)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1000, 25)     0           dropout_36[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1000, 25)     3150        lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1000, 25)     100         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1000, 25)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 1000, 25)     0           dropout_37[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1000, 25)     5650        lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 1000, 25)     100         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1000, 25)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1000, 25)     0           dropout_38[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1000, 25)     9400        lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 1000, 25)     100         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 1000, 25)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 1000, 25)     0           dropout_39[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1000, 25)     13150       lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1000, 25)     100         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 1000, 25)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 1000, 25)     0           dropout_40[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1000, 180)    223560      lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1000, 180)    720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 1000, 180)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 1000, 180)    0           dropout_41[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1000, 180)    390960      lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1000, 180)    720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 1000, 180)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1000, 180)    0           dropout_42[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1000, 181)    0           lambda_36[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 41, 180)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 124s 7ms/step - loss: 0.7456 - accuracy: 0.6661 - val_loss: 0.6687 - val_accuracy: 0.7845\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78450, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66867, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 114s 7ms/step - loss: 0.6473 - accuracy: 0.8058 - val_loss: 0.6699 - val_accuracy: 0.8447\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.78450 to 0.84471, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.66867\n",
      "epoch 2\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 119s 7ms/step - loss: 0.6017 - accuracy: 0.8484 - val_loss: 0.5753 - val_accuracy: 0.8647\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84471 to 0.86467, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66867 to 0.57533, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 120s 7ms/step - loss: 0.5688 - accuracy: 0.8651 - val_loss: 0.5490 - val_accuracy: 0.8696\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86467 to 0.86957, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57533 to 0.54899, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 131s 8ms/step - loss: 0.5415 - accuracy: 0.8785 - val_loss: 0.5178 - val_accuracy: 0.8853\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86957 to 0.88527, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54899 to 0.51777, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 124s 7ms/step - loss: 0.5162 - accuracy: 0.8883 - val_loss: 0.5006 - val_accuracy: 0.8918\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88527 to 0.89176, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51777 to 0.50059, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 119s 7ms/step - loss: 0.4945 - accuracy: 0.8936 - val_loss: 0.4756 - val_accuracy: 0.9008\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89176 to 0.90081, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50059 to 0.47557, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 119s 7ms/step - loss: 0.4747 - accuracy: 0.8976 - val_loss: 0.4655 - val_accuracy: 0.9013\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90081 to 0.90130, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47557 to 0.46551, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 120s 7ms/step - loss: 0.4556 - accuracy: 0.9017 - val_loss: 0.4419 - val_accuracy: 0.9012\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90130\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46551 to 0.44188, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 120s 7ms/step - loss: 0.4382 - accuracy: 0.9055 - val_loss: 0.4229 - val_accuracy: 0.9114\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90130 to 0.91144, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44188 to 0.42287, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 121s 7ms/step - loss: 0.4216 - accuracy: 0.9085 - val_loss: 0.4103 - val_accuracy: 0.9086\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91144\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42287 to 0.41033, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 120s 7ms/step - loss: 0.4051 - accuracy: 0.9114 - val_loss: 0.3987 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91144\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41033 to 0.39867, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 123s 7ms/step - loss: 0.3895 - accuracy: 0.9142 - val_loss: 0.3826 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91144 to 0.91663, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39867 to 0.38261, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 119s 7ms/step - loss: 0.3747 - accuracy: 0.9173 - val_loss: 0.3672 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91663\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38261 to 0.36721, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 117s 7ms/step - loss: 0.3619 - accuracy: 0.9196 - val_loss: 0.3561 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91663 to 0.91988, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36721 to 0.35606, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 119s 7ms/step - loss: 0.3486 - accuracy: 0.9210 - val_loss: 0.3466 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91988\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35606 to 0.34662, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 118s 7ms/step - loss: 0.3378 - accuracy: 0.9223 - val_loss: 0.3331 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91988 to 0.92195, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34662 to 0.33309, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 119s 7ms/step - loss: 0.3270 - accuracy: 0.9236 - val_loss: 0.3298 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92195\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33309 to 0.32976, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 119s 7ms/step - loss: 0.3161 - accuracy: 0.9255 - val_loss: 0.3175 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92195 to 0.92495, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32976 to 0.31749, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 122s 7ms/step - loss: 0.3059 - accuracy: 0.9268 - val_loss: 0.3064 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92495 to 0.92580, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31749 to 0.30635, saving model to D:/mulocdeep/lv1_result/fold3_big_lv1_loss-weights.hdf5\n",
      "doing 4th fold\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 1000, 25)     0           dropout_45[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1000, 25)     650         lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 1000, 25)     100         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 1000, 25)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 1000, 25)     0           dropout_46[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 1000, 25)     1900        lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 1000, 25)     100         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 1000, 25)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 1000, 25)     0           dropout_47[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1000, 25)     3150        lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 1000, 25)     100         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 1000, 25)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 1000, 25)     0           dropout_48[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1000, 25)     5650        lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 1000, 25)     100         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 1000, 25)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 1000, 25)     0           dropout_49[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1000, 25)     9400        lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1000, 25)     100         conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 1000, 25)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 1000, 25)     0           dropout_50[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1000, 25)     13150       lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 1000, 25)     100         conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 1000, 25)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 1000, 25)     0           dropout_51[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1000, 180)    223560      lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 1000, 180)    720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 1000, 180)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 1000, 180)    0           dropout_52[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1000, 180)    390960      lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 1000, 180)    720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 1000, 180)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 1000, 180)    0           dropout_53[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1000, 181)    0           lambda_45[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 41, 180)      0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 1000, 25)     0           dropout_45[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1000, 25)     650         lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 1000, 25)     100         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 1000, 25)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 1000, 25)     0           dropout_46[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 1000, 25)     1900        lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 1000, 25)     100         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 1000, 25)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 1000, 25)     0           dropout_47[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1000, 25)     3150        lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 1000, 25)     100         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 1000, 25)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 1000, 25)     0           dropout_48[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1000, 25)     5650        lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 1000, 25)     100         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 1000, 25)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 1000, 25)     0           dropout_49[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1000, 25)     9400        lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1000, 25)     100         conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 1000, 25)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 1000, 25)     0           dropout_50[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1000, 25)     13150       lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 1000, 25)     100         conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 1000, 25)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 1000, 25)     0           dropout_51[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1000, 180)    223560      lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 1000, 180)    720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 1000, 180)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 1000, 180)    0           dropout_52[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1000, 180)    390960      lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 1000, 180)    720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 1000, 180)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 1000, 180)    0           dropout_53[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1000, 181)    0           lambda_45[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 41, 180)      0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 143s 8ms/step - loss: 0.7313 - accuracy: 0.6828 - val_loss: 0.7046 - val_accuracy: 0.8045\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80447, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70460, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.6361 - accuracy: 0.8234 - val_loss: 0.6109 - val_accuracy: 0.8451\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80447 to 0.84506, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.70460 to 0.61089, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 117s 7ms/step - loss: 0.5958 - accuracy: 0.8546 - val_loss: 0.5805 - val_accuracy: 0.8621\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84506 to 0.86207, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.61089 to 0.58046, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 116s 7ms/step - loss: 0.5658 - accuracy: 0.8690 - val_loss: 0.5420 - val_accuracy: 0.8713\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86207 to 0.87130, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.58046 to 0.54203, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 121s 7ms/step - loss: 0.5394 - accuracy: 0.8787 - val_loss: 0.5273 - val_accuracy: 0.8775\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87130 to 0.87747, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54203 to 0.52732, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.5145 - accuracy: 0.8875 - val_loss: 0.5142 - val_accuracy: 0.8854\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87747 to 0.88545, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52732 to 0.51417, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.4926 - accuracy: 0.8928 - val_loss: 0.4828 - val_accuracy: 0.8947\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88545 to 0.89472, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51417 to 0.48282, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.4725 - accuracy: 0.8981 - val_loss: 0.4611 - val_accuracy: 0.8942\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89472\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48282 to 0.46109, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 126s 7ms/step - loss: 0.4536 - accuracy: 0.9021 - val_loss: 0.4446 - val_accuracy: 0.8980\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89472 to 0.89802, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46109 to 0.44455, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 120s 7ms/step - loss: 0.4353 - accuracy: 0.9056 - val_loss: 0.4261 - val_accuracy: 0.9067\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89802 to 0.90665, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44455 to 0.42610, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.4180 - accuracy: 0.9087 - val_loss: 0.4144 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90665\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42610 to 0.41437, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.4028 - accuracy: 0.9110 - val_loss: 0.3963 - val_accuracy: 0.9099\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90665 to 0.90988, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41437 to 0.39629, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.3869 - accuracy: 0.9141 - val_loss: 0.3946 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90988\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39629 to 0.39464, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.3734 - accuracy: 0.9161 - val_loss: 0.3737 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90988 to 0.91149, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39464 to 0.37366, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 116s 7ms/step - loss: 0.3596 - accuracy: 0.9184 - val_loss: 0.3608 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91149\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37366 to 0.36084, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 117s 7ms/step - loss: 0.3472 - accuracy: 0.9203 - val_loss: 0.3485 - val_accuracy: 0.9156\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91149 to 0.91556, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36084 to 0.34853, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 126s 7ms/step - loss: 0.3347 - accuracy: 0.9232 - val_loss: 0.3394 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91556\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34853 to 0.33935, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 120s 7ms/step - loss: 0.3239 - accuracy: 0.9242 - val_loss: 0.3290 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91556 to 0.92003, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33935 to 0.32901, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 125s 7ms/step - loss: 0.3131 - accuracy: 0.9262 - val_loss: 0.3341 - val_accuracy: 0.9169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92003\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32901\n",
      "epoch 19\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 120s 7ms/step - loss: 0.3039 - accuracy: 0.9279 - val_loss: 0.3087 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92003\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32901 to 0.30873, saving model to D:/mulocdeep/lv1_result/fold4_big_lv1_loss-weights.hdf5\n",
      "doing 5th fold\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 1000, 25)     0           dropout_56[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1000, 25)     650         lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 1000, 25)     100         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 1000, 25)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 1000, 25)     0           dropout_57[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1000, 25)     1900        lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 1000, 25)     100         conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 1000, 25)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 1000, 25)     0           dropout_58[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1000, 25)     3150        lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1000, 25)     100         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 1000, 25)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 1000, 25)     0           dropout_59[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1000, 25)     5650        lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1000, 25)     100         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 1000, 25)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 1000, 25)     0           dropout_60[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1000, 25)     9400        lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 1000, 25)     100         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 1000, 25)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 1000, 25)     0           dropout_61[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 1000, 25)     13150       lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1000, 25)     100         conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 1000, 25)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 1000, 25)     0           dropout_62[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1000, 180)    223560      lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 1000, 180)    720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 1000, 180)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 1000, 180)    0           dropout_63[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1000, 180)    390960      lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 1000, 180)    720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 1000, 180)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 1000, 180)    0           dropout_64[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1000, 181)    0           lambda_54[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 41, 180)      0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 1000, 25)     0           dropout_56[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1000, 25)     650         lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 1000, 25)     100         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 1000, 25)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 1000, 25)     0           dropout_57[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1000, 25)     1900        lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 1000, 25)     100         conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 1000, 25)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 1000, 25)     0           dropout_58[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1000, 25)     3150        lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1000, 25)     100         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 1000, 25)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 1000, 25)     0           dropout_59[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1000, 25)     5650        lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1000, 25)     100         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 1000, 25)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 1000, 25)     0           dropout_60[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1000, 25)     9400        lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 1000, 25)     100         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 1000, 25)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 1000, 25)     0           dropout_61[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 1000, 25)     13150       lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1000, 25)     100         conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 1000, 25)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 1000, 25)     0           dropout_62[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1000, 180)    223560      lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 1000, 180)    720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 1000, 180)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 1000, 180)    0           dropout_63[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1000, 180)    390960      lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 1000, 180)    720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 1000, 180)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 1000, 180)    0           dropout_64[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1000, 181)    0           lambda_54[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 41, 180)      0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 135s 8ms/step - loss: 0.7429 - accuracy: 0.6839 - val_loss: 0.7028 - val_accuracy: 0.7998\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79983, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70281, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 138s 8ms/step - loss: 0.6411 - accuracy: 0.8158 - val_loss: 0.7087 - val_accuracy: 0.8050\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.79983 to 0.80495, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.70281\n",
      "epoch 2\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.5979 - accuracy: 0.8497 - val_loss: 0.5833 - val_accuracy: 0.8552\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80495 to 0.85517, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.70281 to 0.58327, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.5652 - accuracy: 0.8684 - val_loss: 0.5492 - val_accuracy: 0.8736\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85517 to 0.87361, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.58327 to 0.54916, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.5381 - accuracy: 0.8808 - val_loss: 0.5229 - val_accuracy: 0.8838\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87361 to 0.88377, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54916 to 0.52294, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.5144 - accuracy: 0.8881 - val_loss: 0.4984 - val_accuracy: 0.8911\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88377 to 0.89112, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52294 to 0.49842, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.4927 - accuracy: 0.8940 - val_loss: 0.4955 - val_accuracy: 0.8912\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89112 to 0.89116, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49842 to 0.49551, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 115s 7ms/step - loss: 0.4727 - accuracy: 0.8985 - val_loss: 0.4591 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89116 to 0.90000, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49551 to 0.45910, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.4534 - accuracy: 0.9030 - val_loss: 0.4440 - val_accuracy: 0.8997\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45910 to 0.44404, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 126s 7ms/step - loss: 0.4353 - accuracy: 0.9063 - val_loss: 0.4274 - val_accuracy: 0.9061\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90000 to 0.90615, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44404 to 0.42737, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.4184 - accuracy: 0.9097 - val_loss: 0.4137 - val_accuracy: 0.9056\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90615\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42737 to 0.41372, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.4021 - accuracy: 0.9127 - val_loss: 0.4046 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90615 to 0.90645, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41372 to 0.40458, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.3866 - accuracy: 0.9154 - val_loss: 0.3841 - val_accuracy: 0.9099\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90645 to 0.90986, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40458 to 0.38405, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.3732 - accuracy: 0.9173 - val_loss: 0.3735 - val_accuracy: 0.9102\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90986 to 0.91020, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38405 to 0.37354, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 115s 7ms/step - loss: 0.3594 - accuracy: 0.9192 - val_loss: 0.3641 - val_accuracy: 0.9147\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91020 to 0.91469, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37354 to 0.36415, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.3455 - accuracy: 0.9220 - val_loss: 0.3481 - val_accuracy: 0.9154\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91469 to 0.91537, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36415 to 0.34806, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 121s 7ms/step - loss: 0.3335 - accuracy: 0.9240 - val_loss: 0.3360 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91537 to 0.91716, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34806 to 0.33600, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 124s 7ms/step - loss: 0.3227 - accuracy: 0.9257 - val_loss: 0.3279 - val_accuracy: 0.9178\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91716 to 0.91781, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33600 to 0.32790, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.3118 - accuracy: 0.9274 - val_loss: 0.3205 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91781 to 0.91845, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32790 to 0.32052, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 120s 7ms/step - loss: 0.3025 - accuracy: 0.9289 - val_loss: 0.3173 - val_accuracy: 0.9181\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91845\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32052 to 0.31727, saving model to D:/mulocdeep/lv1_result/fold5_big_lv1_loss-weights.hdf5\n",
      "doing 6th fold\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 1000, 25)     0           dropout_67[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1000, 25)     650         lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1000, 25)     100         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 1000, 25)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 1000, 25)     0           dropout_68[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1000, 25)     1900        lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1000, 25)     100         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 1000, 25)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 1000, 25)     0           dropout_69[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1000, 25)     3150        lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 1000, 25)     100         conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 1000, 25)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 1000, 25)     0           dropout_70[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1000, 25)     5650        lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 1000, 25)     100         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 1000, 25)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 1000, 25)     0           dropout_71[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 1000, 25)     9400        lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 1000, 25)     100         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 1000, 25)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 1000, 25)     0           dropout_72[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1000, 25)     13150       lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1000, 25)     100         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 1000, 25)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 1000, 25)     0           dropout_73[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1000, 180)    223560      lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 1000, 180)    720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 1000, 180)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 1000, 180)    0           dropout_74[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1000, 180)    390960      lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1000, 180)    720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 1000, 180)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 1000, 180)    0           dropout_75[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 181)    0           lambda_63[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 41, 180)      0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 1000, 25)     0           dropout_67[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1000, 25)     650         lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1000, 25)     100         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 1000, 25)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 1000, 25)     0           dropout_68[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1000, 25)     1900        lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1000, 25)     100         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 1000, 25)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 1000, 25)     0           dropout_69[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1000, 25)     3150        lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 1000, 25)     100         conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 1000, 25)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 1000, 25)     0           dropout_70[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1000, 25)     5650        lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 1000, 25)     100         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 1000, 25)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 1000, 25)     0           dropout_71[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 1000, 25)     9400        lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 1000, 25)     100         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 1000, 25)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 1000, 25)     0           dropout_72[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1000, 25)     13150       lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1000, 25)     100         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 1000, 25)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 1000, 25)     0           dropout_73[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1000, 180)    223560      lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 1000, 180)    720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 1000, 180)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 1000, 180)    0           dropout_74[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1000, 180)    390960      lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1000, 180)    720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 1000, 180)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 1000, 180)    0           dropout_75[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 181)    0           lambda_63[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 41, 180)      0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 135s 8ms/step - loss: 0.7399 - accuracy: 0.6826 - val_loss: 0.6695 - val_accuracy: 0.7891\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78907, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66950, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 123s 7ms/step - loss: 0.6366 - accuracy: 0.8195 - val_loss: 0.6221 - val_accuracy: 0.8464\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.78907 to 0.84645, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66950 to 0.62206, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 132s 8ms/step - loss: 0.5964 - accuracy: 0.8514 - val_loss: 0.5674 - val_accuracy: 0.8635\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84645 to 0.86353, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.62206 to 0.56742, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 119s 7ms/step - loss: 0.5681 - accuracy: 0.8669 - val_loss: 0.5524 - val_accuracy: 0.8786\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86353 to 0.87861, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56742 to 0.55242, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.5426 - accuracy: 0.8783 - val_loss: 0.5241 - val_accuracy: 0.8832\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87861 to 0.88316, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55242 to 0.52411, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 119s 7ms/step - loss: 0.5185 - accuracy: 0.8857 - val_loss: 0.4942 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88316 to 0.89789, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52411 to 0.49420, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.4967 - accuracy: 0.8907 - val_loss: 0.4794 - val_accuracy: 0.8973\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89789\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49420 to 0.47942, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.4757 - accuracy: 0.8963 - val_loss: 0.4551 - val_accuracy: 0.9063\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89789 to 0.90627, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47942 to 0.45508, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.4566 - accuracy: 0.9008 - val_loss: 0.4377 - val_accuracy: 0.9061\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90627\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45508 to 0.43774, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.4389 - accuracy: 0.9032 - val_loss: 0.4312 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90627 to 0.90898, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43774 to 0.43122, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 127s 7ms/step - loss: 0.4223 - accuracy: 0.9073 - val_loss: 0.4067 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90898 to 0.91445, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43122 to 0.40665, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.4058 - accuracy: 0.9104 - val_loss: 0.3955 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91445\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40665 to 0.39545, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 123s 7ms/step - loss: 0.3916 - accuracy: 0.9122 - val_loss: 0.3798 - val_accuracy: 0.9154\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91445 to 0.91544, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39545 to 0.37984, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.3768 - accuracy: 0.9151 - val_loss: 0.3687 - val_accuracy: 0.9160\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91544 to 0.91604, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37984 to 0.36867, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.3626 - accuracy: 0.9176 - val_loss: 0.3563 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91604 to 0.91935, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36867 to 0.35635, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.3503 - accuracy: 0.9196 - val_loss: 0.3431 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91935 to 0.92091, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35635 to 0.34310, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 123s 7ms/step - loss: 0.3385 - accuracy: 0.9208 - val_loss: 0.3316 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92091 to 0.92187, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34310 to 0.33161, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 125s 7ms/step - loss: 0.3268 - accuracy: 0.9230 - val_loss: 0.3231 - val_accuracy: 0.9242\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92187 to 0.92418, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33161 to 0.32313, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17077/17077 [==============================] - 130s 8ms/step - loss: 0.3157 - accuracy: 0.9253 - val_loss: 0.3160 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92418\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32313 to 0.31601, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 126s 7ms/step - loss: 0.3061 - accuracy: 0.9264 - val_loss: 0.3067 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92418 to 0.92570, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31601 to 0.30675, saving model to D:/mulocdeep/lv1_result/fold6_big_lv1_loss-weights.hdf5\n",
      "doing 7th fold\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 1000, 25)     0           dropout_78[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1000, 25)     650         lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 1000, 25)     100         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 1000, 25)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 1000, 25)     0           dropout_79[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1000, 25)     1900        lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 1000, 25)     100         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 1000, 25)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 1000, 25)     0           dropout_80[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1000, 25)     3150        lambda_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1000, 25)     100         conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 1000, 25)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 1000, 25)     0           dropout_81[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 1000, 25)     5650        lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1000, 25)     100         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 1000, 25)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 1000, 25)     0           dropout_82[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1000, 25)     9400        lambda_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 1000, 25)     100         conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 1000, 25)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 1000, 25)     0           dropout_83[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1000, 25)     13150       lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 1000, 25)     100         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 1000, 25)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 1000, 25)     0           dropout_84[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1000, 180)    223560      lambda_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 1000, 180)    720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 1000, 180)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 1000, 180)    0           dropout_85[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1000, 180)    390960      lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 1000, 180)    720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 1000, 180)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 1000, 180)    0           dropout_86[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1000, 181)    0           lambda_72[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 41, 180)      0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 1000, 25)     0           dropout_78[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1000, 25)     650         lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 1000, 25)     100         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 1000, 25)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 1000, 25)     0           dropout_79[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1000, 25)     1900        lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 1000, 25)     100         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 1000, 25)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 1000, 25)     0           dropout_80[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1000, 25)     3150        lambda_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1000, 25)     100         conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 1000, 25)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 1000, 25)     0           dropout_81[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 1000, 25)     5650        lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1000, 25)     100         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 1000, 25)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 1000, 25)     0           dropout_82[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1000, 25)     9400        lambda_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 1000, 25)     100         conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 1000, 25)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 1000, 25)     0           dropout_83[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1000, 25)     13150       lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 1000, 25)     100         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 1000, 25)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 1000, 25)     0           dropout_84[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1000, 180)    223560      lambda_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 1000, 180)    720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 1000, 180)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 1000, 180)    0           dropout_85[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1000, 180)    390960      lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 1000, 180)    720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 1000, 180)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 1000, 180)    0           dropout_86[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1000, 181)    0           lambda_72[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 41, 180)      0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 139s 8ms/step - loss: 0.7399 - accuracy: 0.6707 - val_loss: 0.6922 - val_accuracy: 0.8002\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80024, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69220, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 126s 7ms/step - loss: 0.6361 - accuracy: 0.8236 - val_loss: 0.6689 - val_accuracy: 0.8328\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80024 to 0.83285, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.69220 to 0.66894, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 133s 8ms/step - loss: 0.5948 - accuracy: 0.8553 - val_loss: 0.5657 - val_accuracy: 0.8605\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83285 to 0.86047, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66894 to 0.56571, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 133s 8ms/step - loss: 0.5668 - accuracy: 0.8662 - val_loss: 0.5483 - val_accuracy: 0.8646\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86047 to 0.86462, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56571 to 0.54831, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 128s 7ms/step - loss: 0.5419 - accuracy: 0.8776 - val_loss: 0.5209 - val_accuracy: 0.8811\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86462 to 0.88107, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54831 to 0.52087, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 124s 7ms/step - loss: 0.5188 - accuracy: 0.8850 - val_loss: 0.5091 - val_accuracy: 0.8896\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88107 to 0.88964, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52087 to 0.50907, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 124s 7ms/step - loss: 0.4954 - accuracy: 0.8915 - val_loss: 0.4875 - val_accuracy: 0.8973\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88964 to 0.89731, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50907 to 0.48752, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.4747 - accuracy: 0.8962 - val_loss: 0.4534 - val_accuracy: 0.9076\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89731 to 0.90763, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48752 to 0.45341, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 124s 7ms/step - loss: 0.4559 - accuracy: 0.8996 - val_loss: 0.4389 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90763\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45341 to 0.43893, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.4376 - accuracy: 0.9041 - val_loss: 0.4241 - val_accuracy: 0.9102\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90763 to 0.91020, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43893 to 0.42411, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.4213 - accuracy: 0.9065 - val_loss: 0.4105 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91020 to 0.91237, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42411 to 0.41051, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.4054 - accuracy: 0.9096 - val_loss: 0.3944 - val_accuracy: 0.9129\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91237 to 0.91289, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41051 to 0.39442, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 124s 7ms/step - loss: 0.3893 - accuracy: 0.9122 - val_loss: 0.3821 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91289 to 0.91656, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39442 to 0.38206, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.3748 - accuracy: 0.9149 - val_loss: 0.3671 - val_accuracy: 0.9136\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91656\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38206 to 0.36712, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 120s 7ms/step - loss: 0.3611 - accuracy: 0.9164 - val_loss: 0.3529 - val_accuracy: 0.9212\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91656 to 0.92119, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36712 to 0.35287, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.3483 - accuracy: 0.9195 - val_loss: 0.3464 - val_accuracy: 0.9193\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92119\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35287 to 0.34642, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.3359 - accuracy: 0.9215 - val_loss: 0.3334 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92119 to 0.92233, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34642 to 0.33342, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 128s 8ms/step - loss: 0.3258 - accuracy: 0.9228 - val_loss: 0.3191 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92233 to 0.92312, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33342 to 0.31908, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17053/17053 [==============================] - 129s 8ms/step - loss: 0.3141 - accuracy: 0.9245 - val_loss: 0.3159 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92312\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31908 to 0.31594, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 124s 7ms/step - loss: 0.3046 - accuracy: 0.9263 - val_loss: 0.3111 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92312\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31594 to 0.31112, saving model to D:/mulocdeep/lv1_result/fold7_big_lv1_loss-weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-accused",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
