{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "import math\n",
    "from itertools import product\n",
    "import argparse\n",
    "import sys\n",
    "from utils_gruCS import *\n",
    "import calendar\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "damaged-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eachseq(seq,pssmfile,mask_seq,new_pssms):\n",
    "    if os.path.exists(pssmfile):  #如果pssm文件存在\n",
    "        print(\"found \" + pssmfile + \"\\n\")  #输出找到pssm文件+换行\n",
    "        pssm = readPSSM(pssmfile)  #读取pssm文件\n",
    "    else:  #否则\n",
    "        print(\"using Blosum62\\n\")  #输出使用Blosum62+换行\n",
    "        pssm = convertSampleToBlosum62(seq)  #把Blosum62矩阵当作pssm用\n",
    "        #pssm = convertSampleToCBOW(seq)\n",
    "    pssm = pssm.astype(float)  #对pssm的数据类型转换为浮点型\n",
    "    PhyChem = convertSampleToPhysicsVector_pca(seq)  #将样本转化为物理向量\n",
    "    pssm = np.concatenate((PhyChem, pssm), axis=1)  #物化指标和pssm对应行进行数组拼接\n",
    "    seql = len(seq)   #序列长度  \n",
    "    if seql <= 1000:  #如果序列长度小于等于1000\n",
    "        padnum = 1000 - seql  #pad大小为1000-序列长度\n",
    "        padmatrix = np.zeros([padnum, 25])  #pad矩阵为行数为padnum，列数为25的全0矩阵，即用0填充不足的地方\n",
    "        pssm = np.concatenate((pssm, padmatrix), axis=0)  #物化指标和pssm进行数组拼接 \n",
    "        new_pssms.append(pssm)  #新的pssm空列表中添加pssm矩阵\n",
    "        mask_seq.append(gen_mask_mat(seql, padnum))  #mask序列空列表添加gen_mask矩阵，序列长度为行数，padnum为列数？？？\n",
    "    else:  #如果序列长度大于1000\n",
    "        pssm = np.concatenate((pssm[0:500, :], pssm[seql - 500:seql, :]), axis=0)  #pssm矩阵为前500行和后500行矩阵的拼接\n",
    "        new_pssms.append(pssm)  #新的pssm空列表中添加pssm矩阵\n",
    "        mask_seq.append(gen_mask_mat(1000, 0))  #mask序列空列表添加1000行0列的？？？gen_mask矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metric-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpad(seqfile, labelfile, pssmdir=\"\", npzfile = \"\"): #定义endpad(序列文件，标签文件，pssm路径，npz文件)\n",
    "    if not os.path.exists(npzfile):  #如果npz文件不存在，建立新的pssm空列表，标签空列表，mask序列空列表，id空列表\n",
    "        new_pssms = []\n",
    "        labels = []\n",
    "        mask_seq = []\n",
    "        ids=[]\n",
    "        seqs=[]\n",
    "        f = open(seqfile, \"r\")  #f为打开序列文件\n",
    "        f2 = open(labelfile, \"r\")  #f2为打开标签文件\n",
    "        line = f.readline()  #读取序列文件的第一行\n",
    "        while line != '':\n",
    "            pssmfile = pssmdir + line[1:].strip() + \"_pssm.txt\"  #pssm文件名=pssm地址+id名+_pssm.txt\n",
    "            if line[0] == '>':  #如果该行第一个字符为>\n",
    "                id = line.strip()[1:]  #id为去掉>的字符\n",
    "                ids.append(id)   #在id空列表中添加id\n",
    "            label = f2.readline().strip()  #标签为f2（标签文件）中去掉首尾空格的内容\n",
    "            labels.append(label)  #在标签空列表中添加标签\n",
    "            seq = f.readline().strip()  #第一次seq为第2行的内容，实际seq为>行的下一行\n",
    "            #seql = len(seq)   #序列长度  \n",
    "            process_eachseq(seq,pssmfile,mask_seq,new_pssms)\n",
    "            line = f.readline()  #继续读取下一行，即>行\n",
    "        x = np.array(new_pssms)  #把new_pssms列表变为数组，赋给x\n",
    "        y = [convertlabels_to_categorical(i) for i in labels]  #把标签列表转化为类别(i)\n",
    "        y = np.array(y)  #再把类别转化为数组\n",
    "        mask = np.array(mask_seq)  #把mask_seq（标注的序列？）转化为数组\n",
    "        np.savez(npzfile, x=x, y=y, mask=mask, ids=ids)  #保存多个数组到同一个文件中,保存格式是.npz\n",
    "        return [x, y, mask,ids]  #返回pssm矩阵，类别，标注序列，名字id\n",
    "    else:  #如果上述都存在，直接转化为数组\n",
    "        mask = np.load(npzfile)['mask']\n",
    "        x = np.load(npzfile)['x']\n",
    "        y = np.load(npzfile)['y']\n",
    "        ids=np.load(npzfile)['ids']\n",
    "        return [x, y, mask,ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "warming-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MULocDeep(lv1_dir,lv2_dir,pssm_dir,output_dir,foldnum):\n",
    "    # get small data\n",
    "    [train_x, train_y, train_mask, train_ids] = endpad(\n",
    "        lv2_dir+\"lv2_train_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv2_dir+\"lv2_train_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv2_train_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    [val_x, val_y, val_mask,val_ids] = endpad(\n",
    "        lv2_dir+\"lv2_val_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv2_dir+\"lv2_val_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv2_val_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "\n",
    "    # get big data 训练10分类的多分类\n",
    "    [train_x_big, train_y_big, train_mask_big, train_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv1_train_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    [val_x_big, val_y_big, val_mask_big, val_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv1_val_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model_big, model_small = singlemodel(train_x)  #模型为singlemodel\n",
    "\n",
    "    filepath_acc_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_acc_small_lv2 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_small_lv2_acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_loss_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_loss-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_loss_small_lv2 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_small_lv2_loss-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "    checkpoint_acc_big_lev1 = ModelCheckpoint(filepath_acc_big_lv1, monitor='val_accuracy', save_best_only=True,\n",
    "                                          mode='max',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "\n",
    "    checkpoint_acc_small_lev2 = ModelCheckpoint(filepath_acc_small_lv2, monitor='val_lev2_accuracy', save_best_only=True,\n",
    "                                          mode='max',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    checkpoint_loss_big_lev1 = ModelCheckpoint(filepath_loss_big_lv1, monitor='val_loss', save_best_only=True,\n",
    "                                          mode='min',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    checkpoint_loss_small_lev2 = ModelCheckpoint(filepath_loss_small_lv2, monitor='val_lev2_loss', save_best_only=True,\n",
    "                                          mode='min',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    \n",
    "    for i in range(20):\n",
    "        # train small model\n",
    "        print(\"epoch \"+str(i)+\"\\n\")\n",
    "        '''fitHistory_batch_small = model_small.fit([train_x, train_mask.reshape(-1, 1000, 1)],\n",
    "                                                 [train_y,getTrue4out1(train_y)],\n",
    "                                                 batch_size=batch_size, epochs=1,\n",
    "                                                 validation_data=(\n",
    "                                                 [val_x, val_mask.reshape(-1, 1000, 1)], [val_y,getTrue4out1(val_y)]),\n",
    "                                                 callbacks=[checkpoint_acc_small_lev2,checkpoint_loss_small_lev2],verbose=1)'''\n",
    "        \n",
    "        # train big model  \n",
    "        fitHistory_batch_big = model_big.fit([train_x_big, train_mask_big.reshape(-1, 1000, 1)],\n",
    "                                             [getTrue4out1(train_y_big)],  #为何大模型没有train_y_big\n",
    "                                             batch_size=batch_size, epochs=1,  #等于1？？\n",
    "                                             validation_data=(\n",
    "                                             [val_x_big, val_mask_big.reshape(-1, 1000, 1)], [getTrue4out1(val_y_big)]),  #也没有val_y_big\n",
    "                                             callbacks=[checkpoint_acc_big_lev1,checkpoint_loss_big_lev1], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alert-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_var(input_var,pssm_dir,output_dir,foldnum):\n",
    "    # get small data\n",
    "    [train_x,train_y,train_mask,train_ids]=endpad(input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_seq\",\n",
    "                                        input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_label\",\n",
    "                                        pssm_dir,\n",
    "                                        \"D:/deeploc/deeploc_40nr_8folds/train_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    [val_x,val_y,val_mask,val_ids]=endpad(input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_seq\",\n",
    "                                  input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_label\",\n",
    "                                  pssm_dir,\n",
    "                                  \"D:/deeploc/deeploc_40nr_8folds/val_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model = var_model(train_x)   #这里的模型是var_model\n",
    "\n",
    "    filepath_acc = output_dir+\"fold\" + str(foldnum) + \"acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "    checkpoint_acc = ModelCheckpoint(filepath_acc, monitor='val_accuracy', save_best_only=True, mode='max',\n",
    "                                 save_weights_only=True, verbose=1)\n",
    "    fitHistory_batch = model.fit([train_x,train_mask.reshape(-1,1000,1)],getTrue4out1(train_y),\n",
    "                                 batch_size=batch_size, epochs=20,\n",
    "                                 validation_data=([val_x,val_mask.reshape(-1,1000,1)], getTrue4out1(val_y)),\n",
    "                                 callbacks=[checkpoint_acc],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spiritual-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''我们常常可以把argparse的使用简化成下面四个步骤\n",
    "       1：import argparse\n",
    "       2：parser = argparse.ArgumentParser()\n",
    "       3：parser.add_argument()\n",
    "       4：parser.parse_args()\n",
    "       上面四个步骤解释如下：首先导入该模块；然后创建一个解析对象；然后向该对象中添加你要关注的命令行参数和选项，\n",
    "       每一个add_argument方法对应一个你要关注的参数或选项；最后调用parse_args()方法进行解析；解析成功之后即可使用'''\n",
    "    \n",
    "def main():\n",
    "    #加default\n",
    "    # description= 这个参数简要描述这个程度做什么以及怎么做\n",
    "    parser=argparse.ArgumentParser(\n",
    "        description='MULocDeep: interpretable protein localization classifier at sub-cellular and sub-organellar levels')\n",
    "    #MULocDeep_model  UniLoc-train-20nr\n",
    "    #--lv1_input_dir/--lv2_input_dir 亚细胞训练数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--lv1_input_dir', dest='lv1_dir', type=str, \n",
    "                        default=\"D:/mulocdeep/mul_data\",\n",
    "                        help='sub-cellular training data, contains 8 folds protein sequences and labels', required=False)\n",
    "    parser.add_argument('--lv2_input_dir', dest='lv2_dir', type=str,\n",
    "                       default=\"D:/mulocdeep/mul_data\",\n",
    "                       help='sub-cellular training data, contains 8 folds protein sequences and labels', required=False)\n",
    "    #--MULocDeep_model 添加它来训练MULocDeep模型，否则训练一个var模型\n",
    "    parser.add_argument('--MULocDeep_model', dest='modeltype', action='store_false',  #触发，store_true会触发DeepLoc\n",
    "                        #如果是store_false,则默认值是True，如果是store_true,则默认值是False  \n",
    "                        help='Add this to train the MULocDeep model, otherwise train a variant model', required=False)\n",
    "    #--model_output 受过训练的模型存储的目录的名称  需自己添加\n",
    "    parser.add_argument('--model_output', dest='outputdir', type=str, \n",
    "                       default=\"D:/mulocdeep/lv1_result3\",\n",
    "                       help='the name of the directory where the trained model stores', required=False)  #由True改成False\n",
    "    \n",
    "    parser.add_argument('-existPSSM', dest='existPSSM', type=str,\n",
    "                        default=\"D:/mulocdeep/mulocdeep_pssm\",\n",
    "                        help='the name of the existing PSSM directory if there is one.', required=False)\n",
    "    \n",
    "    #var_model  deeploc_40nr_8folds\n",
    "    #--input_dir 训练var模型的数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--input_var', dest='var_dir', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_40nr_8folds\",\n",
    "                        help='data for traing the variant model, contains 8 folds protein sequences and labels', required=False)\n",
    "    #改true  并且还需要加一个model_ouput  一个是deeploc  一个是MULocDeep\n",
    "    parser.add_argument('--var_model_output', dest='var_outputdir', type=str, help='the name of the directory where the trained model stores', \n",
    "                        default=\"D:/deeploc/var_model_result1\",\n",
    "                        required=False)  #由True改成False\n",
    "    parser.add_argument('-var_existPSSM', dest='var_existPSSM', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_pssm\",\n",
    "                        help='the name of the existing PSSM directory if there is one.', required=False)\n",
    "    parser.set_defaults(feature=True)\n",
    "    #args = parser.parse_args()   #改\n",
    "    args = parser.parse_known_args()[0]   #jupyter下运行解析需要此代码\n",
    "    model_type=args.modeltype\n",
    "    input_lv1=args.lv1_dir\n",
    "    input_lv2 = args.lv2_dir\n",
    "    outputdir=args.outputdir\n",
    "    existPSSM = args.existPSSM\n",
    "    input_var=args.var_dir\n",
    "    var_outputdir=args.var_outputdir\n",
    "    var_existPSSM = args.var_existPSSM\n",
    "\n",
    "    if model_type==True:\n",
    "        if not input_lv1[len(input_lv1) - 1] == \"/\":\n",
    "            input_lv1 = input_lv1 + \"/\"\n",
    "        if not input_lv2[len(input_lv2) - 1] == \"/\":\n",
    "            input_lv2 = input_lv2 + \"/\"\n",
    "        if not outputdir[len(outputdir) - 1] == \"/\":\n",
    "            outputdir = outputdir + \"/\"\n",
    "        if not os.path.exists(outputdir):\n",
    "            os.mkdir(outputdir)\n",
    "        if existPSSM != \"\":\n",
    "            if not existPSSM[len(existPSSM) - 1] == \"/\":\n",
    "                existPSSM = existPSSM + \"/\"\n",
    "        if ((existPSSM == \"\") or (not os.path.exists(existPSSM))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            pssmdir = outputdir + str(ts) + \"_pssm/\"\n",
    "            if not os.path.exists(pssmdir):\n",
    "                os.makedirs(pssmdir)\n",
    "            process_input_train(input_lv1 + \"lv1_train.txt\", pssmdir)\n",
    "            process_input_train(input_lv2 + \"lv2_train.txt\", pssmdir)\n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, input_lv2, pssmdir, outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, input_lv2, existPSSM, outputdir, foldnum)\n",
    "    elif model_type==False:\n",
    "        if not input_var[len(input_var) - 1] == \"/\":\n",
    "            input_var = input_var + \"/\"\n",
    "        if not var_outputdir[len(var_outputdir) - 1] == \"/\":\n",
    "            var_outputdir = var_outputdir + \"/\"\n",
    "        if not os.path.exists(var_outputdir):\n",
    "            os.mkdir(var_outputdir)\n",
    "        if existPSSM != \"\":\n",
    "            if not var_existPSSM[len(var_existPSSM) - 1] == \"/\":\n",
    "                var_existPSSM = var_existPSSM + \"/\"\n",
    "        if ((var_existPSSM == \"\") or (not os.path.exists(var_existPSSM))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            pssmdir = var_outputdir + str(ts) + \"_pssm/\"\n",
    "            if not os.path.exists(pssmdir):\n",
    "                os.makedirs(pssmdir)\n",
    "            process_input_train(input_var + \"processed_deeploc_train_S_seq\", pssmdir)\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, pssmdir, var_outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, var_existPSSM, var_outputdir, foldnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "associate-hearts",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing 0th fold\n",
      "WARNING:tensorflow:From C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1000, 25)     0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 180)    223560      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000, 180)    720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 180)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1000, 180)    0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 180)    390960      lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000, 180)    720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 180)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1000, 180)    0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 181)    0           lambda_3[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 41, 180)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1000, 25)     0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 180)    223560      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000, 180)    720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 180)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1000, 180)    0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 180)    390960      lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000, 180)    720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 180)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1000, 180)    0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 181)    0           lambda_3[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 41, 180)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 141s 8ms/step - loss: 0.7218 - accuracy: 0.7187 - val_loss: 0.6630 - val_accuracy: 0.8265\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82650, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66300, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.6338 - accuracy: 0.8203 - val_loss: 0.6117 - val_accuracy: 0.8236\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.82650\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66300 to 0.61173, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 108s 6ms/step - loss: 0.5841 - accuracy: 0.8565 - val_loss: 0.5681 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82650 to 0.86724, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.61173 to 0.56812, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 109s 6ms/step - loss: 0.5499 - accuracy: 0.8785 - val_loss: 0.5288 - val_accuracy: 0.8802\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86724 to 0.88020, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56812 to 0.52881, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 109s 6ms/step - loss: 0.5232 - accuracy: 0.8906 - val_loss: 0.5030 - val_accuracy: 0.8958\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88020 to 0.89579, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52881 to 0.50300, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.4985 - accuracy: 0.8986 - val_loss: 0.4866 - val_accuracy: 0.9026\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89579 to 0.90262, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50300 to 0.48656, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.4755 - accuracy: 0.9065 - val_loss: 0.4595 - val_accuracy: 0.9099\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90262 to 0.90990, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48656 to 0.45951, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.4540 - accuracy: 0.9117 - val_loss: 0.4538 - val_accuracy: 0.9121\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90990 to 0.91215, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45951 to 0.45382, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.4345 - accuracy: 0.9158 - val_loss: 0.4277 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91215 to 0.91493, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45382 to 0.42770, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 108s 6ms/step - loss: 0.4154 - accuracy: 0.9199 - val_loss: 0.4112 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91493 to 0.91640, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42770 to 0.41117, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 108s 6ms/step - loss: 0.3971 - accuracy: 0.9234 - val_loss: 0.4072 - val_accuracy: 0.9202\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91640 to 0.92020, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41117 to 0.40723, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 121s 7ms/step - loss: 0.3793 - accuracy: 0.9278 - val_loss: 0.3799 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92020 to 0.92401, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40723 to 0.37991, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 109s 6ms/step - loss: 0.3631 - accuracy: 0.9306 - val_loss: 0.3784 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92401 to 0.92434, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37991 to 0.37842, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 108s 6ms/step - loss: 0.3464 - accuracy: 0.9346 - val_loss: 0.3563 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92434 to 0.92761, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37842 to 0.35634, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.3318 - accuracy: 0.9373 - val_loss: 0.3402 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92761 to 0.93010, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35634 to 0.34018, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 108s 6ms/step - loss: 0.3171 - accuracy: 0.9392 - val_loss: 0.3330 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93010\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34018 to 0.33304, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 109s 6ms/step - loss: 0.3038 - accuracy: 0.9420 - val_loss: 0.3293 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93010\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33304 to 0.32933, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.2913 - accuracy: 0.9441 - val_loss: 0.3210 - val_accuracy: 0.9254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93010\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32933 to 0.32101, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 109s 6ms/step - loss: 0.2785 - accuracy: 0.9469 - val_loss: 0.3326 - val_accuracy: 0.9235\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93010\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32101\n",
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 116s 7ms/step - loss: 0.2682 - accuracy: 0.9484 - val_loss: 0.3042 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93010\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32101 to 0.30424, saving model to D:/mulocdeep/lv1_result3/fold0_big_lv1_loss-weights.hdf5\n",
      "doing 1th fold\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1000, 25)     0           dropout_6[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 180)    223560      lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1000, 180)    720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 180)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1000, 180)    0           dropout_7[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 180)    390960      lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 180)    720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1000, 180)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1000, 180)    0           dropout_8[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1000, 181)    0           lambda_6[0][0]                   \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 41, 180)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1000, 25)     0           dropout_6[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 180)    223560      lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1000, 180)    720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 180)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1000, 180)    0           dropout_7[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 180)    390960      lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 180)    720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1000, 180)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1000, 180)    0           dropout_8[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1000, 181)    0           lambda_6[0][0]                   \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 41, 180)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 127s 7ms/step - loss: 0.7293 - accuracy: 0.7084 - val_loss: 0.6588 - val_accuracy: 0.8146\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81460, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65881, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 120s 7ms/step - loss: 0.6335 - accuracy: 0.8233 - val_loss: 0.6251 - val_accuracy: 0.8430\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81460 to 0.84303, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.65881 to 0.62512, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 123s 7ms/step - loss: 0.5806 - accuracy: 0.8615 - val_loss: 0.5705 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84303 to 0.85926, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.62512 to 0.57047, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.5474 - accuracy: 0.8817 - val_loss: 0.5324 - val_accuracy: 0.8799\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85926 to 0.87992, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57047 to 0.53241, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.5200 - accuracy: 0.8930 - val_loss: 0.5092 - val_accuracy: 0.8855\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87992 to 0.88552, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53241 to 0.50923, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.4949 - accuracy: 0.9012 - val_loss: 0.4880 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88552 to 0.89358, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50923 to 0.48800, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.4721 - accuracy: 0.9084 - val_loss: 0.4735 - val_accuracy: 0.9043\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89358 to 0.90425, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48800 to 0.47355, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.4512 - accuracy: 0.9134 - val_loss: 0.4541 - val_accuracy: 0.9076\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90425 to 0.90757, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47355 to 0.45408, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.4309 - accuracy: 0.9185 - val_loss: 0.4378 - val_accuracy: 0.9082\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90757 to 0.90818, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45408 to 0.43783, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.4114 - accuracy: 0.9231 - val_loss: 0.4254 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90818 to 0.91035, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43783 to 0.42541, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 116s 7ms/step - loss: 0.3923 - accuracy: 0.9276 - val_loss: 0.4058 - val_accuracy: 0.9154\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91035 to 0.91542, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42541 to 0.40582, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.3752 - accuracy: 0.9308 - val_loss: 0.4009 - val_accuracy: 0.9099\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91542\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40582 to 0.40089, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.3580 - accuracy: 0.9339 - val_loss: 0.3803 - val_accuracy: 0.9193\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91542 to 0.91926, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40089 to 0.38031, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.3414 - accuracy: 0.9372 - val_loss: 0.3695 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91926 to 0.92172, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38031 to 0.36946, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.3272 - accuracy: 0.9392 - val_loss: 0.3597 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92172\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36946 to 0.35971, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.3122 - accuracy: 0.9430 - val_loss: 0.3508 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92172\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35971 to 0.35076, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.2986 - accuracy: 0.9446 - val_loss: 0.3395 - val_accuracy: 0.9213\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92172\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35076 to 0.33950, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.2914 - accuracy: 0.9445 - val_loss: 0.3339 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92172\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33950 to 0.33395, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 116s 7ms/step - loss: 0.2776 - accuracy: 0.9474 - val_loss: 0.3331 - val_accuracy: 0.9175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92172\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33395 to 0.33307, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 118s 7ms/step - loss: 0.2645 - accuracy: 0.9496 - val_loss: 0.3154 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92172 to 0.92466, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33307 to 0.31545, saving model to D:/mulocdeep/lv1_result3/fold1_big_lv1_loss-weights.hdf5\n",
      "doing 2th fold\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1000, 25)     0           dropout_11[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 180)    223560      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1000, 180)    720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1000, 180)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1000, 180)    0           dropout_12[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 180)    390960      lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1000, 180)    720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1000, 180)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1000, 180)    0           dropout_13[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 181)    0           lambda_9[0][0]                   \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 41, 180)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1000, 25)     0           dropout_11[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 180)    223560      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1000, 180)    720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1000, 180)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1000, 180)    0           dropout_12[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 180)    390960      lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1000, 180)    720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1000, 180)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1000, 180)    0           dropout_13[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 181)    0           lambda_9[0][0]                   \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 41, 180)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 117s 7ms/step - loss: 0.7267 - accuracy: 0.6973 - val_loss: 0.6652 - val_accuracy: 0.8214\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82140, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66523, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 113s 7ms/step - loss: 0.6322 - accuracy: 0.8201 - val_loss: 0.6175 - val_accuracy: 0.8496\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82140 to 0.84964, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66523 to 0.61748, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 115s 7ms/step - loss: 0.5825 - accuracy: 0.8579 - val_loss: 0.5729 - val_accuracy: 0.8606\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84964 to 0.86057, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.61748 to 0.57293, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 116s 7ms/step - loss: 0.5485 - accuracy: 0.8789 - val_loss: 0.5399 - val_accuracy: 0.8780\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86057 to 0.87801, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57293 to 0.53989, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 116s 7ms/step - loss: 0.5214 - accuracy: 0.8908 - val_loss: 0.5206 - val_accuracy: 0.8896\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87801 to 0.88957, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53989 to 0.52063, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 115s 7ms/step - loss: 0.4961 - accuracy: 0.9004 - val_loss: 0.4864 - val_accuracy: 0.9031\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88957 to 0.90308, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52063 to 0.48644, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 125s 7ms/step - loss: 0.4730 - accuracy: 0.9072 - val_loss: 0.4701 - val_accuracy: 0.9037\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90308 to 0.90371, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48644 to 0.47013, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 121s 7ms/step - loss: 0.4507 - accuracy: 0.9135 - val_loss: 0.4488 - val_accuracy: 0.9089\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90371 to 0.90886, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47013 to 0.44884, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 115s 7ms/step - loss: 0.4302 - accuracy: 0.9187 - val_loss: 0.4310 - val_accuracy: 0.9160\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90886 to 0.91596, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44884 to 0.43100, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 114s 7ms/step - loss: 0.4112 - accuracy: 0.9229 - val_loss: 0.4168 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91596 to 0.91642, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43100 to 0.41679, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 114s 7ms/step - loss: 0.3912 - accuracy: 0.9275 - val_loss: 0.3953 - val_accuracy: 0.9214\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91642 to 0.92140, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41679 to 0.39534, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 116s 7ms/step - loss: 0.3733 - accuracy: 0.9311 - val_loss: 0.3846 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92140\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39534 to 0.38461, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 112s 7ms/step - loss: 0.3575 - accuracy: 0.9338 - val_loss: 0.3722 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92140 to 0.92326, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38461 to 0.37223, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 114s 7ms/step - loss: 0.3422 - accuracy: 0.9363 - val_loss: 0.3611 - val_accuracy: 0.9226\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92326\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37223 to 0.36112, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 115s 7ms/step - loss: 0.3268 - accuracy: 0.9392 - val_loss: 0.3555 - val_accuracy: 0.9235\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92326 to 0.92347, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36112 to 0.35549, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 116s 7ms/step - loss: 0.3123 - accuracy: 0.9420 - val_loss: 0.3399 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92347\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35549 to 0.33991, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 116s 7ms/step - loss: 0.2992 - accuracy: 0.9444 - val_loss: 0.3357 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92347 to 0.92486, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33991 to 0.33569, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 121s 7ms/step - loss: 0.2868 - accuracy: 0.9466 - val_loss: 0.3203 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92486 to 0.92740, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33569 to 0.32028, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17214/17214 [==============================] - 117s 7ms/step - loss: 0.2748 - accuracy: 0.9485 - val_loss: 0.3153 - val_accuracy: 0.9255\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92740\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32028 to 0.31533, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 117s 7ms/step - loss: 0.2630 - accuracy: 0.9508 - val_loss: 0.3070 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92740 to 0.92761, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31533 to 0.30698, saving model to D:/mulocdeep/lv1_result3/fold2_big_lv1_loss-weights.hdf5\n",
      "doing 3th fold\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1000, 25)     0           dropout_16[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1000, 180)    223560      lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1000, 180)    720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1000, 180)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1000, 180)    0           dropout_17[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1000, 180)    390960      lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1000, 180)    720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1000, 180)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1000, 180)    0           dropout_18[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1000, 181)    0           lambda_12[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 41, 180)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1000, 25)     0           dropout_16[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1000, 180)    223560      lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1000, 180)    720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1000, 180)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1000, 180)    0           dropout_17[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1000, 180)    390960      lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1000, 180)    720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1000, 180)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1000, 180)    0           dropout_18[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1000, 181)    0           lambda_12[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 41, 180)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 120s 7ms/step - loss: 0.7236 - accuracy: 0.7199 - val_loss: 0.6629 - val_accuracy: 0.8073\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80726, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66286, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 116s 7ms/step - loss: 0.6333 - accuracy: 0.8220 - val_loss: 0.6138 - val_accuracy: 0.8391\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80726 to 0.83915, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66286 to 0.61376, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 115s 7ms/step - loss: 0.5821 - accuracy: 0.8586 - val_loss: 0.5571 - val_accuracy: 0.8680\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83915 to 0.86795, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.61376 to 0.55715, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 116s 7ms/step - loss: 0.5486 - accuracy: 0.8787 - val_loss: 0.5247 - val_accuracy: 0.8918\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86795 to 0.89185, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55715 to 0.52472, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 116s 7ms/step - loss: 0.5209 - accuracy: 0.8916 - val_loss: 0.5114 - val_accuracy: 0.8901\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89185\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52472 to 0.51137, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 115s 7ms/step - loss: 0.4962 - accuracy: 0.9002 - val_loss: 0.4832 - val_accuracy: 0.9026\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89185 to 0.90260, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51137 to 0.48324, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 130s 8ms/step - loss: 0.4736 - accuracy: 0.9067 - val_loss: 0.4772 - val_accuracy: 0.9039\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90260 to 0.90394, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48324 to 0.47722, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 114s 7ms/step - loss: 0.4517 - accuracy: 0.9132 - val_loss: 0.4423 - val_accuracy: 0.9132\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90394 to 0.91318, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47722 to 0.44233, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 114s 7ms/step - loss: 0.4311 - accuracy: 0.9190 - val_loss: 0.4284 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91318 to 0.91420, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44233 to 0.42836, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 115s 7ms/step - loss: 0.4117 - accuracy: 0.9230 - val_loss: 0.4086 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91420 to 0.91700, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42836 to 0.40859, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 116s 7ms/step - loss: 0.3938 - accuracy: 0.9268 - val_loss: 0.3918 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91700 to 0.92223, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40859 to 0.39185, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 117s 7ms/step - loss: 0.3763 - accuracy: 0.9303 - val_loss: 0.3882 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92223\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39185 to 0.38816, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 114s 7ms/step - loss: 0.3583 - accuracy: 0.9340 - val_loss: 0.3696 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92223 to 0.92584, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38816 to 0.36961, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 120s 7ms/step - loss: 0.3438 - accuracy: 0.9362 - val_loss: 0.3520 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92584 to 0.92592, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36961 to 0.35196, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 125s 7ms/step - loss: 0.3285 - accuracy: 0.9390 - val_loss: 0.3487 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92592 to 0.92649, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35196 to 0.34866, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 117s 7ms/step - loss: 0.3140 - accuracy: 0.9415 - val_loss: 0.3326 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92649 to 0.92872, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34866 to 0.33260, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 116s 7ms/step - loss: 0.3018 - accuracy: 0.9434 - val_loss: 0.3233 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92872 to 0.92888, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33260 to 0.32326, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 117s 7ms/step - loss: 0.2889 - accuracy: 0.9454 - val_loss: 0.3142 - val_accuracy: 0.9310\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92888 to 0.93103, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32326 to 0.31424, saving model to D:/mulocdeep/lv1_result3/fold3_big_lv1_loss-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 116s 7ms/step - loss: 0.2771 - accuracy: 0.9474 - val_loss: 0.3155 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93103\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31424\n",
      "epoch 19\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 116s 7ms/step - loss: 0.2659 - accuracy: 0.9495 - val_loss: 0.3170 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93103\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31424\n",
      "doing 4th fold\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1000, 25)     0           dropout_21[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1000, 180)    223560      lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1000, 180)    720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 1000, 180)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1000, 180)    0           dropout_22[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1000, 180)    390960      lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1000, 180)    720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1000, 180)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1000, 180)    0           dropout_23[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1000, 181)    0           lambda_15[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 41, 180)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1000, 25)     0           dropout_21[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1000, 180)    223560      lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1000, 180)    720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 1000, 180)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1000, 180)    0           dropout_22[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1000, 180)    390960      lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1000, 180)    720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1000, 180)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1000, 180)    0           dropout_23[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1000, 181)    0           lambda_15[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 41, 180)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 129s 8ms/step - loss: 0.7258 - accuracy: 0.7182 - val_loss: 0.6722 - val_accuracy: 0.8110\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81100, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67223, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 120s 7ms/step - loss: 0.6354 - accuracy: 0.8191 - val_loss: 0.6240 - val_accuracy: 0.8133\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81100 to 0.81326, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.67223 to 0.62398, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.5862 - accuracy: 0.8558 - val_loss: 0.5628 - val_accuracy: 0.8626\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81326 to 0.86256, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.62398 to 0.56282, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 116s 7ms/step - loss: 0.5505 - accuracy: 0.8804 - val_loss: 0.5335 - val_accuracy: 0.8774\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86256 to 0.87743, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56282 to 0.53348, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 131s 8ms/step - loss: 0.5224 - accuracy: 0.8925 - val_loss: 0.5083 - val_accuracy: 0.8949\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87743 to 0.89488, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53348 to 0.50826, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 113s 7ms/step - loss: 0.4981 - accuracy: 0.9003 - val_loss: 0.4892 - val_accuracy: 0.8988\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89488 to 0.89879, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50826 to 0.48921, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 112s 7ms/step - loss: 0.4757 - accuracy: 0.9057 - val_loss: 0.4708 - val_accuracy: 0.9014\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89879 to 0.90137, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48921 to 0.47085, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 112s 7ms/step - loss: 0.4538 - accuracy: 0.9123 - val_loss: 0.4492 - val_accuracy: 0.9071\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90137 to 0.90705, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47085 to 0.44918, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 113s 7ms/step - loss: 0.4336 - accuracy: 0.9170 - val_loss: 0.4317 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90705 to 0.90967, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44918 to 0.43167, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.4137 - accuracy: 0.9217 - val_loss: 0.4179 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90967 to 0.91064, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43167 to 0.41786, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.3951 - accuracy: 0.9258 - val_loss: 0.4001 - val_accuracy: 0.9188\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91064 to 0.91878, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41786 to 0.40008, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 111s 6ms/step - loss: 0.3789 - accuracy: 0.9281 - val_loss: 0.3845 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91878 to 0.92076, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40008 to 0.38451, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.3611 - accuracy: 0.9320 - val_loss: 0.3720 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92076 to 0.92209, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38451 to 0.37201, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.3452 - accuracy: 0.9352 - val_loss: 0.3561 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92209 to 0.92519, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37201 to 0.35606, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 112s 7ms/step - loss: 0.3300 - accuracy: 0.9385 - val_loss: 0.3567 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92519\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35606\n",
      "epoch 15\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 112s 7ms/step - loss: 0.3160 - accuracy: 0.9401 - val_loss: 0.3329 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92519\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35606 to 0.33289, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 112s 7ms/step - loss: 0.3017 - accuracy: 0.9436 - val_loss: 0.3325 - val_accuracy: 0.9210\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92519\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33289 to 0.33252, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 111s 6ms/step - loss: 0.2895 - accuracy: 0.9451 - val_loss: 0.3257 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92519\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33252 to 0.32569, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 115s 7ms/step - loss: 0.2777 - accuracy: 0.9471 - val_loss: 0.3122 - val_accuracy: 0.9273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92519 to 0.92729, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32569 to 0.31221, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 111s 7ms/step - loss: 0.2661 - accuracy: 0.9489 - val_loss: 0.3102 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92729\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31221 to 0.31019, saving model to D:/mulocdeep/lv1_result3/fold4_big_lv1_loss-weights.hdf5\n",
      "doing 5th fold\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1000, 25)     0           dropout_26[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1000, 180)    223560      lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1000, 180)    720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1000, 180)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1000, 180)    0           dropout_27[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1000, 180)    390960      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1000, 180)    720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1000, 180)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1000, 180)    0           dropout_28[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1000, 181)    0           lambda_18[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 41, 180)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1000, 25)     0           dropout_26[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1000, 180)    223560      lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1000, 180)    720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1000, 180)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1000, 180)    0           dropout_27[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1000, 180)    390960      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1000, 180)    720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1000, 180)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1000, 180)    0           dropout_28[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1000, 181)    0           lambda_18[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 41, 180)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 123s 7ms/step - loss: 0.7214 - accuracy: 0.7314 - val_loss: 0.6738 - val_accuracy: 0.8172\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81721, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67378, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 130s 8ms/step - loss: 0.6291 - accuracy: 0.8320 - val_loss: 0.6280 - val_accuracy: 0.8254\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81721 to 0.82541, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.67378 to 0.62796, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.5844 - accuracy: 0.8575 - val_loss: 0.5713 - val_accuracy: 0.8699\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82541 to 0.86990, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.62796 to 0.57126, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.5494 - accuracy: 0.8789 - val_loss: 0.5418 - val_accuracy: 0.8835\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86990 to 0.88348, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57126 to 0.54177, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 114s 7ms/step - loss: 0.5206 - accuracy: 0.8922 - val_loss: 0.5088 - val_accuracy: 0.8917\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88348 to 0.89172, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54177 to 0.50883, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 114s 7ms/step - loss: 0.4966 - accuracy: 0.8995 - val_loss: 0.4921 - val_accuracy: 0.8961\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89172 to 0.89607, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50883 to 0.49207, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 114s 7ms/step - loss: 0.4727 - accuracy: 0.9074 - val_loss: 0.4685 - val_accuracy: 0.9032\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89607 to 0.90316, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49207 to 0.46846, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 114s 7ms/step - loss: 0.4512 - accuracy: 0.9120 - val_loss: 0.4524 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90316 to 0.90705, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46846 to 0.45238, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 115s 7ms/step - loss: 0.4310 - accuracy: 0.9172 - val_loss: 0.4341 - val_accuracy: 0.9085\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90705 to 0.90850, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45238 to 0.43406, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 114s 7ms/step - loss: 0.4118 - accuracy: 0.9215 - val_loss: 0.4149 - val_accuracy: 0.9125\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90850 to 0.91247, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43406 to 0.41487, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 114s 7ms/step - loss: 0.3929 - accuracy: 0.9255 - val_loss: 0.3991 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91247 to 0.91708, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41487 to 0.39913, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.3751 - accuracy: 0.9294 - val_loss: 0.3913 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91708\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39913 to 0.39128, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 114s 7ms/step - loss: 0.3589 - accuracy: 0.9334 - val_loss: 0.3810 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91708\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39128 to 0.38097, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 115s 7ms/step - loss: 0.3427 - accuracy: 0.9355 - val_loss: 0.3651 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91708 to 0.91836, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38097 to 0.36508, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 115s 7ms/step - loss: 0.3278 - accuracy: 0.9388 - val_loss: 0.3564 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91836 to 0.91913, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36508 to 0.35637, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 113s 7ms/step - loss: 0.3139 - accuracy: 0.9408 - val_loss: 0.3549 - val_accuracy: 0.9177\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91913\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35637 to 0.35494, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 115s 7ms/step - loss: 0.3009 - accuracy: 0.9436 - val_loss: 0.3395 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91913 to 0.92267, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35494 to 0.33945, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 113s 7ms/step - loss: 0.2869 - accuracy: 0.9464 - val_loss: 0.3336 - val_accuracy: 0.9187\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92267\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33945 to 0.33362, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 113s 7ms/step - loss: 0.2753 - accuracy: 0.9485 - val_loss: 0.3162 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92267 to 0.92374, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33362 to 0.31618, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 126s 7ms/step - loss: 0.2656 - accuracy: 0.9491 - val_loss: 0.3170 - val_accuracy: 0.9251\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92374 to 0.92511, saving model to D:/mulocdeep/lv1_result3/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31618\n",
      "doing 6th fold\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1000, 25)     0           dropout_31[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1000, 180)    223560      lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1000, 180)    720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 1000, 180)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1000, 180)    0           dropout_32[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1000, 180)    390960      lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1000, 180)    720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 1000, 180)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1000, 180)    0           dropout_33[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 181)    0           lambda_21[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 41, 180)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1000, 25)     0           dropout_31[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1000, 180)    223560      lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1000, 180)    720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 1000, 180)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1000, 180)    0           dropout_32[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1000, 180)    390960      lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1000, 180)    720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 1000, 180)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1000, 180)    0           dropout_33[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 181)    0           lambda_21[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 41, 180)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.7293 - accuracy: 0.7110 - val_loss: 0.6728 - val_accuracy: 0.8202\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82015, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67283, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 113s 7ms/step - loss: 0.6346 - accuracy: 0.8294 - val_loss: 0.6040 - val_accuracy: 0.8551\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82015 to 0.85515, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.67283 to 0.60398, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 110s 6ms/step - loss: 0.5869 - accuracy: 0.8575 - val_loss: 0.5602 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85515 to 0.86692, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.60398 to 0.56020, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 109s 6ms/step - loss: 0.5520 - accuracy: 0.8771 - val_loss: 0.5243 - val_accuracy: 0.8879\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86692 to 0.88787, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56020 to 0.52433, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 106s 6ms/step - loss: 0.5240 - accuracy: 0.8894 - val_loss: 0.5030 - val_accuracy: 0.8952\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88787 to 0.89517, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52433 to 0.50298, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 118s 7ms/step - loss: 0.4986 - accuracy: 0.8993 - val_loss: 0.4804 - val_accuracy: 0.9025\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89517 to 0.90251, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50298 to 0.48044, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 102s 6ms/step - loss: 0.4761 - accuracy: 0.9059 - val_loss: 0.4716 - val_accuracy: 0.9027\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90251 to 0.90267, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48044 to 0.47163, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 102s 6ms/step - loss: 0.4541 - accuracy: 0.9118 - val_loss: 0.4475 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90267 to 0.91109, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47163 to 0.44750, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 103s 6ms/step - loss: 0.4341 - accuracy: 0.9163 - val_loss: 0.4280 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91109 to 0.91728, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44750 to 0.42798, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 102s 6ms/step - loss: 0.4141 - accuracy: 0.9214 - val_loss: 0.4145 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91728\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42798 to 0.41454, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 102s 6ms/step - loss: 0.3960 - accuracy: 0.9253 - val_loss: 0.4042 - val_accuracy: 0.9181\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91728 to 0.91808, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41454 to 0.40415, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 101s 6ms/step - loss: 0.3790 - accuracy: 0.9288 - val_loss: 0.3860 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91808\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40415 to 0.38596, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 101s 6ms/step - loss: 0.3623 - accuracy: 0.9320 - val_loss: 0.3724 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91808 to 0.92251, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38596 to 0.37239, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 101s 6ms/step - loss: 0.3467 - accuracy: 0.9350 - val_loss: 0.3616 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92251 to 0.92558, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37239 to 0.36163, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 105s 6ms/step - loss: 0.3314 - accuracy: 0.9373 - val_loss: 0.3502 - val_accuracy: 0.9255\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92558\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36163 to 0.35016, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 104s 6ms/step - loss: 0.3170 - accuracy: 0.9403 - val_loss: 0.3405 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92558 to 0.92729, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35016 to 0.34053, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 102s 6ms/step - loss: 0.3046 - accuracy: 0.9424 - val_loss: 0.3314 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92729\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34053 to 0.33140, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 102s 6ms/step - loss: 0.2918 - accuracy: 0.9446 - val_loss: 0.3416 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92729\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.33140\n",
      "epoch 18\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 101s 6ms/step - loss: 0.2795 - accuracy: 0.9467 - val_loss: 0.3131 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92729 to 0.92925, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_acc-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from 0.33140 to 0.31310, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 101s 6ms/step - loss: 0.2683 - accuracy: 0.9490 - val_loss: 0.3046 - val_accuracy: 0.9291\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92925\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31310 to 0.30460, saving model to D:/mulocdeep/lv1_result3/fold6_big_lv1_loss-weights.hdf5\n",
      "doing 7th fold\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1000, 25)     0           dropout_36[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1000, 180)    223560      lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 1000, 180)    720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1000, 180)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1000, 180)    0           dropout_37[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1000, 180)    390960      lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 1000, 180)    720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1000, 180)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1000, 180)    0           dropout_38[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1000, 181)    0           lambda_24[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 41, 180)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1000, 25)     0           dropout_36[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1000, 180)    223560      lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 1000, 180)    720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1000, 180)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1000, 180)    0           dropout_37[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1000, 180)    390960      lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 1000, 180)    720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1000, 180)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1000, 180)    0           dropout_38[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1000, 181)    0           lambda_24[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 41, 180)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,288,713\n",
      "Trainable params: 1,287,631\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 115s 7ms/step - loss: 0.7340 - accuracy: 0.7012 - val_loss: 0.6611 - val_accuracy: 0.8203\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82028, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66111, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 106s 6ms/step - loss: 0.6346 - accuracy: 0.8309 - val_loss: 0.6189 - val_accuracy: 0.8411\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82028 to 0.84111, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66111 to 0.61894, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 106s 6ms/step - loss: 0.5861 - accuracy: 0.8568 - val_loss: 0.5584 - val_accuracy: 0.8697\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84111 to 0.86968, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.61894 to 0.55844, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.5508 - accuracy: 0.8781 - val_loss: 0.5198 - val_accuracy: 0.8922\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86968 to 0.89217, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55844 to 0.51985, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 105s 6ms/step - loss: 0.5239 - accuracy: 0.8898 - val_loss: 0.5048 - val_accuracy: 0.8961\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89217 to 0.89609, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51985 to 0.50476, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 103s 6ms/step - loss: 0.4987 - accuracy: 0.8987 - val_loss: 0.4788 - val_accuracy: 0.9046\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89609 to 0.90462, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50476 to 0.47878, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 103s 6ms/step - loss: 0.4760 - accuracy: 0.9054 - val_loss: 0.4663 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90462 to 0.90771, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47878 to 0.46625, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 102s 6ms/step - loss: 0.4544 - accuracy: 0.9105 - val_loss: 0.4475 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90771\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46625 to 0.44752, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 103s 6ms/step - loss: 0.4334 - accuracy: 0.9162 - val_loss: 0.4355 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90771 to 0.91194, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44752 to 0.43548, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 103s 6ms/step - loss: 0.4137 - accuracy: 0.9210 - val_loss: 0.4128 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91194 to 0.91996, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43548 to 0.41281, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 103s 6ms/step - loss: 0.3958 - accuracy: 0.9241 - val_loss: 0.3965 - val_accuracy: 0.9186\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91996\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41281 to 0.39650, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 102s 6ms/step - loss: 0.3781 - accuracy: 0.9280 - val_loss: 0.3848 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91996 to 0.92277, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39650 to 0.38477, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 112s 7ms/step - loss: 0.3614 - accuracy: 0.9313 - val_loss: 0.3688 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92277 to 0.92455, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38477 to 0.36882, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 102s 6ms/step - loss: 0.3453 - accuracy: 0.9346 - val_loss: 0.3574 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92455\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36882 to 0.35737, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 103s 6ms/step - loss: 0.3309 - accuracy: 0.9363 - val_loss: 0.3550 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92455\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35737 to 0.35499, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 103s 6ms/step - loss: 0.3176 - accuracy: 0.9387 - val_loss: 0.3420 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92455\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35499 to 0.34200, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 105s 6ms/step - loss: 0.3035 - accuracy: 0.9413 - val_loss: 0.3259 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92455 to 0.92680, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34200 to 0.32588, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 103s 6ms/step - loss: 0.2917 - accuracy: 0.9429 - val_loss: 0.3180 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92680 to 0.92929, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32588 to 0.31796, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 102s 6ms/step - loss: 0.2774 - accuracy: 0.9467 - val_loss: 0.3147 - val_accuracy: 0.9276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92929\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31796 to 0.31473, saving model to D:/mulocdeep/lv1_result3/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 102s 6ms/step - loss: 0.2664 - accuracy: 0.9488 - val_loss: 0.3184 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92929\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31473\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-accused",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
