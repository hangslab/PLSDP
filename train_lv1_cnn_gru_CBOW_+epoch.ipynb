{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "import math\n",
    "from itertools import product\n",
    "import argparse\n",
    "import sys\n",
    "from utils_cnn_CS import *\n",
    "import calendar\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "damaged-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eachseq(seq,pssmfile,mask_seq,new_pssms):\n",
    "    if os.path.exists(pssmfile):  #如果pssm文件存在\n",
    "        print(\"found \" + pssmfile + \"\\n\")  #输出找到pssm文件+换行\n",
    "        pssm = readPSSM(pssmfile)  #读取pssm文件\n",
    "    else:  #否则\n",
    "        print(\"using Blosum62\\n\")  #输出使用Blosum62+换行\n",
    "        #pssm = convertSampleToBlosum62(seq)  #把Blosum62矩阵当作pssm用\n",
    "        pssm = convertSampleToCBOW(seq)\n",
    "    pssm = pssm.astype(float)  #对pssm的数据类型转换为浮点型\n",
    "    PhyChem = convertSampleToPhysicsVector_pca(seq)  #将样本转化为物理向量\n",
    "    pssm = np.concatenate((PhyChem, pssm), axis=1)  #物化指标和pssm对应行进行数组拼接\n",
    "    seql = len(seq)   #序列长度  \n",
    "    if seql <= 1000:  #如果序列长度小于等于1000\n",
    "        padnum = 1000 - seql  #pad大小为1000-序列长度\n",
    "        padmatrix = np.zeros([padnum, 25])  #pad矩阵为行数为padnum，列数为25的全0矩阵，即用0填充不足的地方\n",
    "        pssm = np.concatenate((pssm, padmatrix), axis=0)  #物化指标和pssm进行数组拼接 \n",
    "        new_pssms.append(pssm)  #新的pssm空列表中添加pssm矩阵\n",
    "        mask_seq.append(gen_mask_mat(seql, padnum))  #mask序列空列表添加gen_mask矩阵，序列长度为行数，padnum为列数？？？\n",
    "    else:  #如果序列长度大于1000\n",
    "        pssm = np.concatenate((pssm[0:500, :], pssm[seql - 500:seql, :]), axis=0)  #pssm矩阵为前500行和后500行矩阵的拼接\n",
    "        new_pssms.append(pssm)  #新的pssm空列表中添加pssm矩阵\n",
    "        mask_seq.append(gen_mask_mat(1000, 0))  #mask序列空列表添加1000行0列的？？？gen_mask矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metric-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpad(seqfile, labelfile, pssmdir=\"\", npzfile = \"\"): #定义endpad(序列文件，标签文件，pssm路径，npz文件)\n",
    "    if not os.path.exists(npzfile):  #如果npz文件不存在，建立新的pssm空列表，标签空列表，mask序列空列表，id空列表\n",
    "        new_pssms = []\n",
    "        labels = []\n",
    "        mask_seq = []\n",
    "        ids=[]\n",
    "        seqs=[]\n",
    "        f = open(seqfile, \"r\")  #f为打开序列文件\n",
    "        f2 = open(labelfile, \"r\")  #f2为打开标签文件\n",
    "        line = f.readline()  #读取序列文件的第一行\n",
    "        while line != '':\n",
    "            pssmfile = pssmdir + line[1:].strip() + \"_pssm.txt\"  #pssm文件名=pssm地址+id名+_pssm.txt\n",
    "            if line[0] == '>':  #如果该行第一个字符为>\n",
    "                id = line.strip()[1:]  #id为去掉>的字符\n",
    "                ids.append(id)   #在id空列表中添加id\n",
    "            label = f2.readline().strip()  #标签为f2（标签文件）中去掉首尾空格的内容\n",
    "            labels.append(label)  #在标签空列表中添加标签\n",
    "            seq = f.readline().strip()  #第一次seq为第2行的内容，实际seq为>行的下一行\n",
    "            #seql = len(seq)   #序列长度  \n",
    "            process_eachseq(seq,pssmfile,mask_seq,new_pssms)\n",
    "            line = f.readline()  #继续读取下一行，即>行\n",
    "        x = np.array(new_pssms)  #把new_pssms列表变为数组，赋给x\n",
    "        y = [convertlabels_to_categorical(i) for i in labels]  #把标签列表转化为类别(i)\n",
    "        y = np.array(y)  #再把类别转化为数组\n",
    "        mask = np.array(mask_seq)  #把mask_seq（标注的序列？）转化为数组\n",
    "        np.savez(npzfile, x=x, y=y, mask=mask, ids=ids)  #保存多个数组到同一个文件中,保存格式是.npz\n",
    "        return [x, y, mask,ids]  #返回pssm矩阵，类别，标注序列，名字id\n",
    "    else:  #如果上述都存在，直接转化为数组\n",
    "        mask = np.load(npzfile)['mask']\n",
    "        x = np.load(npzfile)['x']\n",
    "        y = np.load(npzfile)['y']\n",
    "        ids=np.load(npzfile)['ids']\n",
    "        return [x, y, mask,ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "warming-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MULocDeep(lv1_dir,lv2_dir,pssm_dir,output_dir,foldnum):\n",
    "    # get small data\n",
    "    [train_x, train_y, train_mask, train_ids] = endpad(\n",
    "        lv2_dir+\"lv2_train_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv2_dir+\"lv2_train_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv2_train_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    [val_x, val_y, val_mask,val_ids] = endpad(\n",
    "        lv2_dir+\"lv2_val_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv2_dir+\"lv2_val_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv2_val_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "\n",
    "    # get big data 训练10分类的多分类\n",
    "    [train_x_big, train_y_big, train_mask_big, train_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv1_train_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    [val_x_big, val_y_big, val_mask_big, val_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv1_val_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model_big, model_small = singlemodel(train_x)  #模型为singlemodel\n",
    "\n",
    "    filepath_acc_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_acc_small_lv2 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_small_lv2_acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_loss_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_loss-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_loss_small_lv2 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_small_lv2_loss-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "    checkpoint_acc_big_lev1 = ModelCheckpoint(filepath_acc_big_lv1, monitor='val_accuracy', save_best_only=True,\n",
    "                                          mode='max',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "\n",
    "    checkpoint_acc_small_lev2 = ModelCheckpoint(filepath_acc_small_lv2, monitor='val_lev2_accuracy', save_best_only=True,\n",
    "                                          mode='max',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    checkpoint_loss_big_lev1 = ModelCheckpoint(filepath_loss_big_lv1, monitor='val_loss', save_best_only=True,\n",
    "                                          mode='min',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    checkpoint_loss_small_lev2 = ModelCheckpoint(filepath_loss_small_lv2, monitor='val_lev2_loss', save_best_only=True,\n",
    "                                          mode='min',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    \n",
    "    for i in range(80):\n",
    "        # train small model\n",
    "        print(\"epoch \"+str(i)+\"\\n\")\n",
    "        '''fitHistory_batch_small = model_small.fit([train_x, train_mask.reshape(-1, 1000, 1)],\n",
    "                                                 [train_y,getTrue4out1(train_y)],\n",
    "                                                 batch_size=batch_size, epochs=1,\n",
    "                                                 validation_data=(\n",
    "                                                 [val_x, val_mask.reshape(-1, 1000, 1)], [val_y,getTrue4out1(val_y)]),\n",
    "                                                 callbacks=[checkpoint_acc_small_lev2,checkpoint_loss_small_lev2],verbose=1)'''\n",
    "        \n",
    "        # train big model  \n",
    "        fitHistory_batch_big = model_big.fit([train_x_big, train_mask_big.reshape(-1, 1000, 1)],\n",
    "                                             [getTrue4out1(train_y_big)],  #为何大模型没有train_y_big\n",
    "                                             batch_size=batch_size, epochs=1,  #等于1？？\n",
    "                                             validation_data=(\n",
    "                                             [val_x_big, val_mask_big.reshape(-1, 1000, 1)], [getTrue4out1(val_y_big)]),  #也没有val_y_big\n",
    "                                             callbacks=[checkpoint_acc_big_lev1,checkpoint_loss_big_lev1], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alert-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_var(input_var,pssm_dir,output_dir,foldnum):\n",
    "    # get small data\n",
    "    [train_x,train_y,train_mask,train_ids]=endpad(input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_seq\",\n",
    "                                        input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_label\",\n",
    "                                        pssm_dir,\n",
    "                                        \"D:/deeploc/deeploc_40nr_8folds/train_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    [val_x,val_y,val_mask,val_ids]=endpad(input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_seq\",\n",
    "                                  input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_label\",\n",
    "                                  pssm_dir,\n",
    "                                  \"D:/deeploc/deeploc_40nr_8folds/val_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model = var_model(train_x)   #这里的模型是var_model\n",
    "\n",
    "    filepath_acc = output_dir+\"fold\" + str(foldnum) + \"acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "    checkpoint_acc = ModelCheckpoint(filepath_acc, monitor='val_accuracy', save_best_only=True, mode='max',\n",
    "                                 save_weights_only=True, verbose=1)\n",
    "    fitHistory_batch = model.fit([train_x,train_mask.reshape(-1,1000,1)],getTrue4out1(train_y),\n",
    "                                 batch_size=batch_size, epochs=20,\n",
    "                                 validation_data=([val_x,val_mask.reshape(-1,1000,1)], getTrue4out1(val_y)),\n",
    "                                 callbacks=[checkpoint_acc],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spiritual-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''我们常常可以把argparse的使用简化成下面四个步骤\n",
    "       1：import argparse\n",
    "       2：parser = argparse.ArgumentParser()\n",
    "       3：parser.add_argument()\n",
    "       4：parser.parse_args()\n",
    "       上面四个步骤解释如下：首先导入该模块；然后创建一个解析对象；然后向该对象中添加你要关注的命令行参数和选项，\n",
    "       每一个add_argument方法对应一个你要关注的参数或选项；最后调用parse_args()方法进行解析；解析成功之后即可使用'''\n",
    "    \n",
    "def main():\n",
    "    #加default\n",
    "    # description= 这个参数简要描述这个程度做什么以及怎么做\n",
    "    parser=argparse.ArgumentParser(\n",
    "        description='MULocDeep: interpretable protein localization classifier at sub-cellular and sub-organellar levels')\n",
    "    #MULocDeep_model  UniLoc-train-20nr\n",
    "    #--lv1_input_dir/--lv2_input_dir 亚细胞训练数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--lv1_input_dir', dest='lv1_dir', type=str, \n",
    "                        default=\"D:/mulocdeep/mul_data\",\n",
    "                        help='sub-cellular training data, contains 8 folds protein sequences and labels', required=False)\n",
    "    parser.add_argument('--lv2_input_dir', dest='lv2_dir', type=str,\n",
    "                       default=\"D:/mulocdeep/mul_data\",\n",
    "                       help='sub-cellular training data, contains 8 folds protein sequences and labels', required=False)\n",
    "    #--MULocDeep_model 添加它来训练MULocDeep模型，否则训练一个var模型\n",
    "    parser.add_argument('--MULocDeep_model', dest='modeltype', action='store_false',  #触发，store_true会触发DeepLoc\n",
    "                        #如果是store_false,则默认值是True，如果是store_true,则默认值是False  \n",
    "                        help='Add this to train the MULocDeep model, otherwise train a variant model', required=False)\n",
    "    #--model_output 受过训练的模型存储的目录的名称  需自己添加\n",
    "    parser.add_argument('--model_output', dest='outputdir', type=str, \n",
    "                       default=\"D:/mulocdeep/lv1_result11\",\n",
    "                       help='the name of the directory where the trained model stores', required=False)  #由True改成False\n",
    "    \n",
    "    parser.add_argument('-existPSSM', dest='existPSSM', type=str,\n",
    "                        default=\"D:/mulocdeep/mulocdeep_pssm_empty\",\n",
    "                        help='the name of the existing PSSM directory if there is one.', required=False)\n",
    "    \n",
    "    #var_model  deeploc_40nr_8folds\n",
    "    #--input_dir 训练var模型的数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--input_var', dest='var_dir', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_40nr_8folds\",\n",
    "                        help='data for traing the variant model, contains 8 folds protein sequences and labels', required=False)\n",
    "    #改true  并且还需要加一个model_ouput  一个是deeploc  一个是MULocDeep\n",
    "    parser.add_argument('--var_model_output', dest='var_outputdir', type=str, help='the name of the directory where the trained model stores', \n",
    "                        default=\"D:/deeploc/var_model_result1\",\n",
    "                        required=False)  #由True改成False\n",
    "    parser.add_argument('-var_existPSSM', dest='var_existPSSM', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_pssm\",\n",
    "                        help='the name of the existing PSSM directory if there is one.', required=False)\n",
    "    parser.set_defaults(feature=True)\n",
    "    #args = parser.parse_args()   #改\n",
    "    args = parser.parse_known_args()[0]   #jupyter下运行解析需要此代码\n",
    "    model_type=args.modeltype\n",
    "    input_lv1=args.lv1_dir\n",
    "    input_lv2 = args.lv2_dir\n",
    "    outputdir=args.outputdir\n",
    "    existPSSM = args.existPSSM\n",
    "    input_var=args.var_dir\n",
    "    var_outputdir=args.var_outputdir\n",
    "    var_existPSSM = args.var_existPSSM\n",
    "\n",
    "    if model_type==True:\n",
    "        if not input_lv1[len(input_lv1) - 1] == \"/\":\n",
    "            input_lv1 = input_lv1 + \"/\"\n",
    "        if not input_lv2[len(input_lv2) - 1] == \"/\":\n",
    "            input_lv2 = input_lv2 + \"/\"\n",
    "        if not outputdir[len(outputdir) - 1] == \"/\":\n",
    "            outputdir = outputdir + \"/\"\n",
    "        if not os.path.exists(outputdir):\n",
    "            os.mkdir(outputdir)\n",
    "        if existPSSM != \"\":\n",
    "            if not existPSSM[len(existPSSM) - 1] == \"/\":\n",
    "                existPSSM = existPSSM + \"/\"\n",
    "        if ((existPSSM == \"\") or (not os.path.exists(existPSSM))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            pssmdir = outputdir + str(ts) + \"_pssm/\"\n",
    "            if not os.path.exists(pssmdir):\n",
    "                os.makedirs(pssmdir)\n",
    "            process_input_train(input_lv1 + \"lv1_train.txt\", pssmdir)\n",
    "            process_input_train(input_lv2 + \"lv2_train.txt\", pssmdir)\n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, input_lv2, pssmdir, outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, input_lv2, existPSSM, outputdir, foldnum)\n",
    "    elif model_type==False:\n",
    "        if not input_var[len(input_var) - 1] == \"/\":\n",
    "            input_var = input_var + \"/\"\n",
    "        if not var_outputdir[len(var_outputdir) - 1] == \"/\":\n",
    "            var_outputdir = var_outputdir + \"/\"\n",
    "        if not os.path.exists(var_outputdir):\n",
    "            os.mkdir(var_outputdir)\n",
    "        if existPSSM != \"\":\n",
    "            if not var_existPSSM[len(var_existPSSM) - 1] == \"/\":\n",
    "                var_existPSSM = var_existPSSM + \"/\"\n",
    "        if ((var_existPSSM == \"\") or (not os.path.exists(var_existPSSM))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            pssmdir = var_outputdir + str(ts) + \"_pssm/\"\n",
    "            if not os.path.exists(pssmdir):\n",
    "                os.makedirs(pssmdir)\n",
    "            process_input_train(input_var + \"processed_deeploc_train_S_seq\", pssmdir)\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, pssmdir, var_outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, var_existPSSM, var_outputdir, foldnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "associate-hearts",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing 0th fold\n",
      "WARNING:tensorflow:From C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1000, 25)     0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1000, 25)     650         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000, 25)     100         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 25)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1000, 25)     0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1000, 25)     1900        lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000, 25)     100         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 25)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1000, 25)     0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1000, 25)     3150        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1000, 25)     100         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000, 25)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1000, 25)     0           dropout_4[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1000, 25)     5650        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1000, 25)     100         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1000, 25)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1000, 25)     0           dropout_5[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1000, 25)     9400        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1000, 25)     100         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1000, 25)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1000, 25)     0           dropout_6[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1000, 25)     13150       lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 25)     100         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 25)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1000, 25)     0           dropout_7[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 180)    223560      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1000, 180)    720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1000, 180)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1000, 180)    0           dropout_8[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 180)    390960      lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1000, 180)    720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1000, 180)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1000, 180)    0           dropout_9[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 181)    0           lambda_9[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 41, 180)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1000, 25)     0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1000, 25)     650         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000, 25)     100         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 25)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1000, 25)     0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1000, 25)     1900        lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000, 25)     100         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 25)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1000, 25)     0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1000, 25)     3150        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1000, 25)     100         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000, 25)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1000, 25)     0           dropout_4[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1000, 25)     5650        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1000, 25)     100         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1000, 25)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1000, 25)     0           dropout_5[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1000, 25)     9400        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1000, 25)     100         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1000, 25)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1000, 25)     0           dropout_6[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1000, 25)     13150       lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 25)     100         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 25)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1000, 25)     0           dropout_7[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 180)    223560      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1000, 180)    720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1000, 180)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1000, 180)    0           dropout_8[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 180)    390960      lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1000, 180)    720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1000, 180)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1000, 180)    0           dropout_9[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 181)    0           lambda_9[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 41, 180)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 131s 8ms/step - loss: 0.7595 - accuracy: 0.6682 - val_loss: 0.6578 - val_accuracy: 0.7886\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78863, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65775, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 133s 8ms/step - loss: 0.6389 - accuracy: 0.8159 - val_loss: 0.6341 - val_accuracy: 0.8317\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.78863 to 0.83174, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.65775 to 0.63405, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.5927 - accuracy: 0.8444 - val_loss: 0.5699 - val_accuracy: 0.8611\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83174 to 0.86115, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.63405 to 0.56988, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.5602 - accuracy: 0.8700 - val_loss: 0.5401 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86115 to 0.88413, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56988 to 0.54008, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.5349 - accuracy: 0.8826 - val_loss: 0.5213 - val_accuracy: 0.8903\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88413 to 0.89027, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54008 to 0.52132, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 124s 7ms/step - loss: 0.5124 - accuracy: 0.8895 - val_loss: 0.4945 - val_accuracy: 0.8939\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89027 to 0.89387, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52132 to 0.49450, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.4914 - accuracy: 0.8945 - val_loss: 0.4703 - val_accuracy: 0.9011\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89387 to 0.90115, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49450 to 0.47028, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.4723 - accuracy: 0.8991 - val_loss: 0.4619 - val_accuracy: 0.9046\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90115 to 0.90462, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47028 to 0.46189, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 130s 8ms/step - loss: 0.4536 - accuracy: 0.9031 - val_loss: 0.4366 - val_accuracy: 0.9061\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90462 to 0.90613, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46189 to 0.43659, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 124s 7ms/step - loss: 0.4358 - accuracy: 0.9066 - val_loss: 0.4267 - val_accuracy: 0.9080\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90613 to 0.90802, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43659 to 0.42667, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 126s 7ms/step - loss: 0.4194 - accuracy: 0.9097 - val_loss: 0.4062 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90802 to 0.91235, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42667 to 0.40625, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.4038 - accuracy: 0.9119 - val_loss: 0.3961 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91235 to 0.91333, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40625 to 0.39610, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.3891 - accuracy: 0.9152 - val_loss: 0.3823 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91333 to 0.91415, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39610 to 0.38230, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.3735 - accuracy: 0.9177 - val_loss: 0.3676 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91415 to 0.91791, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38230 to 0.36758, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 126s 7ms/step - loss: 0.3606 - accuracy: 0.9203 - val_loss: 0.3510 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91791 to 0.92286, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36758 to 0.35102, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 126s 7ms/step - loss: 0.3478 - accuracy: 0.9226 - val_loss: 0.3472 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92286\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35102 to 0.34716, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 128s 7ms/step - loss: 0.3362 - accuracy: 0.9241 - val_loss: 0.3347 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92286\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34716 to 0.33467, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.3251 - accuracy: 0.9254 - val_loss: 0.3263 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92286 to 0.92303, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33467 to 0.32627, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 124s 7ms/step - loss: 0.3144 - accuracy: 0.9274 - val_loss: 0.3125 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92303 to 0.92663, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32627 to 0.31252, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 126s 7ms/step - loss: 0.3035 - accuracy: 0.9297 - val_loss: 0.3153 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92663\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31252\n",
      "epoch 20\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.2948 - accuracy: 0.9308 - val_loss: 0.2987 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92663\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31252 to 0.29871, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 126s 7ms/step - loss: 0.2856 - accuracy: 0.9322 - val_loss: 0.2924 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92663\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29871 to 0.29239, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 124s 7ms/step - loss: 0.2772 - accuracy: 0.9339 - val_loss: 0.2846 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92663 to 0.92675, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29239 to 0.28457, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 129s 8ms/step - loss: 0.2691 - accuracy: 0.9349 - val_loss: 0.2804 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92675\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28457 to 0.28037, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 127s 7ms/step - loss: 0.2614 - accuracy: 0.9361 - val_loss: 0.2775 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92675 to 0.92810, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28037 to 0.27751, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.2534 - accuracy: 0.9379 - val_loss: 0.2661 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92810 to 0.92892, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27751 to 0.26607, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.2469 - accuracy: 0.9383 - val_loss: 0.2643 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92892 to 0.93010, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26607 to 0.26426, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 124s 7ms/step - loss: 0.2404 - accuracy: 0.9396 - val_loss: 0.2595 - val_accuracy: 0.9314\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93010 to 0.93137, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26426 to 0.25952, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 28\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 124s 7ms/step - loss: 0.2348 - accuracy: 0.9406 - val_loss: 0.2555 - val_accuracy: 0.9291\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25952 to 0.25545, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 124s 7ms/step - loss: 0.2294 - accuracy: 0.9413 - val_loss: 0.2513 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25545 to 0.25132, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.2219 - accuracy: 0.9434 - val_loss: 0.2495 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25132 to 0.24949, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 127s 7ms/step - loss: 0.2170 - accuracy: 0.9440 - val_loss: 0.2446 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24949 to 0.24463, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.2118 - accuracy: 0.9449 - val_loss: 0.2402 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24463 to 0.24016, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.2068 - accuracy: 0.9458 - val_loss: 0.2379 - val_accuracy: 0.9310\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24016 to 0.23792, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 34\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.2010 - accuracy: 0.9471 - val_loss: 0.2429 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23792\n",
      "epoch 35\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1976 - accuracy: 0.9476 - val_loss: 0.2367 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23792 to 0.23673, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 36\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 123s 7ms/step - loss: 0.1928 - accuracy: 0.9488 - val_loss: 0.2334 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23673 to 0.23337, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 37\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 123s 7ms/step - loss: 0.1893 - accuracy: 0.9492 - val_loss: 0.2309 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23337 to 0.23085, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 38\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 127s 7ms/step - loss: 0.1846 - accuracy: 0.9500 - val_loss: 0.2311 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23085\n",
      "epoch 39\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 124s 7ms/step - loss: 0.1806 - accuracy: 0.9516 - val_loss: 0.2311 - val_accuracy: 0.9291\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23085\n",
      "epoch 40\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 121s 7ms/step - loss: 0.1766 - accuracy: 0.9520 - val_loss: 0.2313 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23085\n",
      "epoch 41\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 121s 7ms/step - loss: 0.1732 - accuracy: 0.9528 - val_loss: 0.2278 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23085 to 0.22780, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 42\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 124s 7ms/step - loss: 0.1692 - accuracy: 0.9535 - val_loss: 0.2233 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22780 to 0.22327, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 43\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 123s 7ms/step - loss: 0.1652 - accuracy: 0.9545 - val_loss: 0.2216 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22327 to 0.22156, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 44\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1619 - accuracy: 0.9556 - val_loss: 0.2254 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22156\n",
      "epoch 45\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1585 - accuracy: 0.9562 - val_loss: 0.2290 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22156\n",
      "epoch 46\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 123s 7ms/step - loss: 0.1567 - accuracy: 0.9564 - val_loss: 0.2230 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22156\n",
      "epoch 47\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1531 - accuracy: 0.9573 - val_loss: 0.2209 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22156 to 0.22088, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 48\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1509 - accuracy: 0.9571 - val_loss: 0.2269 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22088\n",
      "epoch 49\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1465 - accuracy: 0.9593 - val_loss: 0.2197 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22088 to 0.21969, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 50\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1449 - accuracy: 0.9595 - val_loss: 0.2240 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93137\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 51\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1404 - accuracy: 0.9607 - val_loss: 0.2219 - val_accuracy: 0.9323\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93137 to 0.93227, saving model to D:/mulocdeep/lv1_result11/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 52\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1391 - accuracy: 0.9605 - val_loss: 0.2260 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 53\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 123s 7ms/step - loss: 0.1352 - accuracy: 0.9620 - val_loss: 0.2227 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 54\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 124s 7ms/step - loss: 0.1336 - accuracy: 0.9620 - val_loss: 0.2288 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 55\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1311 - accuracy: 0.9628 - val_loss: 0.2295 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 56\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1289 - accuracy: 0.9639 - val_loss: 0.2201 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 57\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1253 - accuracy: 0.9653 - val_loss: 0.2234 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 58\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1244 - accuracy: 0.9648 - val_loss: 0.2230 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 59\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 121s 7ms/step - loss: 0.1223 - accuracy: 0.9651 - val_loss: 0.2351 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 60\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 121s 7ms/step - loss: 0.1197 - accuracy: 0.9654 - val_loss: 0.2332 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 61\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 127s 7ms/step - loss: 0.1177 - accuracy: 0.9665 - val_loss: 0.2269 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 62\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 123s 7ms/step - loss: 0.1160 - accuracy: 0.9669 - val_loss: 0.2315 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 63\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1131 - accuracy: 0.9681 - val_loss: 0.2285 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 64\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 121s 7ms/step - loss: 0.1106 - accuracy: 0.9687 - val_loss: 0.2305 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 65\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1090 - accuracy: 0.9689 - val_loss: 0.2403 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 66\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1077 - accuracy: 0.9691 - val_loss: 0.2355 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 67\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 120s 7ms/step - loss: 0.1054 - accuracy: 0.9700 - val_loss: 0.2331 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 68\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1030 - accuracy: 0.9709 - val_loss: 0.2390 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 69\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 126s 7ms/step - loss: 0.1020 - accuracy: 0.9710 - val_loss: 0.2396 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 70\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 121s 7ms/step - loss: 0.1022 - accuracy: 0.9707 - val_loss: 0.2334 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 71\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 121s 7ms/step - loss: 0.0979 - accuracy: 0.9722 - val_loss: 0.2416 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 72\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.0978 - accuracy: 0.9716 - val_loss: 0.2407 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 73\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.0958 - accuracy: 0.9721 - val_loss: 0.2335 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 74\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.0931 - accuracy: 0.9739 - val_loss: 0.2455 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 75\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 121s 7ms/step - loss: 0.0920 - accuracy: 0.9736 - val_loss: 0.2445 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 76\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.0906 - accuracy: 0.9743 - val_loss: 0.2343 - val_accuracy: 0.9308\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 77\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 124s 7ms/step - loss: 0.0877 - accuracy: 0.9754 - val_loss: 0.2391 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 78\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.0872 - accuracy: 0.9755 - val_loss: 0.2383 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "epoch 79\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.0855 - accuracy: 0.9762 - val_loss: 0.2396 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93227\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.21969\n",
      "doing 1th fold\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1000, 25)     0           dropout_12[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1000, 25)     650         lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1000, 25)     100         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1000, 25)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1000, 25)     0           dropout_13[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1000, 25)     1900        lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1000, 25)     100         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1000, 25)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1000, 25)     0           dropout_14[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1000, 25)     3150        lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1000, 25)     100         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1000, 25)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1000, 25)     0           dropout_15[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1000, 25)     5650        lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1000, 25)     100         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1000, 25)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1000, 25)     0           dropout_16[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1000, 25)     9400        lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1000, 25)     100         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1000, 25)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1000, 25)     0           dropout_17[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1000, 25)     13150       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1000, 25)     100         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1000, 25)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1000, 25)     0           dropout_18[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 180)    223560      lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1000, 180)    720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 1000, 180)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1000, 180)    0           dropout_19[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 180)    390960      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1000, 180)    720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 1000, 180)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1000, 180)    0           dropout_20[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1000, 181)    0           lambda_18[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 41, 180)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1000, 25)     0           dropout_12[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1000, 25)     650         lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1000, 25)     100         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1000, 25)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1000, 25)     0           dropout_13[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1000, 25)     1900        lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1000, 25)     100         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1000, 25)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1000, 25)     0           dropout_14[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1000, 25)     3150        lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1000, 25)     100         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1000, 25)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1000, 25)     0           dropout_15[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1000, 25)     5650        lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1000, 25)     100         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1000, 25)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1000, 25)     0           dropout_16[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1000, 25)     9400        lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1000, 25)     100         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1000, 25)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1000, 25)     0           dropout_17[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1000, 25)     13150       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1000, 25)     100         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1000, 25)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1000, 25)     0           dropout_18[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 180)    223560      lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1000, 180)    720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 1000, 180)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1000, 180)    0           dropout_19[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 180)    390960      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1000, 180)    720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 1000, 180)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1000, 180)    0           dropout_20[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1000, 181)    0           lambda_18[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 41, 180)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 135s 8ms/step - loss: 0.7543 - accuracy: 0.6346 - val_loss: 0.6669 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79149, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66687, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 126s 7ms/step - loss: 0.6499 - accuracy: 0.8052 - val_loss: 0.6788 - val_accuracy: 0.8281\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.79149 to 0.82806, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.66687\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 132s 8ms/step - loss: 0.6039 - accuracy: 0.8455 - val_loss: 0.5795 - val_accuracy: 0.8619\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82806 to 0.86192, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66687 to 0.57951, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 120s 7ms/step - loss: 0.5681 - accuracy: 0.8662 - val_loss: 0.5615 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86192 to 0.87342, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57951 to 0.56154, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.5383 - accuracy: 0.8819 - val_loss: 0.5255 - val_accuracy: 0.8834\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87342 to 0.88339, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56154 to 0.52549, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 118s 7ms/step - loss: 0.5145 - accuracy: 0.8894 - val_loss: 0.5124 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88339 to 0.88937, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52549 to 0.51245, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 118s 7ms/step - loss: 0.4924 - accuracy: 0.8952 - val_loss: 0.4874 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88937 to 0.89358, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51245 to 0.48740, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 120s 7ms/step - loss: 0.4733 - accuracy: 0.8992 - val_loss: 0.4713 - val_accuracy: 0.9034\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89358 to 0.90339, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48740 to 0.47130, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 116s 7ms/step - loss: 0.4539 - accuracy: 0.9038 - val_loss: 0.4504 - val_accuracy: 0.9046\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90339 to 0.90458, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47130 to 0.45042, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.4365 - accuracy: 0.9064 - val_loss: 0.4321 - val_accuracy: 0.9039\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90458\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45042 to 0.43209, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.4200 - accuracy: 0.9101 - val_loss: 0.4244 - val_accuracy: 0.9045\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90458\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43209 to 0.42435, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.4042 - accuracy: 0.9129 - val_loss: 0.4041 - val_accuracy: 0.9093\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90458 to 0.90928, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42435 to 0.40413, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.3886 - accuracy: 0.9151 - val_loss: 0.3890 - val_accuracy: 0.9096\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90928 to 0.90957, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40413 to 0.38900, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.3749 - accuracy: 0.9173 - val_loss: 0.3788 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90957 to 0.91305, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38900 to 0.37883, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.3607 - accuracy: 0.9204 - val_loss: 0.3717 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91305\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37883 to 0.37168, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 111s 6ms/step - loss: 0.3486 - accuracy: 0.9222 - val_loss: 0.3589 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91305 to 0.91787, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37168 to 0.35888, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.3364 - accuracy: 0.9239 - val_loss: 0.3471 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91787\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35888 to 0.34709, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.3250 - accuracy: 0.9260 - val_loss: 0.3391 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91787\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34709 to 0.33906, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.3149 - accuracy: 0.9269 - val_loss: 0.3302 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91787\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33906 to 0.33025, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.3043 - accuracy: 0.9291 - val_loss: 0.3195 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91787 to 0.91918, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33025 to 0.31947, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.2945 - accuracy: 0.9309 - val_loss: 0.3181 - val_accuracy: 0.9187\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91918\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31947 to 0.31810, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.2855 - accuracy: 0.9316 - val_loss: 0.3051 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91918 to 0.91939, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31810 to 0.30511, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.2778 - accuracy: 0.9327 - val_loss: 0.3009 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91939 to 0.91984, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30511 to 0.30092, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.2692 - accuracy: 0.9348 - val_loss: 0.3019 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91984 to 0.92086, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30092\n",
      "epoch 24\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.2617 - accuracy: 0.9355 - val_loss: 0.2967 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92086 to 0.92254, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30092 to 0.29671, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.2547 - accuracy: 0.9370 - val_loss: 0.2852 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92254\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29671 to 0.28521, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.2467 - accuracy: 0.9387 - val_loss: 0.2854 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92254 to 0.92307, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28521\n",
      "epoch 27\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.2413 - accuracy: 0.9390 - val_loss: 0.2740 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92307\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28521 to 0.27399, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 28\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.2340 - accuracy: 0.9404 - val_loss: 0.2821 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92307 to 0.92372, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27399\n",
      "epoch 29\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.2295 - accuracy: 0.9417 - val_loss: 0.2684 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92372\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27399 to 0.26844, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.2237 - accuracy: 0.9421 - val_loss: 0.2657 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92372\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26844 to 0.26571, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.2173 - accuracy: 0.9435 - val_loss: 0.2641 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92372 to 0.92434, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26571 to 0.26408, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.2122 - accuracy: 0.9446 - val_loss: 0.2657 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92434\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26408\n",
      "epoch 33\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.2066 - accuracy: 0.9457 - val_loss: 0.2609 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92434 to 0.92487, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26408 to 0.26088, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 34\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.2025 - accuracy: 0.9458 - val_loss: 0.2557 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26088 to 0.25569, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 120s 7ms/step - loss: 0.1976 - accuracy: 0.9475 - val_loss: 0.2544 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25569 to 0.25437, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 36\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.1927 - accuracy: 0.9490 - val_loss: 0.2500 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25437 to 0.24998, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 37\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.1897 - accuracy: 0.9493 - val_loss: 0.2526 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24998\n",
      "epoch 38\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.1851 - accuracy: 0.9503 - val_loss: 0.2501 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24998\n",
      "epoch 39\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.1808 - accuracy: 0.9513 - val_loss: 0.2448 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24998 to 0.24476, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 40\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.1770 - accuracy: 0.9522 - val_loss: 0.2443 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24476 to 0.24432, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 41\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.1729 - accuracy: 0.9528 - val_loss: 0.2442 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24432 to 0.24421, saving model to D:/mulocdeep/lv1_result11/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 42\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 111s 6ms/step - loss: 0.1688 - accuracy: 0.9542 - val_loss: 0.2493 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 43\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1646 - accuracy: 0.9555 - val_loss: 0.2471 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 44\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.1624 - accuracy: 0.9549 - val_loss: 0.2504 - val_accuracy: 0.9215\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 45\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.1593 - accuracy: 0.9556 - val_loss: 0.2469 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 46\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.1562 - accuracy: 0.9566 - val_loss: 0.2505 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 47\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.1521 - accuracy: 0.9577 - val_loss: 0.2482 - val_accuracy: 0.9210\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 48\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.1500 - accuracy: 0.9585 - val_loss: 0.2463 - val_accuracy: 0.9210\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 49\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.1476 - accuracy: 0.9585 - val_loss: 0.2481 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 50\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.1439 - accuracy: 0.9600 - val_loss: 0.2532 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 51\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 125s 7ms/step - loss: 0.1417 - accuracy: 0.9600 - val_loss: 0.2474 - val_accuracy: 0.9203\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 52\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.1393 - accuracy: 0.9610 - val_loss: 0.2465 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 53\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.1357 - accuracy: 0.9619 - val_loss: 0.2529 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 54\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.1346 - accuracy: 0.9619 - val_loss: 0.2477 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 55\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.1306 - accuracy: 0.9629 - val_loss: 0.2497 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 56\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.1296 - accuracy: 0.9630 - val_loss: 0.2522 - val_accuracy: 0.9204\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 57\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.1266 - accuracy: 0.9642 - val_loss: 0.2577 - val_accuracy: 0.9196\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 58\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.1244 - accuracy: 0.9645 - val_loss: 0.2521 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 59\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 118s 7ms/step - loss: 0.1207 - accuracy: 0.9662 - val_loss: 0.2499 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 60\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 118s 7ms/step - loss: 0.1178 - accuracy: 0.9671 - val_loss: 0.2520 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 61\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.1167 - accuracy: 0.9672 - val_loss: 0.2487 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 62\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.1147 - accuracy: 0.9676 - val_loss: 0.2548 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 63\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.1119 - accuracy: 0.9685 - val_loss: 0.2538 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 64\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.1093 - accuracy: 0.9696 - val_loss: 0.2554 - val_accuracy: 0.9225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 65\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.1085 - accuracy: 0.9693 - val_loss: 0.2627 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 66\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.1054 - accuracy: 0.9707 - val_loss: 0.2597 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 67\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.1046 - accuracy: 0.9706 - val_loss: 0.2642 - val_accuracy: 0.9202\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 68\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.1029 - accuracy: 0.9708 - val_loss: 0.2629 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 69\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.1009 - accuracy: 0.9715 - val_loss: 0.2628 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 70\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 116s 7ms/step - loss: 0.0993 - accuracy: 0.9720 - val_loss: 0.2707 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 71\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.0970 - accuracy: 0.9728 - val_loss: 0.2663 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 72\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.0952 - accuracy: 0.9733 - val_loss: 0.2661 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 73\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.0932 - accuracy: 0.9736 - val_loss: 0.2672 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 74\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.0924 - accuracy: 0.9742 - val_loss: 0.2653 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 75\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.0899 - accuracy: 0.9749 - val_loss: 0.2676 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 76\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.0888 - accuracy: 0.9751 - val_loss: 0.2903 - val_accuracy: 0.9206\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 77\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.0876 - accuracy: 0.9759 - val_loss: 0.2760 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 78\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.0851 - accuracy: 0.9764 - val_loss: 0.2714 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "epoch 79\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.0841 - accuracy: 0.9766 - val_loss: 0.2763 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92487\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24421\n",
      "doing 2th fold\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1000, 25)     0           dropout_23[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1000, 25)     650         lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1000, 25)     100         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 1000, 25)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1000, 25)     0           dropout_24[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1000, 25)     1900        lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1000, 25)     100         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 1000, 25)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1000, 25)     0           dropout_25[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1000, 25)     3150        lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1000, 25)     100         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1000, 25)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1000, 25)     0           dropout_26[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1000, 25)     5650        lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1000, 25)     100         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1000, 25)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1000, 25)     0           dropout_27[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1000, 25)     9400        lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1000, 25)     100         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1000, 25)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1000, 25)     0           dropout_28[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1000, 25)     13150       lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1000, 25)     100         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 1000, 25)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1000, 25)     0           dropout_29[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 180)    223560      lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1000, 180)    720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 1000, 180)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1000, 180)    0           dropout_30[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 180)    390960      lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1000, 180)    720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1000, 180)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 1000, 180)    0           dropout_31[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 181)    0           lambda_27[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 41, 180)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1000, 25)     0           dropout_23[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1000, 25)     650         lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1000, 25)     100         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 1000, 25)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1000, 25)     0           dropout_24[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1000, 25)     1900        lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1000, 25)     100         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 1000, 25)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1000, 25)     0           dropout_25[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1000, 25)     3150        lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1000, 25)     100         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1000, 25)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1000, 25)     0           dropout_26[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1000, 25)     5650        lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1000, 25)     100         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1000, 25)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1000, 25)     0           dropout_27[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1000, 25)     9400        lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1000, 25)     100         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1000, 25)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1000, 25)     0           dropout_28[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1000, 25)     13150       lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1000, 25)     100         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 1000, 25)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1000, 25)     0           dropout_29[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 180)    223560      lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1000, 180)    720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 1000, 180)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1000, 180)    0           dropout_30[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 180)    390960      lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1000, 180)    720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1000, 180)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 1000, 180)    0           dropout_31[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 181)    0           lambda_27[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 41, 180)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 118s 7ms/step - loss: 0.7246 - accuracy: 0.7229 - val_loss: 0.6912 - val_accuracy: 0.8106\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81060, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69124, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.6395 - accuracy: 0.8185 - val_loss: 0.6333 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81060 to 0.84656, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.69124 to 0.63333, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 122s 7ms/step - loss: 0.5950 - accuracy: 0.8508 - val_loss: 0.5934 - val_accuracy: 0.8642\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84656 to 0.86420, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.63333 to 0.59336, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 114s 7ms/step - loss: 0.5659 - accuracy: 0.8682 - val_loss: 0.5535 - val_accuracy: 0.8782\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86420 to 0.87818, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.59336 to 0.55354, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.5403 - accuracy: 0.8775 - val_loss: 0.5213 - val_accuracy: 0.8775\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87818\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55354 to 0.52132, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.5159 - accuracy: 0.8852 - val_loss: 0.5026 - val_accuracy: 0.8848\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87818 to 0.88485, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52132 to 0.50258, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.4930 - accuracy: 0.8923 - val_loss: 0.4852 - val_accuracy: 0.8955\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88485 to 0.89548, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50258 to 0.48524, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.4731 - accuracy: 0.8971 - val_loss: 0.4629 - val_accuracy: 0.8997\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89548 to 0.89975, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48524 to 0.46287, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.4536 - accuracy: 0.9013 - val_loss: 0.4474 - val_accuracy: 0.9025\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89975 to 0.90253, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46287 to 0.44736, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 106s 6ms/step - loss: 0.4363 - accuracy: 0.9041 - val_loss: 0.4316 - val_accuracy: 0.9055\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90253 to 0.90553, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44736 to 0.43163, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.4192 - accuracy: 0.9074 - val_loss: 0.4152 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90553 to 0.90840, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43163 to 0.41524, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 115s 7ms/step - loss: 0.4037 - accuracy: 0.9095 - val_loss: 0.3995 - val_accuracy: 0.9089\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90840 to 0.90886, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41524 to 0.39947, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.3882 - accuracy: 0.9129 - val_loss: 0.3849 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90886 to 0.91431, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39947 to 0.38490, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.3745 - accuracy: 0.9150 - val_loss: 0.3778 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91431\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38490 to 0.37775, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.3602 - accuracy: 0.9180 - val_loss: 0.3612 - val_accuracy: 0.9178\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91431 to 0.91781, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37775 to 0.36122, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.3474 - accuracy: 0.9199 - val_loss: 0.3494 - val_accuracy: 0.9177\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91781\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36122 to 0.34938, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.3362 - accuracy: 0.9213 - val_loss: 0.3433 - val_accuracy: 0.9187\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91781 to 0.91874, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34938 to 0.34330, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.3243 - accuracy: 0.9240 - val_loss: 0.3374 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91874 to 0.92068, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34330 to 0.33738, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.3140 - accuracy: 0.9259 - val_loss: 0.3216 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92068\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33738 to 0.32160, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.3037 - accuracy: 0.9272 - val_loss: 0.3140 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92068 to 0.92212, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32160 to 0.31404, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 119s 7ms/step - loss: 0.2946 - accuracy: 0.9286 - val_loss: 0.3107 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92212\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31404 to 0.31070, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 110s 6ms/step - loss: 0.2853 - accuracy: 0.9308 - val_loss: 0.2976 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92212 to 0.92309, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31070 to 0.29764, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.2776 - accuracy: 0.9317 - val_loss: 0.2972 - val_accuracy: 0.9254\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92309 to 0.92541, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29764 to 0.29716, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.2699 - accuracy: 0.9329 - val_loss: 0.2900 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92541\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29716 to 0.29002, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.2615 - accuracy: 0.9351 - val_loss: 0.2826 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92541\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29002 to 0.28264, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.2542 - accuracy: 0.9362 - val_loss: 0.2753 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92541 to 0.92630, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28264 to 0.27529, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.2473 - accuracy: 0.9372 - val_loss: 0.2723 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92630\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27529 to 0.27227, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.2413 - accuracy: 0.9386 - val_loss: 0.2719 - val_accuracy: 0.9255\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92630\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27227 to 0.27190, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 28\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 114s 7ms/step - loss: 0.2347 - accuracy: 0.9396 - val_loss: 0.2637 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92630\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27190 to 0.26366, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.2294 - accuracy: 0.9407 - val_loss: 0.2613 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92630\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26366 to 0.26134, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.2230 - accuracy: 0.9413 - val_loss: 0.2580 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92630 to 0.92718, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26134 to 0.25798, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.2184 - accuracy: 0.9413 - val_loss: 0.2587 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92718\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25798\n",
      "epoch 32\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.2124 - accuracy: 0.9437 - val_loss: 0.2501 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92718\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25798 to 0.25008, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.2072 - accuracy: 0.9445 - val_loss: 0.2564 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92718 to 0.92883, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25008\n",
      "epoch 34\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.2022 - accuracy: 0.9460 - val_loss: 0.2467 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92883\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25008 to 0.24666, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.1976 - accuracy: 0.9470 - val_loss: 0.2396 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92883\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24666 to 0.23961, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 36\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.1932 - accuracy: 0.9481 - val_loss: 0.2487 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92883\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23961\n",
      "epoch 37\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 116s 7ms/step - loss: 0.1896 - accuracy: 0.9482 - val_loss: 0.2401 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92883\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23961\n",
      "epoch 38\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.1856 - accuracy: 0.9494 - val_loss: 0.2386 - val_accuracy: 0.9254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92883\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23961 to 0.23856, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 39\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1826 - accuracy: 0.9499 - val_loss: 0.2345 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92883\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23856 to 0.23453, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 40\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1763 - accuracy: 0.9518 - val_loss: 0.2326 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92883 to 0.92989, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23453 to 0.23263, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 41\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 106s 6ms/step - loss: 0.1736 - accuracy: 0.9515 - val_loss: 0.2374 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23263\n",
      "epoch 42\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.1702 - accuracy: 0.9529 - val_loss: 0.2412 - val_accuracy: 0.9255\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23263\n",
      "epoch 43\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.1667 - accuracy: 0.9535 - val_loss: 0.2366 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23263\n",
      "epoch 44\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.1622 - accuracy: 0.9551 - val_loss: 0.2339 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23263\n",
      "epoch 45\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1604 - accuracy: 0.9548 - val_loss: 0.2268 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23263 to 0.22683, saving model to D:/mulocdeep/lv1_result11/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 46\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 117s 7ms/step - loss: 0.1582 - accuracy: 0.9553 - val_loss: 0.2321 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 47\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 110s 6ms/step - loss: 0.1525 - accuracy: 0.9573 - val_loss: 0.2351 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 48\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1506 - accuracy: 0.9574 - val_loss: 0.2309 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 49\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1485 - accuracy: 0.9584 - val_loss: 0.2367 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 50\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1451 - accuracy: 0.9591 - val_loss: 0.2286 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 51\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1428 - accuracy: 0.9592 - val_loss: 0.2375 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 52\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1391 - accuracy: 0.9605 - val_loss: 0.2309 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 53\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1360 - accuracy: 0.9615 - val_loss: 0.2369 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 54\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 118s 7ms/step - loss: 0.1352 - accuracy: 0.9612 - val_loss: 0.2364 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 55\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 111s 6ms/step - loss: 0.1316 - accuracy: 0.9625 - val_loss: 0.2500 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 56\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.1295 - accuracy: 0.9627 - val_loss: 0.2344 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 57\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1268 - accuracy: 0.9638 - val_loss: 0.2387 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 58\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.1249 - accuracy: 0.9644 - val_loss: 0.2350 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 59\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1229 - accuracy: 0.9651 - val_loss: 0.2353 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 60\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.1195 - accuracy: 0.9658 - val_loss: 0.2482 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 61\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.1168 - accuracy: 0.9669 - val_loss: 0.2395 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 62\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.1151 - accuracy: 0.9672 - val_loss: 0.2449 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 63\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17214/17214 [==============================] - 119s 7ms/step - loss: 0.1129 - accuracy: 0.9678 - val_loss: 0.2486 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 64\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1115 - accuracy: 0.9681 - val_loss: 0.2404 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 65\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1109 - accuracy: 0.9681 - val_loss: 0.2400 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 66\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.1090 - accuracy: 0.9686 - val_loss: 0.2406 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 67\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.1049 - accuracy: 0.9699 - val_loss: 0.2460 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 68\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.1039 - accuracy: 0.9701 - val_loss: 0.2465 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 69\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.1019 - accuracy: 0.9711 - val_loss: 0.2517 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 70\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.1004 - accuracy: 0.9710 - val_loss: 0.2462 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 71\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.0987 - accuracy: 0.9721 - val_loss: 0.2461 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 72\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 118s 7ms/step - loss: 0.0970 - accuracy: 0.9718 - val_loss: 0.2438 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 73\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.0956 - accuracy: 0.9725 - val_loss: 0.2468 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 74\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.0930 - accuracy: 0.9735 - val_loss: 0.2473 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 75\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 106s 6ms/step - loss: 0.0905 - accuracy: 0.9745 - val_loss: 0.2546 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 76\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.0897 - accuracy: 0.9741 - val_loss: 0.2486 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 77\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.0870 - accuracy: 0.9757 - val_loss: 0.2501 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 78\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.0865 - accuracy: 0.9756 - val_loss: 0.2577 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "epoch 79\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.0852 - accuracy: 0.9764 - val_loss: 0.2504 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22683\n",
      "doing 3th fold\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1000, 25)     0           dropout_34[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1000, 25)     650         lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1000, 25)     100         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 1000, 25)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 1000, 25)     0           dropout_35[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1000, 25)     1900        lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1000, 25)     100         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 1000, 25)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1000, 25)     0           dropout_36[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1000, 25)     3150        lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1000, 25)     100         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1000, 25)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 1000, 25)     0           dropout_37[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1000, 25)     5650        lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 1000, 25)     100         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1000, 25)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1000, 25)     0           dropout_38[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1000, 25)     9400        lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 1000, 25)     100         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 1000, 25)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 1000, 25)     0           dropout_39[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1000, 25)     13150       lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1000, 25)     100         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 1000, 25)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 1000, 25)     0           dropout_40[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1000, 180)    223560      lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1000, 180)    720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 1000, 180)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 1000, 180)    0           dropout_41[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1000, 180)    390960      lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1000, 180)    720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 1000, 180)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1000, 180)    0           dropout_42[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1000, 181)    0           lambda_36[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 41, 180)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1000, 25)     0           dropout_34[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1000, 25)     650         lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1000, 25)     100         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 1000, 25)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 1000, 25)     0           dropout_35[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1000, 25)     1900        lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1000, 25)     100         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 1000, 25)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1000, 25)     0           dropout_36[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1000, 25)     3150        lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1000, 25)     100         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1000, 25)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 1000, 25)     0           dropout_37[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1000, 25)     5650        lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 1000, 25)     100         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1000, 25)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1000, 25)     0           dropout_38[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1000, 25)     9400        lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 1000, 25)     100         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 1000, 25)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 1000, 25)     0           dropout_39[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1000, 25)     13150       lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1000, 25)     100         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 1000, 25)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 1000, 25)     0           dropout_40[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1000, 180)    223560      lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1000, 180)    720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 1000, 180)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 1000, 180)    0           dropout_41[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1000, 180)    390960      lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1000, 180)    720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 1000, 180)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1000, 180)    0           dropout_42[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1000, 181)    0           lambda_36[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 41, 180)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 119s 7ms/step - loss: 0.7344 - accuracy: 0.6904 - val_loss: 0.7168 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80000, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.71676, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 110s 6ms/step - loss: 0.6407 - accuracy: 0.8103 - val_loss: 0.6318 - val_accuracy: 0.8413\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80000 to 0.84134, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.71676 to 0.63184, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.5971 - accuracy: 0.8492 - val_loss: 0.5745 - val_accuracy: 0.8656\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84134 to 0.86560, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.63184 to 0.57455, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 109s 6ms/step - loss: 0.5671 - accuracy: 0.8657 - val_loss: 0.5362 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86560 to 0.87286, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57455 to 0.53616, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 109s 6ms/step - loss: 0.5399 - accuracy: 0.8770 - val_loss: 0.5242 - val_accuracy: 0.8823\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87286 to 0.88231, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53616 to 0.52423, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 110s 6ms/step - loss: 0.5147 - accuracy: 0.8874 - val_loss: 0.5009 - val_accuracy: 0.8942\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88231 to 0.89420, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52423 to 0.50093, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.4926 - accuracy: 0.8939 - val_loss: 0.4729 - val_accuracy: 0.8963\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89420 to 0.89627, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50093 to 0.47291, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 113s 7ms/step - loss: 0.4734 - accuracy: 0.8974 - val_loss: 0.4534 - val_accuracy: 0.8985\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89627 to 0.89846, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47291 to 0.45336, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 104s 6ms/step - loss: 0.4546 - accuracy: 0.9020 - val_loss: 0.4431 - val_accuracy: 0.9033\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89846 to 0.90333, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45336 to 0.44309, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 103s 6ms/step - loss: 0.4367 - accuracy: 0.9055 - val_loss: 0.4229 - val_accuracy: 0.9065\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90333 to 0.90653, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44309 to 0.42289, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 104s 6ms/step - loss: 0.4200 - accuracy: 0.9080 - val_loss: 0.4136 - val_accuracy: 0.9083\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90653 to 0.90832, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42289 to 0.41364, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.4043 - accuracy: 0.9109 - val_loss: 0.3955 - val_accuracy: 0.9138\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90832 to 0.91379, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41364 to 0.39547, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 110s 6ms/step - loss: 0.3893 - accuracy: 0.9129 - val_loss: 0.3787 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91379 to 0.91611, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39547 to 0.37867, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 107s 6ms/step - loss: 0.3754 - accuracy: 0.9161 - val_loss: 0.3704 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91611 to 0.91704, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37867 to 0.37044, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.3621 - accuracy: 0.9174 - val_loss: 0.3535 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91704\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37044 to 0.35348, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 114s 7ms/step - loss: 0.3488 - accuracy: 0.9199 - val_loss: 0.3430 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91704 to 0.92203, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35348 to 0.34304, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.3365 - accuracy: 0.9221 - val_loss: 0.3324 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92203 to 0.92247, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34304 to 0.33237, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.3254 - accuracy: 0.9243 - val_loss: 0.3251 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92247\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33237 to 0.32507, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 104s 6ms/step - loss: 0.3155 - accuracy: 0.9250 - val_loss: 0.3149 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92247 to 0.92280, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32507 to 0.31492, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 103s 6ms/step - loss: 0.3056 - accuracy: 0.9272 - val_loss: 0.3085 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92280 to 0.92284, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31492 to 0.30847, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.2956 - accuracy: 0.9289 - val_loss: 0.2995 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92284 to 0.92515, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30847 to 0.29948, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 111s 6ms/step - loss: 0.2876 - accuracy: 0.9298 - val_loss: 0.2935 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92515\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29948 to 0.29352, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 110s 6ms/step - loss: 0.2787 - accuracy: 0.9316 - val_loss: 0.2848 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92515 to 0.92661, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29352 to 0.28478, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.2710 - accuracy: 0.9329 - val_loss: 0.2819 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92661 to 0.92698, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28478 to 0.28190, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 116s 7ms/step - loss: 0.2634 - accuracy: 0.9337 - val_loss: 0.2766 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92698\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28190 to 0.27657, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.2560 - accuracy: 0.9352 - val_loss: 0.2658 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92698 to 0.92929, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27657 to 0.26577, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 107s 6ms/step - loss: 0.2491 - accuracy: 0.9369 - val_loss: 0.2619 - val_accuracy: 0.9296\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92929 to 0.92957, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26577 to 0.26190, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 107s 6ms/step - loss: 0.2432 - accuracy: 0.9372 - val_loss: 0.2626 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26190\n",
      "epoch 28\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.2352 - accuracy: 0.9397 - val_loss: 0.2556 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92957 to 0.93047, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26190 to 0.25561, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 107s 6ms/step - loss: 0.2298 - accuracy: 0.9405 - val_loss: 0.2534 - val_accuracy: 0.9321\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93047 to 0.93213, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25561 to 0.25344, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.2251 - accuracy: 0.9405 - val_loss: 0.2470 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93213\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25344 to 0.24701, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.2192 - accuracy: 0.9421 - val_loss: 0.2474 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93213\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24701\n",
      "epoch 32\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.2138 - accuracy: 0.9432 - val_loss: 0.2428 - val_accuracy: 0.9296\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93213\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24701 to 0.24284, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 114s 7ms/step - loss: 0.2084 - accuracy: 0.9445 - val_loss: 0.2429 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93213\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24284\n",
      "epoch 34\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.2046 - accuracy: 0.9452 - val_loss: 0.2367 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93213\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24284 to 0.23671, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 105s 6ms/step - loss: 0.1986 - accuracy: 0.9462 - val_loss: 0.2359 - val_accuracy: 0.9298\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93213\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23671 to 0.23589, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 36\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 105s 6ms/step - loss: 0.1945 - accuracy: 0.9475 - val_loss: 0.2363 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93213\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23589\n",
      "epoch 37\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 105s 6ms/step - loss: 0.1901 - accuracy: 0.9480 - val_loss: 0.2316 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93213\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23589 to 0.23163, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.1857 - accuracy: 0.9493 - val_loss: 0.2321 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93213\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23163\n",
      "epoch 39\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.1809 - accuracy: 0.9508 - val_loss: 0.2274 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93213\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23163 to 0.22744, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 40\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.1786 - accuracy: 0.9505 - val_loss: 0.2261 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93213\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22744 to 0.22613, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 41\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 114s 7ms/step - loss: 0.1732 - accuracy: 0.9523 - val_loss: 0.2257 - val_accuracy: 0.9332\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93213 to 0.93318, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22613 to 0.22571, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 42\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 109s 6ms/step - loss: 0.1695 - accuracy: 0.9532 - val_loss: 0.2256 - val_accuracy: 0.9312\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22571 to 0.22563, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 43\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 105s 6ms/step - loss: 0.1654 - accuracy: 0.9540 - val_loss: 0.2276 - val_accuracy: 0.9321\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22563\n",
      "epoch 44\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 107s 6ms/step - loss: 0.1631 - accuracy: 0.9540 - val_loss: 0.2270 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22563\n",
      "epoch 45\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.1605 - accuracy: 0.9550 - val_loss: 0.2259 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22563\n",
      "epoch 46\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 107s 6ms/step - loss: 0.1557 - accuracy: 0.9562 - val_loss: 0.2214 - val_accuracy: 0.9311\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22563 to 0.22143, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 47\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 107s 6ms/step - loss: 0.1528 - accuracy: 0.9573 - val_loss: 0.2280 - val_accuracy: 0.9318\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22143\n",
      "epoch 48\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 107s 6ms/step - loss: 0.1498 - accuracy: 0.9580 - val_loss: 0.2293 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22143\n",
      "epoch 49\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.1457 - accuracy: 0.9592 - val_loss: 0.2276 - val_accuracy: 0.9314\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22143\n",
      "epoch 50\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 115s 7ms/step - loss: 0.1438 - accuracy: 0.9595 - val_loss: 0.2254 - val_accuracy: 0.9303\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22143\n",
      "epoch 51\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 107s 6ms/step - loss: 0.1423 - accuracy: 0.9597 - val_loss: 0.2254 - val_accuracy: 0.9325\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22143\n",
      "epoch 52\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.1389 - accuracy: 0.9607 - val_loss: 0.2253 - val_accuracy: 0.9311\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22143\n",
      "epoch 53\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.1348 - accuracy: 0.9619 - val_loss: 0.2261 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22143\n",
      "epoch 54\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 105s 6ms/step - loss: 0.1319 - accuracy: 0.9631 - val_loss: 0.2276 - val_accuracy: 0.9311\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22143\n",
      "epoch 55\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 105s 6ms/step - loss: 0.1292 - accuracy: 0.9636 - val_loss: 0.2275 - val_accuracy: 0.9312\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22143\n",
      "epoch 56\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.1269 - accuracy: 0.9644 - val_loss: 0.2288 - val_accuracy: 0.9318\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22143\n",
      "epoch 57\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 105s 6ms/step - loss: 0.1243 - accuracy: 0.9652 - val_loss: 0.2206 - val_accuracy: 0.9318\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22143 to 0.22064, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 58\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.1231 - accuracy: 0.9651 - val_loss: 0.2272 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 59\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 116s 7ms/step - loss: 0.1197 - accuracy: 0.9664 - val_loss: 0.2293 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 60\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.1176 - accuracy: 0.9669 - val_loss: 0.2381 - val_accuracy: 0.9315\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 61\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.1160 - accuracy: 0.9670 - val_loss: 0.2279 - val_accuracy: 0.9324\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 62\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.1129 - accuracy: 0.9682 - val_loss: 0.2326 - val_accuracy: 0.9303\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 63\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 107s 6ms/step - loss: 0.1102 - accuracy: 0.9690 - val_loss: 0.2284 - val_accuracy: 0.9325\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 64\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.1075 - accuracy: 0.9700 - val_loss: 0.2356 - val_accuracy: 0.9311\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 65\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.1064 - accuracy: 0.9702 - val_loss: 0.2370 - val_accuracy: 0.9330\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 66\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 107s 6ms/step - loss: 0.1032 - accuracy: 0.9711 - val_loss: 0.2468 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 67\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.1015 - accuracy: 0.9719 - val_loss: 0.2400 - val_accuracy: 0.9312\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 68\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 116s 7ms/step - loss: 0.1005 - accuracy: 0.9719 - val_loss: 0.2394 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 69\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 110s 6ms/step - loss: 0.0992 - accuracy: 0.9720 - val_loss: 0.2337 - val_accuracy: 0.9312\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93318\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 70\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 112s 7ms/step - loss: 0.0967 - accuracy: 0.9731 - val_loss: 0.2299 - val_accuracy: 0.9340\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93318 to 0.93404, saving model to D:/mulocdeep/lv1_result11/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 71\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 112s 7ms/step - loss: 0.0957 - accuracy: 0.9734 - val_loss: 0.2400 - val_accuracy: 0.9317\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93404\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 72\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 114s 7ms/step - loss: 0.0932 - accuracy: 0.9744 - val_loss: 0.2406 - val_accuracy: 0.9315\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93404\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 73\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 113s 7ms/step - loss: 0.0907 - accuracy: 0.9749 - val_loss: 0.2370 - val_accuracy: 0.9298\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93404\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 74\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 112s 7ms/step - loss: 0.0891 - accuracy: 0.9753 - val_loss: 0.2418 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93404\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 75\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 113s 7ms/step - loss: 0.0883 - accuracy: 0.9758 - val_loss: 0.2431 - val_accuracy: 0.9310\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93404\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 76\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 123s 7ms/step - loss: 0.0869 - accuracy: 0.9757 - val_loss: 0.2463 - val_accuracy: 0.9308\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93404\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 77\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 113s 7ms/step - loss: 0.0844 - accuracy: 0.9769 - val_loss: 0.2543 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93404\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 78\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 113s 7ms/step - loss: 0.0832 - accuracy: 0.9775 - val_loss: 0.2446 - val_accuracy: 0.9303\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93404\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "epoch 79\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 113s 7ms/step - loss: 0.0825 - accuracy: 0.9768 - val_loss: 0.2512 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93404\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22064\n",
      "doing 4th fold\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 1000, 25)     0           dropout_45[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1000, 25)     650         lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 1000, 25)     100         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 1000, 25)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 1000, 25)     0           dropout_46[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 1000, 25)     1900        lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 1000, 25)     100         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 1000, 25)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 1000, 25)     0           dropout_47[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1000, 25)     3150        lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 1000, 25)     100         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 1000, 25)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 1000, 25)     0           dropout_48[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1000, 25)     5650        lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 1000, 25)     100         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 1000, 25)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 1000, 25)     0           dropout_49[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1000, 25)     9400        lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1000, 25)     100         conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 1000, 25)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 1000, 25)     0           dropout_50[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1000, 25)     13150       lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 1000, 25)     100         conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 1000, 25)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 1000, 25)     0           dropout_51[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1000, 180)    223560      lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 1000, 180)    720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 1000, 180)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 1000, 180)    0           dropout_52[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1000, 180)    390960      lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 1000, 180)    720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 1000, 180)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 1000, 180)    0           dropout_53[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1000, 181)    0           lambda_45[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 41, 180)      0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 1000, 25)     0           dropout_45[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1000, 25)     650         lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 1000, 25)     100         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 1000, 25)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 1000, 25)     0           dropout_46[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 1000, 25)     1900        lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 1000, 25)     100         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 1000, 25)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 1000, 25)     0           dropout_47[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1000, 25)     3150        lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 1000, 25)     100         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 1000, 25)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 1000, 25)     0           dropout_48[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1000, 25)     5650        lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 1000, 25)     100         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 1000, 25)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 1000, 25)     0           dropout_49[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1000, 25)     9400        lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1000, 25)     100         conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 1000, 25)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 1000, 25)     0           dropout_50[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1000, 25)     13150       lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 1000, 25)     100         conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 1000, 25)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 1000, 25)     0           dropout_51[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1000, 180)    223560      lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 1000, 180)    720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 1000, 180)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 1000, 180)    0           dropout_52[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1000, 180)    390960      lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 1000, 180)    720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 1000, 180)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 1000, 180)    0           dropout_53[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1000, 181)    0           lambda_45[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 41, 180)      0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 125s 7ms/step - loss: 0.7463 - accuracy: 0.6752 - val_loss: 0.6729 - val_accuracy: 0.7641\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76409, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67293, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 115s 7ms/step - loss: 0.6447 - accuracy: 0.8080 - val_loss: 0.6527 - val_accuracy: 0.8421\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.76409 to 0.84208, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.67293 to 0.65267, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 136s 8ms/step - loss: 0.5993 - accuracy: 0.8486 - val_loss: 0.5908 - val_accuracy: 0.8621\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84208 to 0.86207, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.65267 to 0.59077, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 113s 7ms/step - loss: 0.5668 - accuracy: 0.8637 - val_loss: 0.5544 - val_accuracy: 0.8777\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86207 to 0.87771, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.59077 to 0.55441, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 113s 7ms/step - loss: 0.5391 - accuracy: 0.8806 - val_loss: 0.5245 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87771 to 0.88311, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55441 to 0.52447, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.5150 - accuracy: 0.8888 - val_loss: 0.5026 - val_accuracy: 0.8856\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88311 to 0.88557, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52447 to 0.50256, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 115s 7ms/step - loss: 0.4939 - accuracy: 0.8934 - val_loss: 0.4780 - val_accuracy: 0.8957\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88557 to 0.89569, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50256 to 0.47804, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.4727 - accuracy: 0.8990 - val_loss: 0.4676 - val_accuracy: 0.8988\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89569 to 0.89875, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47804 to 0.46765, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.4549 - accuracy: 0.9019 - val_loss: 0.4512 - val_accuracy: 0.9050\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89875 to 0.90504, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46765 to 0.45122, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 111s 7ms/step - loss: 0.4366 - accuracy: 0.9057 - val_loss: 0.4273 - val_accuracy: 0.9033\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90504\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45122 to 0.42729, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 121s 7ms/step - loss: 0.4195 - accuracy: 0.9087 - val_loss: 0.4107 - val_accuracy: 0.9120\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90504 to 0.91201, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42729 to 0.41069, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.4041 - accuracy: 0.9120 - val_loss: 0.4044 - val_accuracy: 0.9079\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91201\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41069 to 0.40442, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 115s 7ms/step - loss: 0.3878 - accuracy: 0.9151 - val_loss: 0.3838 - val_accuracy: 0.9116\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91201\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40442 to 0.38380, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.3744 - accuracy: 0.9162 - val_loss: 0.3767 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91201 to 0.91221, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38380 to 0.37666, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.3598 - accuracy: 0.9198 - val_loss: 0.3608 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91221 to 0.91644, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37666 to 0.36076, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.3471 - accuracy: 0.9212 - val_loss: 0.3532 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91644\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36076 to 0.35319, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 115s 7ms/step - loss: 0.3353 - accuracy: 0.9237 - val_loss: 0.3432 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91644\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35319 to 0.34318, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 115s 7ms/step - loss: 0.3244 - accuracy: 0.9254 - val_loss: 0.3263 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91644 to 0.92277, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34318 to 0.32630, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17102/17102 [==============================] - 113s 7ms/step - loss: 0.3143 - accuracy: 0.9261 - val_loss: 0.3162 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92277\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32630 to 0.31620, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 126s 7ms/step - loss: 0.3048 - accuracy: 0.9277 - val_loss: 0.3083 - val_accuracy: 0.9246\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92277 to 0.92459, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31620 to 0.30832, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 115s 7ms/step - loss: 0.2939 - accuracy: 0.9305 - val_loss: 0.3028 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92459\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30832 to 0.30285, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.2863 - accuracy: 0.9308 - val_loss: 0.2930 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92459 to 0.92471, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30285 to 0.29304, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 115s 7ms/step - loss: 0.2778 - accuracy: 0.9317 - val_loss: 0.2895 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92471 to 0.92600, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29304 to 0.28955, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.2694 - accuracy: 0.9338 - val_loss: 0.2825 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92600\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28955 to 0.28253, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.2615 - accuracy: 0.9351 - val_loss: 0.2865 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92600\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28253\n",
      "epoch 25\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.2545 - accuracy: 0.9362 - val_loss: 0.2728 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92600\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28253 to 0.27280, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.2466 - accuracy: 0.9383 - val_loss: 0.2679 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92600 to 0.92676, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27280 to 0.26791, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 124s 7ms/step - loss: 0.2405 - accuracy: 0.9387 - val_loss: 0.2760 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92676\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26791\n",
      "epoch 28\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 113s 7ms/step - loss: 0.2338 - accuracy: 0.9407 - val_loss: 0.2566 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92676 to 0.92862, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26791 to 0.25655, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 113s 7ms/step - loss: 0.2286 - accuracy: 0.9411 - val_loss: 0.2551 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25655 to 0.25505, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 113s 7ms/step - loss: 0.2228 - accuracy: 0.9425 - val_loss: 0.2539 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25505 to 0.25388, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 115s 7ms/step - loss: 0.2175 - accuracy: 0.9432 - val_loss: 0.2461 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25388 to 0.24612, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 113s 7ms/step - loss: 0.2112 - accuracy: 0.9448 - val_loss: 0.2489 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24612\n",
      "epoch 33\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 116s 7ms/step - loss: 0.2076 - accuracy: 0.9447 - val_loss: 0.2598 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24612\n",
      "epoch 34\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.2012 - accuracy: 0.9464 - val_loss: 0.2450 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24612 to 0.24504, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 127s 7ms/step - loss: 0.1962 - accuracy: 0.9474 - val_loss: 0.2430 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24504 to 0.24297, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 36\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 117s 7ms/step - loss: 0.1934 - accuracy: 0.9482 - val_loss: 0.2376 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24297 to 0.23765, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 37\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.1888 - accuracy: 0.9496 - val_loss: 0.2421 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23765\n",
      "epoch 38\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.1837 - accuracy: 0.9502 - val_loss: 0.2337 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23765 to 0.23367, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 39\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.1790 - accuracy: 0.9512 - val_loss: 0.2346 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23367\n",
      "epoch 40\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.1756 - accuracy: 0.9515 - val_loss: 0.2410 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23367\n",
      "epoch 41\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.1712 - accuracy: 0.9535 - val_loss: 0.2300 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23367 to 0.22995, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 42\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 112s 7ms/step - loss: 0.1685 - accuracy: 0.9539 - val_loss: 0.2343 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22995\n",
      "epoch 43\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 115s 7ms/step - loss: 0.1644 - accuracy: 0.9551 - val_loss: 0.2316 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22995\n",
      "epoch 44\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.1605 - accuracy: 0.9557 - val_loss: 0.2348 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22995\n",
      "epoch 45\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 126s 7ms/step - loss: 0.1581 - accuracy: 0.9559 - val_loss: 0.2303 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22995\n",
      "epoch 46\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 116s 7ms/step - loss: 0.1550 - accuracy: 0.9568 - val_loss: 0.2354 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22995\n",
      "epoch 47\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.1514 - accuracy: 0.9577 - val_loss: 0.2347 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22995\n",
      "epoch 48\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.1484 - accuracy: 0.9587 - val_loss: 0.2309 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22995\n",
      "epoch 49\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 113s 7ms/step - loss: 0.1447 - accuracy: 0.9592 - val_loss: 0.2264 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22995 to 0.22635, saving model to D:/mulocdeep/lv1_result11/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 50\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 115s 7ms/step - loss: 0.1432 - accuracy: 0.9596 - val_loss: 0.2313 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 51\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 113s 7ms/step - loss: 0.1389 - accuracy: 0.9609 - val_loss: 0.2283 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 52\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 113s 7ms/step - loss: 0.1367 - accuracy: 0.9618 - val_loss: 0.2382 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 53\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 123s 7ms/step - loss: 0.1336 - accuracy: 0.9626 - val_loss: 0.2328 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 54\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 116s 7ms/step - loss: 0.1317 - accuracy: 0.9630 - val_loss: 0.2348 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 55\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 115s 7ms/step - loss: 0.1286 - accuracy: 0.9644 - val_loss: 0.2347 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 56\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 116s 7ms/step - loss: 0.1268 - accuracy: 0.9645 - val_loss: 0.2359 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 57\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.1256 - accuracy: 0.9644 - val_loss: 0.2269 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 58\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 120s 7ms/step - loss: 0.1231 - accuracy: 0.9646 - val_loss: 0.2340 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 59\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 116s 7ms/step - loss: 0.1186 - accuracy: 0.9665 - val_loss: 0.2495 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 60\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 113s 7ms/step - loss: 0.1181 - accuracy: 0.9663 - val_loss: 0.2331 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 61\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.1154 - accuracy: 0.9674 - val_loss: 0.2369 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 62\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 121s 7ms/step - loss: 0.1142 - accuracy: 0.9672 - val_loss: 0.2359 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 63\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 116s 7ms/step - loss: 0.1107 - accuracy: 0.9687 - val_loss: 0.2439 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 64\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 116s 7ms/step - loss: 0.1104 - accuracy: 0.9683 - val_loss: 0.2446 - val_accuracy: 0.9235\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 65\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.1067 - accuracy: 0.9700 - val_loss: 0.2410 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 66\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 114s 7ms/step - loss: 0.1060 - accuracy: 0.9699 - val_loss: 0.2423 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 67\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.1020 - accuracy: 0.9711 - val_loss: 0.2432 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 68\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.1013 - accuracy: 0.9711 - val_loss: 0.2431 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 69\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.0999 - accuracy: 0.9719 - val_loss: 0.2403 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 70\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 128s 7ms/step - loss: 0.0971 - accuracy: 0.9726 - val_loss: 0.2533 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 71\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.0961 - accuracy: 0.9724 - val_loss: 0.2462 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 72\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.0941 - accuracy: 0.9736 - val_loss: 0.2525 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 73\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 117s 7ms/step - loss: 0.0924 - accuracy: 0.9740 - val_loss: 0.2480 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 74\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.0904 - accuracy: 0.9746 - val_loss: 0.2531 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 75\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.0890 - accuracy: 0.9755 - val_loss: 0.2523 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 76\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 117s 7ms/step - loss: 0.0870 - accuracy: 0.9759 - val_loss: 0.2527 - val_accuracy: 0.9242\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 77\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 116s 7ms/step - loss: 0.0855 - accuracy: 0.9766 - val_loss: 0.2627 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 78\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 129s 8ms/step - loss: 0.0837 - accuracy: 0.9767 - val_loss: 0.2565 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "epoch 79\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.0823 - accuracy: 0.9768 - val_loss: 0.2601 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92862\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22635\n",
      "doing 5th fold\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 1000, 25)     0           dropout_56[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1000, 25)     650         lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 1000, 25)     100         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 1000, 25)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 1000, 25)     0           dropout_57[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1000, 25)     1900        lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 1000, 25)     100         conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 1000, 25)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 1000, 25)     0           dropout_58[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1000, 25)     3150        lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1000, 25)     100         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 1000, 25)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 1000, 25)     0           dropout_59[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1000, 25)     5650        lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1000, 25)     100         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 1000, 25)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 1000, 25)     0           dropout_60[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1000, 25)     9400        lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 1000, 25)     100         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 1000, 25)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 1000, 25)     0           dropout_61[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 1000, 25)     13150       lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1000, 25)     100         conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 1000, 25)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 1000, 25)     0           dropout_62[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1000, 180)    223560      lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 1000, 180)    720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 1000, 180)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 1000, 180)    0           dropout_63[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1000, 180)    390960      lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 1000, 180)    720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 1000, 180)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 1000, 180)    0           dropout_64[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1000, 181)    0           lambda_54[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 41, 180)      0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 1000, 25)     0           dropout_56[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1000, 25)     650         lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 1000, 25)     100         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 1000, 25)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 1000, 25)     0           dropout_57[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1000, 25)     1900        lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 1000, 25)     100         conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 1000, 25)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 1000, 25)     0           dropout_58[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1000, 25)     3150        lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1000, 25)     100         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 1000, 25)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 1000, 25)     0           dropout_59[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1000, 25)     5650        lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1000, 25)     100         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 1000, 25)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 1000, 25)     0           dropout_60[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1000, 25)     9400        lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 1000, 25)     100         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 1000, 25)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 1000, 25)     0           dropout_61[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 1000, 25)     13150       lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1000, 25)     100         conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 1000, 25)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 1000, 25)     0           dropout_62[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1000, 180)    223560      lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 1000, 180)    720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 1000, 180)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 1000, 180)    0           dropout_63[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1000, 180)    390960      lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 1000, 180)    720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 1000, 180)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 1000, 180)    0           dropout_64[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1000, 181)    0           lambda_54[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 41, 180)      0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 129s 7ms/step - loss: 0.7329 - accuracy: 0.6746 - val_loss: 0.6766 - val_accuracy: 0.7692\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76921, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67656, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.6353 - accuracy: 0.8202 - val_loss: 0.6208 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.76921 to 0.82378, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.67656 to 0.62085, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.5946 - accuracy: 0.8549 - val_loss: 0.5803 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82378 to 0.84966, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.62085 to 0.58035, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 132s 8ms/step - loss: 0.5657 - accuracy: 0.8675 - val_loss: 0.5482 - val_accuracy: 0.8703\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84966 to 0.87032, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.58035 to 0.54819, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 122s 7ms/step - loss: 0.5400 - accuracy: 0.8805 - val_loss: 0.5302 - val_accuracy: 0.8867\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87032 to 0.88668, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54819 to 0.53023, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.5147 - accuracy: 0.8887 - val_loss: 0.5081 - val_accuracy: 0.8868\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88668 to 0.88685, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53023 to 0.50808, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.4931 - accuracy: 0.8930 - val_loss: 0.4814 - val_accuracy: 0.8915\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88685 to 0.89150, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50808 to 0.48138, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.4726 - accuracy: 0.8983 - val_loss: 0.4713 - val_accuracy: 0.8908\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89150\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48138 to 0.47128, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 115s 7ms/step - loss: 0.4523 - accuracy: 0.9024 - val_loss: 0.4458 - val_accuracy: 0.9032\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89150 to 0.90325, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47128 to 0.44583, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.4350 - accuracy: 0.9056 - val_loss: 0.4224 - val_accuracy: 0.9046\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90325 to 0.90457, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44583 to 0.42245, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.4175 - accuracy: 0.9090 - val_loss: 0.4112 - val_accuracy: 0.9036\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90457\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42245 to 0.41124, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.4011 - accuracy: 0.9114 - val_loss: 0.3936 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90457 to 0.91097, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41124 to 0.39359, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.3867 - accuracy: 0.9141 - val_loss: 0.3851 - val_accuracy: 0.9125\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91097 to 0.91251, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39359 to 0.38514, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 126s 7ms/step - loss: 0.3720 - accuracy: 0.9168 - val_loss: 0.3752 - val_accuracy: 0.9093\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91251\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38514 to 0.37518, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 115s 7ms/step - loss: 0.3589 - accuracy: 0.9189 - val_loss: 0.3603 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91251\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37518 to 0.36026, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.3455 - accuracy: 0.9209 - val_loss: 0.3509 - val_accuracy: 0.9125\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91251\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36026 to 0.35095, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.3342 - accuracy: 0.9228 - val_loss: 0.3374 - val_accuracy: 0.9188\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91251 to 0.91883, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35095 to 0.33743, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.3228 - accuracy: 0.9255 - val_loss: 0.3286 - val_accuracy: 0.9206\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91883 to 0.92062, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33743 to 0.32859, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.3116 - accuracy: 0.9274 - val_loss: 0.3230 - val_accuracy: 0.9201\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92062\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32859 to 0.32297, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 120s 7ms/step - loss: 0.3029 - accuracy: 0.9281 - val_loss: 0.3103 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92062\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32297 to 0.31026, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 114s 7ms/step - loss: 0.2930 - accuracy: 0.9295 - val_loss: 0.3097 - val_accuracy: 0.9188\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92062\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31026 to 0.30967, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 129s 7ms/step - loss: 0.2848 - accuracy: 0.9308 - val_loss: 0.2969 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92062 to 0.92071, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30967 to 0.29694, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.2753 - accuracy: 0.9327 - val_loss: 0.3008 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92071\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.29694\n",
      "epoch 23\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.2670 - accuracy: 0.9338 - val_loss: 0.2886 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92071 to 0.92084, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29694 to 0.28856, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.2596 - accuracy: 0.9359 - val_loss: 0.2822 - val_accuracy: 0.9213\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92084 to 0.92131, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28856 to 0.28216, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.2525 - accuracy: 0.9367 - val_loss: 0.2842 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92131\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28216\n",
      "epoch 26\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.2458 - accuracy: 0.9381 - val_loss: 0.2711 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92131 to 0.92391, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28216 to 0.27110, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.2399 - accuracy: 0.9386 - val_loss: 0.2670 - val_accuracy: 0.9215\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92391\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27110 to 0.26703, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 28\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.2335 - accuracy: 0.9397 - val_loss: 0.2652 - val_accuracy: 0.9242\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92391 to 0.92421, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26703 to 0.26515, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 129s 7ms/step - loss: 0.2274 - accuracy: 0.9412 - val_loss: 0.2702 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92421 to 0.92468, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26515\n",
      "epoch 30\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 115s 7ms/step - loss: 0.2223 - accuracy: 0.9420 - val_loss: 0.2620 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92468\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26515 to 0.26203, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.2159 - accuracy: 0.9439 - val_loss: 0.2554 - val_accuracy: 0.9235\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92468\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26203 to 0.25536, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.2113 - accuracy: 0.9441 - val_loss: 0.2528 - val_accuracy: 0.9244\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92468\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25536 to 0.25281, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.2056 - accuracy: 0.9460 - val_loss: 0.2522 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92468 to 0.92485, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25281 to 0.25221, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 34\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.2021 - accuracy: 0.9461 - val_loss: 0.2514 - val_accuracy: 0.9251\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92485 to 0.92515, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25221 to 0.25136, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 115s 7ms/step - loss: 0.1969 - accuracy: 0.9470 - val_loss: 0.2514 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92515 to 0.92600, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25136\n",
      "epoch 36\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.1917 - accuracy: 0.9485 - val_loss: 0.2440 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92600\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25136 to 0.24403, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 37\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 131s 8ms/step - loss: 0.1885 - accuracy: 0.9489 - val_loss: 0.2394 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92600 to 0.92690, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24403 to 0.23937, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.1833 - accuracy: 0.9504 - val_loss: 0.2570 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23937\n",
      "epoch 39\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.1790 - accuracy: 0.9511 - val_loss: 0.2377 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23937 to 0.23769, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 40\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.1765 - accuracy: 0.9511 - val_loss: 0.2356 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23769 to 0.23565, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 41\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 115s 7ms/step - loss: 0.1709 - accuracy: 0.9530 - val_loss: 0.2393 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23565\n",
      "epoch 42\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.1688 - accuracy: 0.9531 - val_loss: 0.2390 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23565\n",
      "epoch 43\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 122s 7ms/step - loss: 0.1645 - accuracy: 0.9545 - val_loss: 0.2488 - val_accuracy: 0.9242\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23565\n",
      "epoch 44\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.1606 - accuracy: 0.9552 - val_loss: 0.2391 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23565\n",
      "epoch 45\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 129s 7ms/step - loss: 0.1575 - accuracy: 0.9561 - val_loss: 0.2384 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23565\n",
      "epoch 46\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.1545 - accuracy: 0.9567 - val_loss: 0.2377 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23565\n",
      "epoch 47\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.1519 - accuracy: 0.9575 - val_loss: 0.2337 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23565 to 0.23371, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 48\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.1474 - accuracy: 0.9589 - val_loss: 0.2392 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 49\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 121s 7ms/step - loss: 0.1461 - accuracy: 0.9590 - val_loss: 0.2411 - val_accuracy: 0.9246\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 50\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 124s 7ms/step - loss: 0.1444 - accuracy: 0.9592 - val_loss: 0.2497 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 51\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 121s 7ms/step - loss: 0.1404 - accuracy: 0.9601 - val_loss: 0.2395 - val_accuracy: 0.9235\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 52\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 123s 7ms/step - loss: 0.1360 - accuracy: 0.9619 - val_loss: 0.2433 - val_accuracy: 0.9251\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 53\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 128s 7ms/step - loss: 0.1337 - accuracy: 0.9625 - val_loss: 0.2466 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 54\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 120s 7ms/step - loss: 0.1316 - accuracy: 0.9627 - val_loss: 0.2396 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 55\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.1302 - accuracy: 0.9631 - val_loss: 0.2473 - val_accuracy: 0.9248\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 56\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 120s 7ms/step - loss: 0.1267 - accuracy: 0.9638 - val_loss: 0.2402 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 57\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.1238 - accuracy: 0.9653 - val_loss: 0.2486 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 58\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 120s 7ms/step - loss: 0.1212 - accuracy: 0.9660 - val_loss: 0.2396 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 59\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.1195 - accuracy: 0.9659 - val_loss: 0.2440 - val_accuracy: 0.9193\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 60\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 129s 7ms/step - loss: 0.1172 - accuracy: 0.9668 - val_loss: 0.2476 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 61\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.1151 - accuracy: 0.9674 - val_loss: 0.2384 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 62\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 120s 7ms/step - loss: 0.1130 - accuracy: 0.9682 - val_loss: 0.2411 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 63\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.1111 - accuracy: 0.9684 - val_loss: 0.2417 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 64\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.1102 - accuracy: 0.9686 - val_loss: 0.2499 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 65\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.1085 - accuracy: 0.9689 - val_loss: 0.2553 - val_accuracy: 0.9248\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 66\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.1053 - accuracy: 0.9700 - val_loss: 0.2560 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 67\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.1028 - accuracy: 0.9705 - val_loss: 0.2680 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 68\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 125s 7ms/step - loss: 0.1012 - accuracy: 0.9711 - val_loss: 0.2473 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 69\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.0987 - accuracy: 0.9723 - val_loss: 0.2468 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 70\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.0973 - accuracy: 0.9726 - val_loss: 0.2550 - val_accuracy: 0.9255\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 71\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.0959 - accuracy: 0.9729 - val_loss: 0.2483 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 72\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.0932 - accuracy: 0.9738 - val_loss: 0.2493 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 73\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.0922 - accuracy: 0.9735 - val_loss: 0.2598 - val_accuracy: 0.9244\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 74\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.0899 - accuracy: 0.9750 - val_loss: 0.2519 - val_accuracy: 0.9251\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 75\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.0882 - accuracy: 0.9753 - val_loss: 0.2548 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 76\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 129s 8ms/step - loss: 0.0879 - accuracy: 0.9753 - val_loss: 0.2655 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 77\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.0867 - accuracy: 0.9757 - val_loss: 0.2542 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92690 to 0.92694, saving model to D:/mulocdeep/lv1_result11/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 78\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.0843 - accuracy: 0.9765 - val_loss: 0.2578 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92694\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "epoch 79\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.0825 - accuracy: 0.9769 - val_loss: 0.2620 - val_accuracy: 0.9255\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92694\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23371\n",
      "doing 6th fold\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 1000, 25)     0           dropout_67[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1000, 25)     650         lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1000, 25)     100         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 1000, 25)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 1000, 25)     0           dropout_68[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1000, 25)     1900        lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1000, 25)     100         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 1000, 25)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 1000, 25)     0           dropout_69[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1000, 25)     3150        lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 1000, 25)     100         conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 1000, 25)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 1000, 25)     0           dropout_70[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1000, 25)     5650        lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 1000, 25)     100         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 1000, 25)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 1000, 25)     0           dropout_71[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 1000, 25)     9400        lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 1000, 25)     100         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 1000, 25)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 1000, 25)     0           dropout_72[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1000, 25)     13150       lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1000, 25)     100         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 1000, 25)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 1000, 25)     0           dropout_73[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1000, 180)    223560      lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 1000, 180)    720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 1000, 180)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 1000, 180)    0           dropout_74[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1000, 180)    390960      lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1000, 180)    720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 1000, 180)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 1000, 180)    0           dropout_75[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 181)    0           lambda_63[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 41, 180)      0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 1000, 25)     0           dropout_67[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1000, 25)     650         lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1000, 25)     100         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 1000, 25)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 1000, 25)     0           dropout_68[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1000, 25)     1900        lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1000, 25)     100         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 1000, 25)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 1000, 25)     0           dropout_69[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1000, 25)     3150        lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 1000, 25)     100         conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 1000, 25)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 1000, 25)     0           dropout_70[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1000, 25)     5650        lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 1000, 25)     100         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 1000, 25)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 1000, 25)     0           dropout_71[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 1000, 25)     9400        lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 1000, 25)     100         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 1000, 25)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 1000, 25)     0           dropout_72[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1000, 25)     13150       lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1000, 25)     100         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 1000, 25)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 1000, 25)     0           dropout_73[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1000, 180)    223560      lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 1000, 180)    720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 1000, 180)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 1000, 180)    0           dropout_74[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1000, 180)    390960      lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1000, 180)    720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 1000, 180)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 1000, 180)    0           dropout_75[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 181)    0           lambda_63[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 41, 180)      0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 130s 8ms/step - loss: 0.7333 - accuracy: 0.6880 - val_loss: 0.6979 - val_accuracy: 0.8137\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81369, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69786, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 117s 7ms/step - loss: 0.6385 - accuracy: 0.8240 - val_loss: 0.6528 - val_accuracy: 0.8355\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81369 to 0.83551, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.69786 to 0.65280, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 136s 8ms/step - loss: 0.5973 - accuracy: 0.8498 - val_loss: 0.5658 - val_accuracy: 0.8583\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83551 to 0.85826, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.65280 to 0.56576, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 119s 7ms/step - loss: 0.5672 - accuracy: 0.8658 - val_loss: 0.5447 - val_accuracy: 0.8736\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85826 to 0.87362, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56576 to 0.54466, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 125s 7ms/step - loss: 0.5408 - accuracy: 0.8787 - val_loss: 0.5314 - val_accuracy: 0.8849\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87362 to 0.88492, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54466 to 0.53141, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 124s 7ms/step - loss: 0.5167 - accuracy: 0.8860 - val_loss: 0.4943 - val_accuracy: 0.8923\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88492 to 0.89230, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53141 to 0.49430, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 125s 7ms/step - loss: 0.4948 - accuracy: 0.8915 - val_loss: 0.4742 - val_accuracy: 0.8976\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89230 to 0.89761, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49430 to 0.47424, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 123s 7ms/step - loss: 0.4745 - accuracy: 0.8961 - val_loss: 0.4600 - val_accuracy: 0.9009\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89761 to 0.90088, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47424 to 0.46003, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 118s 7ms/step - loss: 0.4555 - accuracy: 0.9006 - val_loss: 0.4403 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90088 to 0.90638, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46003 to 0.44028, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 117s 7ms/step - loss: 0.4371 - accuracy: 0.9052 - val_loss: 0.4212 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90638 to 0.90838, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44028 to 0.42122, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 128s 7ms/step - loss: 0.4204 - accuracy: 0.9074 - val_loss: 0.4069 - val_accuracy: 0.9096\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90838 to 0.90962, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42122 to 0.40685, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 115s 7ms/step - loss: 0.4049 - accuracy: 0.9103 - val_loss: 0.3938 - val_accuracy: 0.9134\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90962 to 0.91341, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40685 to 0.39377, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 116s 7ms/step - loss: 0.3896 - accuracy: 0.9125 - val_loss: 0.3821 - val_accuracy: 0.9147\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91341 to 0.91472, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39377 to 0.38208, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 117s 7ms/step - loss: 0.3744 - accuracy: 0.9164 - val_loss: 0.3717 - val_accuracy: 0.9154\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91472 to 0.91536, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38208 to 0.37170, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 116s 7ms/step - loss: 0.3613 - accuracy: 0.9181 - val_loss: 0.3599 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91536 to 0.91728, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37170 to 0.35995, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 117s 7ms/step - loss: 0.3479 - accuracy: 0.9210 - val_loss: 0.3451 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91728\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35995 to 0.34511, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 117s 7ms/step - loss: 0.3362 - accuracy: 0.9225 - val_loss: 0.3394 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91728 to 0.91828, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34511 to 0.33944, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 121s 7ms/step - loss: 0.3245 - accuracy: 0.9243 - val_loss: 0.3235 - val_accuracy: 0.9190\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91828 to 0.91903, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from 0.33944 to 0.32353, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 136s 8ms/step - loss: 0.3145 - accuracy: 0.9256 - val_loss: 0.3134 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91903 to 0.92426, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32353 to 0.31341, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 118s 7ms/step - loss: 0.3041 - accuracy: 0.9274 - val_loss: 0.3040 - val_accuracy: 0.9241\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92426\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31341 to 0.30397, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 120s 7ms/step - loss: 0.2949 - accuracy: 0.9285 - val_loss: 0.3014 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92426\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30397 to 0.30142, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.2856 - accuracy: 0.9306 - val_loss: 0.2942 - val_accuracy: 0.9251\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92426 to 0.92514, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30142 to 0.29424, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.2774 - accuracy: 0.9319 - val_loss: 0.2899 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92514 to 0.92562, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29424 to 0.28986, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.2691 - accuracy: 0.9334 - val_loss: 0.2813 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92562 to 0.92670, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28986 to 0.28127, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 123s 7ms/step - loss: 0.2603 - accuracy: 0.9352 - val_loss: 0.2735 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92670 to 0.92813, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28127 to 0.27352, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 128s 7ms/step - loss: 0.2535 - accuracy: 0.9366 - val_loss: 0.2748 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92813\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27352\n",
      "epoch 26\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 124s 7ms/step - loss: 0.2471 - accuracy: 0.9372 - val_loss: 0.2658 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92813\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27352 to 0.26582, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.2407 - accuracy: 0.9386 - val_loss: 0.2586 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92813 to 0.92945, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26582 to 0.25859, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 28\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.2356 - accuracy: 0.9392 - val_loss: 0.2667 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92945\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25859\n",
      "epoch 29\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 124s 7ms/step - loss: 0.2291 - accuracy: 0.9407 - val_loss: 0.2559 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92945\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25859 to 0.25593, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 123s 7ms/step - loss: 0.2227 - accuracy: 0.9416 - val_loss: 0.2503 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92945 to 0.93061, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25593 to 0.25031, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.2181 - accuracy: 0.9425 - val_loss: 0.2495 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93061\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25031 to 0.24954, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 125s 7ms/step - loss: 0.2124 - accuracy: 0.9436 - val_loss: 0.2488 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93061\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24954 to 0.24878, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 133s 8ms/step - loss: 0.2067 - accuracy: 0.9461 - val_loss: 0.2498 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93061\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24878\n",
      "epoch 34\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 121s 7ms/step - loss: 0.2028 - accuracy: 0.9459 - val_loss: 0.2410 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93061 to 0.93069, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24878 to 0.24096, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 123s 7ms/step - loss: 0.1980 - accuracy: 0.9463 - val_loss: 0.2412 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93069\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24096\n",
      "epoch 36\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 120s 7ms/step - loss: 0.1931 - accuracy: 0.9477 - val_loss: 0.2390 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93069\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24096 to 0.23905, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 37\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.1892 - accuracy: 0.9483 - val_loss: 0.2477 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93069\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23905\n",
      "epoch 38\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17077/17077 [==============================] - 121s 7ms/step - loss: 0.1845 - accuracy: 0.9501 - val_loss: 0.2374 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93069\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23905 to 0.23742, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 39\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 120s 7ms/step - loss: 0.1802 - accuracy: 0.9507 - val_loss: 0.2368 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93069\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23742 to 0.23684, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 40\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 119s 7ms/step - loss: 0.1777 - accuracy: 0.9512 - val_loss: 0.2345 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93069\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23684 to 0.23449, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 41\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 124s 7ms/step - loss: 0.1730 - accuracy: 0.9522 - val_loss: 0.2435 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93069\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23449\n",
      "epoch 42\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 113s 7ms/step - loss: 0.1694 - accuracy: 0.9532 - val_loss: 0.2373 - val_accuracy: 0.9248\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93069\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23449\n",
      "epoch 43\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 114s 7ms/step - loss: 0.1655 - accuracy: 0.9541 - val_loss: 0.2298 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93069\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23449 to 0.22975, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 44\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 115s 7ms/step - loss: 0.1620 - accuracy: 0.9551 - val_loss: 0.2340 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93069\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22975\n",
      "epoch 45\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 115s 7ms/step - loss: 0.1580 - accuracy: 0.9563 - val_loss: 0.2303 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93069 to 0.93089, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22975\n",
      "epoch 46\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 116s 7ms/step - loss: 0.1556 - accuracy: 0.9566 - val_loss: 0.2344 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22975\n",
      "epoch 47\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 114s 7ms/step - loss: 0.1536 - accuracy: 0.9571 - val_loss: 0.2413 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22975\n",
      "epoch 48\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 114s 7ms/step - loss: 0.1498 - accuracy: 0.9581 - val_loss: 0.2367 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22975\n",
      "epoch 49\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 127s 7ms/step - loss: 0.1469 - accuracy: 0.9591 - val_loss: 0.2344 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22975\n",
      "epoch 50\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 114s 7ms/step - loss: 0.1435 - accuracy: 0.9599 - val_loss: 0.2412 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22975\n",
      "epoch 51\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 115s 7ms/step - loss: 0.1402 - accuracy: 0.9609 - val_loss: 0.2309 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22975\n",
      "epoch 52\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 116s 7ms/step - loss: 0.1392 - accuracy: 0.9604 - val_loss: 0.2305 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22975\n",
      "epoch 53\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 115s 7ms/step - loss: 0.1355 - accuracy: 0.9618 - val_loss: 0.2294 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22975 to 0.22942, saving model to D:/mulocdeep/lv1_result11/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 54\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 116s 7ms/step - loss: 0.1325 - accuracy: 0.9625 - val_loss: 0.2389 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 55\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 115s 7ms/step - loss: 0.1298 - accuracy: 0.9632 - val_loss: 0.2317 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 56\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 114s 7ms/step - loss: 0.1270 - accuracy: 0.9644 - val_loss: 0.2392 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 57\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 127s 7ms/step - loss: 0.1254 - accuracy: 0.9643 - val_loss: 0.2336 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 58\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 114s 7ms/step - loss: 0.1244 - accuracy: 0.9643 - val_loss: 0.2355 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 59\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 116s 7ms/step - loss: 0.1217 - accuracy: 0.9650 - val_loss: 0.2307 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 60\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 121s 7ms/step - loss: 0.1181 - accuracy: 0.9663 - val_loss: 0.2335 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 61\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 123s 7ms/step - loss: 0.1171 - accuracy: 0.9661 - val_loss: 0.2381 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 62\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 125s 7ms/step - loss: 0.1150 - accuracy: 0.9669 - val_loss: 0.2417 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 63\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17077/17077 [==============================] - 124s 7ms/step - loss: 0.1134 - accuracy: 0.9674 - val_loss: 0.2376 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 64\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 124s 7ms/step - loss: 0.1100 - accuracy: 0.9687 - val_loss: 0.2416 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 65\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 126s 7ms/step - loss: 0.1073 - accuracy: 0.9695 - val_loss: 0.2382 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 66\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 121s 7ms/step - loss: 0.1060 - accuracy: 0.9699 - val_loss: 0.2398 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 67\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 123s 7ms/step - loss: 0.1044 - accuracy: 0.9698 - val_loss: 0.2362 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 68\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 121s 7ms/step - loss: 0.1015 - accuracy: 0.9713 - val_loss: 0.2485 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 69\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 123s 7ms/step - loss: 0.1005 - accuracy: 0.9718 - val_loss: 0.2395 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 70\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 120s 7ms/step - loss: 0.0976 - accuracy: 0.9730 - val_loss: 0.2487 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 71\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 120s 7ms/step - loss: 0.0978 - accuracy: 0.9718 - val_loss: 0.2486 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 72\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 124s 7ms/step - loss: 0.0960 - accuracy: 0.9729 - val_loss: 0.2446 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 73\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 120s 7ms/step - loss: 0.0943 - accuracy: 0.9733 - val_loss: 0.2391 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 74\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 120s 7ms/step - loss: 0.0911 - accuracy: 0.9741 - val_loss: 0.2360 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 75\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 120s 7ms/step - loss: 0.0906 - accuracy: 0.9743 - val_loss: 0.2476 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 76\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 120s 7ms/step - loss: 0.0893 - accuracy: 0.9745 - val_loss: 0.2489 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 77\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 121s 7ms/step - loss: 0.0874 - accuracy: 0.9752 - val_loss: 0.2473 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 78\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.0854 - accuracy: 0.9761 - val_loss: 0.2451 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "epoch 79\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 120s 7ms/step - loss: 0.0838 - accuracy: 0.9761 - val_loss: 0.2492 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93089\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22942\n",
      "doing 7th fold\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 1000, 25)     0           dropout_78[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1000, 25)     650         lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 1000, 25)     100         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 1000, 25)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 1000, 25)     0           dropout_79[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1000, 25)     1900        lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 1000, 25)     100         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 1000, 25)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 1000, 25)     0           dropout_80[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1000, 25)     3150        lambda_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1000, 25)     100         conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 1000, 25)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 1000, 25)     0           dropout_81[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 1000, 25)     5650        lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1000, 25)     100         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 1000, 25)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 1000, 25)     0           dropout_82[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1000, 25)     9400        lambda_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 1000, 25)     100         conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 1000, 25)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 1000, 25)     0           dropout_83[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1000, 25)     13150       lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 1000, 25)     100         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 1000, 25)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 1000, 25)     0           dropout_84[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1000, 180)    223560      lambda_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 1000, 180)    720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 1000, 180)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 1000, 180)    0           dropout_85[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1000, 180)    390960      lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 1000, 180)    720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 1000, 180)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 1000, 180)    0           dropout_86[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1000, 181)    0           lambda_72[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 41, 180)      0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 1000, 25)     0           dropout_78[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1000, 25)     650         lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 1000, 25)     100         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 1000, 25)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 1000, 25)     0           dropout_79[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1000, 25)     1900        lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 1000, 25)     100         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 1000, 25)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 1000, 25)     0           dropout_80[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1000, 25)     3150        lambda_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1000, 25)     100         conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 1000, 25)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 1000, 25)     0           dropout_81[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 1000, 25)     5650        lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1000, 25)     100         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 1000, 25)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 1000, 25)     0           dropout_82[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1000, 25)     9400        lambda_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 1000, 25)     100         conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 1000, 25)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 1000, 25)     0           dropout_83[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1000, 25)     13150       lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 1000, 25)     100         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 1000, 25)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 1000, 25)     0           dropout_84[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1000, 180)    223560      lambda_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 1000, 180)    720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 1000, 180)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 1000, 180)    0           dropout_85[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1000, 180)    390960      lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 1000, 180)    720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 1000, 180)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 1000, 180)    0           dropout_86[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1000, 181)    0           lambda_72[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 41, 180)      0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 137s 8ms/step - loss: 0.7517 - accuracy: 0.6720 - val_loss: 0.6893 - val_accuracy: 0.7934\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79340, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68933, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.6471 - accuracy: 0.8180 - val_loss: 0.6616 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.79340 to 0.84972, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.68933 to 0.66156, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 125s 7ms/step - loss: 0.6041 - accuracy: 0.8509 - val_loss: 0.5921 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84972 to 0.86043, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66156 to 0.59206, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 120s 7ms/step - loss: 0.5709 - accuracy: 0.8648 - val_loss: 0.5620 - val_accuracy: 0.8671\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86043 to 0.86711, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.59206 to 0.56199, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.5427 - accuracy: 0.8773 - val_loss: 0.5159 - val_accuracy: 0.8906\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86711 to 0.89055, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56199 to 0.51590, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.5168 - accuracy: 0.8869 - val_loss: 0.4983 - val_accuracy: 0.8935\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89055 to 0.89352, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51590 to 0.49827, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 128s 8ms/step - loss: 0.4961 - accuracy: 0.8915 - val_loss: 0.4830 - val_accuracy: 0.8908\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89352\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49827 to 0.48297, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 116s 7ms/step - loss: 0.4753 - accuracy: 0.8969 - val_loss: 0.4576 - val_accuracy: 0.9032\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89352 to 0.90316, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48297 to 0.45762, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 115s 7ms/step - loss: 0.4561 - accuracy: 0.9011 - val_loss: 0.4396 - val_accuracy: 0.9044\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90316 to 0.90439, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45762 to 0.43964, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 115s 7ms/step - loss: 0.4386 - accuracy: 0.9047 - val_loss: 0.4222 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90439 to 0.91170, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43964 to 0.42222, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 115s 7ms/step - loss: 0.4222 - accuracy: 0.9080 - val_loss: 0.4107 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91170\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42222 to 0.41067, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 115s 7ms/step - loss: 0.4062 - accuracy: 0.9107 - val_loss: 0.3955 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91170 to 0.91443, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41067 to 0.39554, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 114s 7ms/step - loss: 0.3912 - accuracy: 0.9130 - val_loss: 0.3808 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91443 to 0.91794, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39554 to 0.38080, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 114s 7ms/step - loss: 0.3780 - accuracy: 0.9150 - val_loss: 0.3719 - val_accuracy: 0.9154\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91794\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38080 to 0.37191, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 114s 7ms/step - loss: 0.3644 - accuracy: 0.9177 - val_loss: 0.3600 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91794 to 0.91893, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37191 to 0.35998, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 116s 7ms/step - loss: 0.3520 - accuracy: 0.9201 - val_loss: 0.3461 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91893 to 0.91988, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35998 to 0.34609, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.3401 - accuracy: 0.9213 - val_loss: 0.3353 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91988 to 0.92281, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34609 to 0.33532, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 116s 7ms/step - loss: 0.3287 - accuracy: 0.9236 - val_loss: 0.3305 - val_accuracy: 0.9255\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92281 to 0.92549, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33532 to 0.33049, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 114s 7ms/step - loss: 0.3167 - accuracy: 0.9262 - val_loss: 0.3199 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92549\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33049 to 0.31988, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.3066 - accuracy: 0.9274 - val_loss: 0.3108 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92549\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31988 to 0.31079, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 117s 7ms/step - loss: 0.2984 - accuracy: 0.9285 - val_loss: 0.2997 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92549 to 0.92640, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31079 to 0.29971, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.2890 - accuracy: 0.9305 - val_loss: 0.2954 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92640\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29971 to 0.29537, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.2804 - accuracy: 0.9313 - val_loss: 0.2978 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92640\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.29537\n",
      "epoch 23\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 124s 7ms/step - loss: 0.2719 - accuracy: 0.9331 - val_loss: 0.2877 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92640\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29537 to 0.28770, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 124s 7ms/step - loss: 0.2641 - accuracy: 0.9346 - val_loss: 0.2805 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92640 to 0.92751, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28770 to 0.28049, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 125s 7ms/step - loss: 0.2572 - accuracy: 0.9354 - val_loss: 0.2756 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92751\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28049 to 0.27560, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 124s 7ms/step - loss: 0.2500 - accuracy: 0.9368 - val_loss: 0.2676 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92751 to 0.92822, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27560 to 0.26759, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 125s 7ms/step - loss: 0.2436 - accuracy: 0.9378 - val_loss: 0.2628 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92822 to 0.92838, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26759 to 0.26275, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 28\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.2372 - accuracy: 0.9395 - val_loss: 0.2624 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92838 to 0.92866, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26275 to 0.26242, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 124s 7ms/step - loss: 0.2328 - accuracy: 0.9395 - val_loss: 0.2592 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92866\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26242 to 0.25917, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 125s 7ms/step - loss: 0.2265 - accuracy: 0.9404 - val_loss: 0.2609 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92866\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25917\n",
      "epoch 31\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 132s 8ms/step - loss: 0.2207 - accuracy: 0.9420 - val_loss: 0.2531 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92866\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25917 to 0.25315, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 127s 7ms/step - loss: 0.2141 - accuracy: 0.9439 - val_loss: 0.2457 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92866 to 0.93047, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25315 to 0.24566, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.2088 - accuracy: 0.9450 - val_loss: 0.2463 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24566\n",
      "epoch 34\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.2041 - accuracy: 0.9457 - val_loss: 0.2433 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24566 to 0.24334, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.2003 - accuracy: 0.9465 - val_loss: 0.2476 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24334\n",
      "epoch 36\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.1953 - accuracy: 0.9483 - val_loss: 0.2394 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24334 to 0.23938, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 37\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 125s 7ms/step - loss: 0.1911 - accuracy: 0.9481 - val_loss: 0.2384 - val_accuracy: 0.9298\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23938 to 0.23838, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 38\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.1856 - accuracy: 0.9493 - val_loss: 0.2383 - val_accuracy: 0.9289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23838 to 0.23832, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 39\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 135s 8ms/step - loss: 0.1815 - accuracy: 0.9506 - val_loss: 0.2359 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23832 to 0.23590, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 40\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.1785 - accuracy: 0.9512 - val_loss: 0.2386 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23590\n",
      "epoch 41\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.1751 - accuracy: 0.9523 - val_loss: 0.2379 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23590\n",
      "epoch 42\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.1710 - accuracy: 0.9527 - val_loss: 0.2388 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23590\n",
      "epoch 43\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 124s 7ms/step - loss: 0.1676 - accuracy: 0.9538 - val_loss: 0.2324 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23590 to 0.23239, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 44\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.1637 - accuracy: 0.9543 - val_loss: 0.2302 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23239 to 0.23023, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 45\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.1607 - accuracy: 0.9551 - val_loss: 0.2288 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.23023 to 0.22877, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 46\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 131s 8ms/step - loss: 0.1573 - accuracy: 0.9563 - val_loss: 0.2310 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22877\n",
      "epoch 47\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.1534 - accuracy: 0.9572 - val_loss: 0.2291 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22877\n",
      "epoch 48\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 124s 7ms/step - loss: 0.1509 - accuracy: 0.9580 - val_loss: 0.2410 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22877\n",
      "epoch 49\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.1478 - accuracy: 0.9588 - val_loss: 0.2279 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22877 to 0.22789, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 50\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.1436 - accuracy: 0.9599 - val_loss: 0.2294 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22789\n",
      "epoch 51\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.1423 - accuracy: 0.9598 - val_loss: 0.2325 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22789\n",
      "epoch 52\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.1385 - accuracy: 0.9611 - val_loss: 0.2319 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22789\n",
      "epoch 53\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.1355 - accuracy: 0.9618 - val_loss: 0.2399 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22789\n",
      "epoch 54\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 135s 8ms/step - loss: 0.1348 - accuracy: 0.9618 - val_loss: 0.2295 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22789\n",
      "epoch 55\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.1313 - accuracy: 0.9630 - val_loss: 0.2377 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22789\n",
      "epoch 56\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.1282 - accuracy: 0.9641 - val_loss: 0.2248 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93047 to 0.93095, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22789 to 0.22477, saving model to D:/mulocdeep/lv1_result11/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 57\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.1264 - accuracy: 0.9647 - val_loss: 0.2375 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 58\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.1238 - accuracy: 0.9647 - val_loss: 0.2322 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 59\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 123s 7ms/step - loss: 0.1218 - accuracy: 0.9654 - val_loss: 0.2326 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 60\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.1190 - accuracy: 0.9667 - val_loss: 0.2365 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 61\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.1177 - accuracy: 0.9669 - val_loss: 0.2301 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 62\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 131s 8ms/step - loss: 0.1147 - accuracy: 0.9676 - val_loss: 0.2485 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 63\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.1136 - accuracy: 0.9675 - val_loss: 0.2407 - val_accuracy: 0.9303\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 64\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 120s 7ms/step - loss: 0.1120 - accuracy: 0.9680 - val_loss: 0.2394 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 65\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.1084 - accuracy: 0.9696 - val_loss: 0.2382 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 66\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 119s 7ms/step - loss: 0.1066 - accuracy: 0.9701 - val_loss: 0.2445 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 67\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 119s 7ms/step - loss: 0.1053 - accuracy: 0.9702 - val_loss: 0.2380 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 68\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.1015 - accuracy: 0.9718 - val_loss: 0.2364 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 69\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 128s 7ms/step - loss: 0.1015 - accuracy: 0.9716 - val_loss: 0.2360 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 70\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.0997 - accuracy: 0.9718 - val_loss: 0.2492 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 71\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.0977 - accuracy: 0.9724 - val_loss: 0.2426 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 72\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.0956 - accuracy: 0.9732 - val_loss: 0.2421 - val_accuracy: 0.9298\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 73\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.0944 - accuracy: 0.9734 - val_loss: 0.2397 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 74\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 120s 7ms/step - loss: 0.0929 - accuracy: 0.9740 - val_loss: 0.2458 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 75\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.0905 - accuracy: 0.9747 - val_loss: 0.2524 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 76\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 120s 7ms/step - loss: 0.0889 - accuracy: 0.9753 - val_loss: 0.2478 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 77\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 130s 8ms/step - loss: 0.0877 - accuracy: 0.9758 - val_loss: 0.2421 - val_accuracy: 0.9296\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 78\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 120s 7ms/step - loss: 0.0870 - accuracy: 0.9753 - val_loss: 0.2483 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n",
      "epoch 79\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 120s 7ms/step - loss: 0.0847 - accuracy: 0.9765 - val_loss: 0.2430 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22477\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-accused",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
