{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "import math\n",
    "from itertools import product\n",
    "import argparse\n",
    "import sys\n",
    "from utils_res_CS import *\n",
    "import calendar\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "damaged-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eachseq(seq,pssmfile,mask_seq,new_pssms):\n",
    "    if os.path.exists(pssmfile):  #如果pssm文件存在\n",
    "        print(\"found \" + pssmfile + \"\\n\")  #输出找到pssm文件+换行\n",
    "        pssm = readPSSM(pssmfile)  #读取pssm文件\n",
    "    else:  #否则\n",
    "        print(\"using Blosum62\\n\")  #输出使用Blosum62+换行\n",
    "        #pssm = convertSampleToBlosum62(seq)  #把Blosum62矩阵当作pssm用\n",
    "        pssm = convertSampleToCBOW(seq)\n",
    "    pssm = pssm.astype(float)  #对pssm的数据类型转换为浮点型\n",
    "    PhyChem = convertSampleToPhysicsVector_pca(seq)  #将样本转化为物理向量\n",
    "    pssm = np.concatenate((PhyChem, pssm), axis=1)  #物化指标和pssm对应行进行数组拼接\n",
    "    seql = len(seq)   #序列长度  \n",
    "    if seql <= 1000:  #如果序列长度小于等于1000\n",
    "        padnum = 1000 - seql  #pad大小为1000-序列长度\n",
    "        padmatrix = np.zeros([padnum, 25])  #pad矩阵为行数为padnum，列数为25的全0矩阵，即用0填充不足的地方\n",
    "        pssm = np.concatenate((pssm, padmatrix), axis=0)  #物化指标和pssm进行数组拼接 \n",
    "        new_pssms.append(pssm)  #新的pssm空列表中添加pssm矩阵\n",
    "        mask_seq.append(gen_mask_mat(seql, padnum))  #mask序列空列表添加gen_mask矩阵，序列长度为行数，padnum为列数？？？\n",
    "    else:  #如果序列长度大于1000\n",
    "        pssm = np.concatenate((pssm[0:500, :], pssm[seql - 500:seql, :]), axis=0)  #pssm矩阵为前500行和后500行矩阵的拼接\n",
    "        new_pssms.append(pssm)  #新的pssm空列表中添加pssm矩阵\n",
    "        mask_seq.append(gen_mask_mat(1000, 0))  #mask序列空列表添加1000行0列的？？？gen_mask矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metric-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpad(seqfile, labelfile, pssmdir=\"\", npzfile = \"\"): #定义endpad(序列文件，标签文件，pssm路径，npz文件)\n",
    "    if not os.path.exists(npzfile):  #如果npz文件不存在，建立新的pssm空列表，标签空列表，mask序列空列表，id空列表\n",
    "        new_pssms = []\n",
    "        labels = []\n",
    "        mask_seq = []\n",
    "        ids=[]\n",
    "        seqs=[]\n",
    "        f = open(seqfile, \"r\")  #f为打开序列文件\n",
    "        f2 = open(labelfile, \"r\")  #f2为打开标签文件\n",
    "        line = f.readline()  #读取序列文件的第一行\n",
    "        while line != '':\n",
    "            pssmfile = pssmdir + line[1:].strip() + \"_pssm.txt\"  #pssm文件名=pssm地址+id名+_pssm.txt\n",
    "            if line[0] == '>':  #如果该行第一个字符为>\n",
    "                id = line.strip()[1:]  #id为去掉>的字符\n",
    "                ids.append(id)   #在id空列表中添加id\n",
    "            label = f2.readline().strip()  #标签为f2（标签文件）中去掉首尾空格的内容\n",
    "            labels.append(label)  #在标签空列表中添加标签\n",
    "            seq = f.readline().strip()  #第一次seq为第2行的内容，实际seq为>行的下一行\n",
    "            #seql = len(seq)   #序列长度  \n",
    "            process_eachseq(seq,pssmfile,mask_seq,new_pssms)\n",
    "            line = f.readline()  #继续读取下一行，即>行\n",
    "        x = np.array(new_pssms)  #把new_pssms列表变为数组，赋给x\n",
    "        y = [convertlabels_to_categorical(i) for i in labels]  #把标签列表转化为类别(i)\n",
    "        y = np.array(y)  #再把类别转化为数组\n",
    "        mask = np.array(mask_seq)  #把mask_seq（标注的序列？）转化为数组\n",
    "        np.savez(npzfile, x=x, y=y, mask=mask, ids=ids)  #保存多个数组到同一个文件中,保存格式是.npz\n",
    "        return [x, y, mask,ids]  #返回pssm矩阵，类别，标注序列，名字id\n",
    "    else:  #如果上述都存在，直接转化为数组\n",
    "        mask = np.load(npzfile)['mask']\n",
    "        x = np.load(npzfile)['x']\n",
    "        y = np.load(npzfile)['y']\n",
    "        ids=np.load(npzfile)['ids']\n",
    "        return [x, y, mask,ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "warming-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MULocDeep(lv1_dir,lv2_dir,pssm_dir,output_dir,foldnum):\n",
    "    # get small data\n",
    "    [train_x, train_y, train_mask, train_ids] = endpad(\n",
    "        lv2_dir+\"lv2_train_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv2_dir+\"lv2_train_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv2_train_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    [val_x, val_y, val_mask,val_ids] = endpad(\n",
    "        lv2_dir+\"lv2_val_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv2_dir+\"lv2_val_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv2_val_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "\n",
    "    # get big data 训练10分类的多分类\n",
    "    [train_x_big, train_y_big, train_mask_big, train_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv1_train_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    [val_x_big, val_y_big, val_mask_big, val_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv1_val_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model_big, model_small = singlemodel(train_x)  #模型为singlemodel\n",
    "\n",
    "    filepath_acc_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_acc_small_lv2 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_small_lv2_acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_loss_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_loss-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_loss_small_lv2 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_small_lv2_loss-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "    checkpoint_acc_big_lev1 = ModelCheckpoint(filepath_acc_big_lv1, monitor='val_accuracy', save_best_only=True,\n",
    "                                          mode='max',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "\n",
    "    checkpoint_acc_small_lev2 = ModelCheckpoint(filepath_acc_small_lv2, monitor='val_lev2_accuracy', save_best_only=True,\n",
    "                                          mode='max',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    checkpoint_loss_big_lev1 = ModelCheckpoint(filepath_loss_big_lv1, monitor='val_loss', save_best_only=True,\n",
    "                                          mode='min',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    checkpoint_loss_small_lev2 = ModelCheckpoint(filepath_loss_small_lv2, monitor='val_lev2_loss', save_best_only=True,\n",
    "                                          mode='min',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    \n",
    "    for i in range(20):\n",
    "        # train small model\n",
    "        print(\"epoch \"+str(i)+\"\\n\")\n",
    "        '''fitHistory_batch_small = model_small.fit([train_x, train_mask.reshape(-1, 1000, 1)],\n",
    "                                                 [train_y,getTrue4out1(train_y)],\n",
    "                                                 batch_size=batch_size, epochs=1,\n",
    "                                                 validation_data=(\n",
    "                                                 [val_x, val_mask.reshape(-1, 1000, 1)], [val_y,getTrue4out1(val_y)]),\n",
    "                                                 callbacks=[checkpoint_acc_small_lev2,checkpoint_loss_small_lev2],verbose=1)'''\n",
    "        \n",
    "        # train big model  \n",
    "        fitHistory_batch_big = model_big.fit([train_x_big, train_mask_big.reshape(-1, 1000, 1)],\n",
    "                                             [getTrue4out1(train_y_big)],  #为何大模型没有train_y_big\n",
    "                                             batch_size=batch_size, epochs=1,  #等于1？？\n",
    "                                             validation_data=(\n",
    "                                             [val_x_big, val_mask_big.reshape(-1, 1000, 1)], [getTrue4out1(val_y_big)]),  #也没有val_y_big\n",
    "                                             callbacks=[checkpoint_acc_big_lev1,checkpoint_loss_big_lev1], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alert-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_var(input_var,pssm_dir,output_dir,foldnum):\n",
    "    # get small data\n",
    "    [train_x,train_y,train_mask,train_ids]=endpad(input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_seq\",\n",
    "                                        input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_label\",\n",
    "                                        pssm_dir,\n",
    "                                        \"D:/deeploc/deeploc_40nr_8folds/train_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    [val_x,val_y,val_mask,val_ids]=endpad(input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_seq\",\n",
    "                                  input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_label\",\n",
    "                                  pssm_dir,\n",
    "                                  \"D:/deeploc/deeploc_40nr_8folds/val_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model = var_model(train_x)   #这里的模型是var_model\n",
    "\n",
    "    filepath_acc = output_dir+\"fold\" + str(foldnum) + \"acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "    checkpoint_acc = ModelCheckpoint(filepath_acc, monitor='val_accuracy', save_best_only=True, mode='max',\n",
    "                                 save_weights_only=True, verbose=1)\n",
    "    fitHistory_batch = model.fit([train_x,train_mask.reshape(-1,1000,1)],getTrue4out1(train_y),\n",
    "                                 batch_size=batch_size, epochs=20,\n",
    "                                 validation_data=([val_x,val_mask.reshape(-1,1000,1)], getTrue4out1(val_y)),\n",
    "                                 callbacks=[checkpoint_acc],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spiritual-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''我们常常可以把argparse的使用简化成下面四个步骤\n",
    "       1：import argparse\n",
    "       2：parser = argparse.ArgumentParser()\n",
    "       3：parser.add_argument()\n",
    "       4：parser.parse_args()\n",
    "       上面四个步骤解释如下：首先导入该模块；然后创建一个解析对象；然后向该对象中添加你要关注的命令行参数和选项，\n",
    "       每一个add_argument方法对应一个你要关注的参数或选项；最后调用parse_args()方法进行解析；解析成功之后即可使用'''\n",
    "    \n",
    "def main():\n",
    "    #加default\n",
    "    # description= 这个参数简要描述这个程度做什么以及怎么做\n",
    "    parser=argparse.ArgumentParser(\n",
    "        description='MULocDeep: interpretable protein localization classifier at sub-cellular and sub-organellar levels')\n",
    "    #MULocDeep_model  UniLoc-train-20nr\n",
    "    #--lv1_input_dir/--lv2_input_dir 亚细胞训练数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--lv1_input_dir', dest='lv1_dir', type=str, \n",
    "                        default=\"D:/mulocdeep/mul_data\",\n",
    "                        help='sub-cellular training data, contains 8 folds protein sequences and labels', required=False)\n",
    "    parser.add_argument('--lv2_input_dir', dest='lv2_dir', type=str,\n",
    "                       default=\"D:/mulocdeep/mul_data\",\n",
    "                       help='sub-cellular training data, contains 8 folds protein sequences and labels', required=False)\n",
    "    #--MULocDeep_model 添加它来训练MULocDeep模型，否则训练一个var模型\n",
    "    parser.add_argument('--MULocDeep_model', dest='modeltype', action='store_false',  #触发，store_true会触发DeepLoc\n",
    "                        #如果是store_false,则默认值是True，如果是store_true,则默认值是False  \n",
    "                        help='Add this to train the MULocDeep model, otherwise train a variant model', required=False)\n",
    "    #--model_output 受过训练的模型存储的目录的名称  需自己添加\n",
    "    parser.add_argument('--model_output', dest='outputdir', type=str, \n",
    "                       default=\"D:/mulocdeep/lv1_result4\",\n",
    "                       help='the name of the directory where the trained model stores', required=False)  #由True改成False\n",
    "    \n",
    "    parser.add_argument('-existPSSM', dest='existPSSM', type=str,\n",
    "                        default=\"D:/mulocdeep/mulocdeep_pssm_empty\",\n",
    "                        help='the name of the existing PSSM directory if there is one.', required=False)\n",
    "    \n",
    "    #var_model  deeploc_40nr_8folds\n",
    "    #--input_dir 训练var模型的数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--input_var', dest='var_dir', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_40nr_8folds\",\n",
    "                        help='data for traing the variant model, contains 8 folds protein sequences and labels', required=False)\n",
    "    #改true  并且还需要加一个model_ouput  一个是deeploc  一个是MULocDeep\n",
    "    parser.add_argument('--var_model_output', dest='var_outputdir', type=str, help='the name of the directory where the trained model stores', \n",
    "                        default=\"D:/deeploc/var_model_result1\",\n",
    "                        required=False)  #由True改成False\n",
    "    parser.add_argument('-var_existPSSM', dest='var_existPSSM', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_pssm\",\n",
    "                        help='the name of the existing PSSM directory if there is one.', required=False)\n",
    "    parser.set_defaults(feature=True)\n",
    "    #args = parser.parse_args()   #改\n",
    "    args = parser.parse_known_args()[0]   #jupyter下运行解析需要此代码\n",
    "    model_type=args.modeltype\n",
    "    input_lv1=args.lv1_dir\n",
    "    input_lv2 = args.lv2_dir\n",
    "    outputdir=args.outputdir\n",
    "    existPSSM = args.existPSSM\n",
    "    input_var=args.var_dir\n",
    "    var_outputdir=args.var_outputdir\n",
    "    var_existPSSM = args.var_existPSSM\n",
    "\n",
    "    if model_type==True:\n",
    "        if not input_lv1[len(input_lv1) - 1] == \"/\":\n",
    "            input_lv1 = input_lv1 + \"/\"\n",
    "        if not input_lv2[len(input_lv2) - 1] == \"/\":\n",
    "            input_lv2 = input_lv2 + \"/\"\n",
    "        if not outputdir[len(outputdir) - 1] == \"/\":\n",
    "            outputdir = outputdir + \"/\"\n",
    "        if not os.path.exists(outputdir):\n",
    "            os.mkdir(outputdir)\n",
    "        if existPSSM != \"\":\n",
    "            if not existPSSM[len(existPSSM) - 1] == \"/\":\n",
    "                existPSSM = existPSSM + \"/\"\n",
    "        if ((existPSSM == \"\") or (not os.path.exists(existPSSM))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            pssmdir = outputdir + str(ts) + \"_pssm/\"\n",
    "            if not os.path.exists(pssmdir):\n",
    "                os.makedirs(pssmdir)\n",
    "            process_input_train(input_lv1 + \"lv1_train.txt\", pssmdir)\n",
    "            process_input_train(input_lv2 + \"lv2_train.txt\", pssmdir)\n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, input_lv2, pssmdir, outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, input_lv2, existPSSM, outputdir, foldnum)\n",
    "    elif model_type==False:\n",
    "        if not input_var[len(input_var) - 1] == \"/\":\n",
    "            input_var = input_var + \"/\"\n",
    "        if not var_outputdir[len(var_outputdir) - 1] == \"/\":\n",
    "            var_outputdir = var_outputdir + \"/\"\n",
    "        if not os.path.exists(var_outputdir):\n",
    "            os.mkdir(var_outputdir)\n",
    "        if existPSSM != \"\":\n",
    "            if not var_existPSSM[len(var_existPSSM) - 1] == \"/\":\n",
    "                var_existPSSM = var_existPSSM + \"/\"\n",
    "        if ((var_existPSSM == \"\") or (not os.path.exists(var_existPSSM))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            pssmdir = var_outputdir + str(ts) + \"_pssm/\"\n",
    "            if not os.path.exists(pssmdir):\n",
    "                os.makedirs(pssmdir)\n",
    "            process_input_train(input_var + \"processed_deeploc_train_S_seq\", pssmdir)\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, pssmdir, var_outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, var_existPSSM, var_outputdir, foldnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "associate-hearts",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing 0th fold\n",
      "WARNING:tensorflow:From C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1000, 25)     0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1000, 25)     650         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000, 25)     100         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 25)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1000, 25)     0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1000, 25)     1900        lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000, 25)     100         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1000, 25)     0           batch_normalization_2[0][0]      \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 25)     0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1000, 25)     0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1000, 25)     3150        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1000, 25)     100         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000, 25)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1000, 25)     0           dropout_4[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1000, 25)     5650        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1000, 25)     100         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1000, 25)     0           batch_normalization_4[0][0]      \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1000, 25)     0           lambda_6[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1000, 25)     9400        lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1000, 25)     100         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1000, 25)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1000, 25)     0           dropout_6[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1000, 25)     13150       lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 25)     100         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1000, 25)     0           batch_normalization_6[0][0]      \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 25)     0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1000, 25)     0           dropout_7[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1000, 25)     1900        lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1000, 25)     100         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1000, 25)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1000, 25)     0           dropout_9[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 180)    223560      lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1000, 180)    720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 1000, 180)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1000, 180)    0           dropout_10[0][0]                 \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 180)    390960      lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1000, 180)    720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 1000, 180)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1000, 180)    0           dropout_11[0][0]                 \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 181)    0           lambda_14[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 41, 180)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1000, 25)     0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1000, 25)     650         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000, 25)     100         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 25)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1000, 25)     0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1000, 25)     1900        lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000, 25)     100         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1000, 25)     0           batch_normalization_2[0][0]      \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 25)     0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1000, 25)     0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1000, 25)     3150        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1000, 25)     100         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000, 25)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1000, 25)     0           dropout_4[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1000, 25)     5650        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1000, 25)     100         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1000, 25)     0           batch_normalization_4[0][0]      \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1000, 25)     0           lambda_6[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1000, 25)     9400        lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1000, 25)     100         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1000, 25)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1000, 25)     0           dropout_6[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1000, 25)     13150       lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 25)     100         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1000, 25)     0           batch_normalization_6[0][0]      \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 25)     0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1000, 25)     0           dropout_7[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1000, 25)     1900        lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1000, 25)     100         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1000, 25)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1000, 25)     0           dropout_9[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 180)    223560      lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1000, 180)    720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 1000, 180)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1000, 180)    0           dropout_10[0][0]                 \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 180)    390960      lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1000, 180)    720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 1000, 180)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1000, 180)    0           dropout_11[0][0]                 \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 181)    0           lambda_14[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 41, 180)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 136s 8ms/step - loss: 0.7426 - accuracy: 0.6869 - val_loss: 0.6645 - val_accuracy: 0.8113\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81133, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66455, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 121s 7ms/step - loss: 0.6333 - accuracy: 0.8264 - val_loss: 0.6106 - val_accuracy: 0.8407\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81133 to 0.84074, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66455 to 0.61059, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.5869 - accuracy: 0.8577 - val_loss: 0.5691 - val_accuracy: 0.8690\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84074 to 0.86904, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.61059 to 0.56907, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.5559 - accuracy: 0.8765 - val_loss: 0.5401 - val_accuracy: 0.8772\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86904 to 0.87718, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56907 to 0.54010, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.5297 - accuracy: 0.8864 - val_loss: 0.5101 - val_accuracy: 0.8925\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87718 to 0.89252, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54010 to 0.51006, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.5065 - accuracy: 0.8945 - val_loss: 0.4935 - val_accuracy: 0.8966\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89252 to 0.89656, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51006 to 0.49354, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.4854 - accuracy: 0.8996 - val_loss: 0.4688 - val_accuracy: 0.9050\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89656 to 0.90503, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49354 to 0.46882, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.4652 - accuracy: 0.9046 - val_loss: 0.4467 - val_accuracy: 0.9094\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90503 to 0.90945, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46882 to 0.44666, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 127s 7ms/step - loss: 0.4469 - accuracy: 0.9081 - val_loss: 0.4324 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90945 to 0.91108, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44666 to 0.43243, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.4294 - accuracy: 0.9103 - val_loss: 0.4145 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91108 to 0.91346, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43243 to 0.41450, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 111s 6ms/step - loss: 0.4119 - accuracy: 0.9141 - val_loss: 0.4028 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91346 to 0.91436, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41450 to 0.40285, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 109s 6ms/step - loss: 0.3957 - accuracy: 0.9166 - val_loss: 0.3895 - val_accuracy: 0.9177\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91436 to 0.91767, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40285 to 0.38954, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 109s 6ms/step - loss: 0.3807 - accuracy: 0.9199 - val_loss: 0.3724 - val_accuracy: 0.9195\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91767 to 0.91951, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38954 to 0.37243, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 108s 6ms/step - loss: 0.3660 - accuracy: 0.9219 - val_loss: 0.3576 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91951 to 0.92389, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37243 to 0.35757, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.3521 - accuracy: 0.9250 - val_loss: 0.3539 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92389\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35757 to 0.35386, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 109s 6ms/step - loss: 0.3390 - accuracy: 0.9265 - val_loss: 0.3349 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92389 to 0.92609, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35386 to 0.33492, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 116s 7ms/step - loss: 0.3268 - accuracy: 0.9284 - val_loss: 0.3316 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92609\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33492 to 0.33155, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.3157 - accuracy: 0.9301 - val_loss: 0.3258 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92609 to 0.92716, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33155 to 0.32582, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 108s 6ms/step - loss: 0.3057 - accuracy: 0.9316 - val_loss: 0.3078 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92716 to 0.92748, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32582 to 0.30785, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.2946 - accuracy: 0.9329 - val_loss: 0.3011 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92748 to 0.92847, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30785 to 0.30111, saving model to D:/mulocdeep/lv1_result4/fold0_big_lv1_loss-weights.hdf5\n",
      "doing 1th fold\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1000, 25)     0           dropout_14[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1000, 25)     650         lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1000, 25)     100         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1000, 25)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1000, 25)     0           dropout_15[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1000, 25)     1900        lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1000, 25)     100         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1000, 25)     0           batch_normalization_14[0][0]     \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1000, 25)     0           lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1000, 25)     0           dropout_16[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1000, 25)     3150        lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1000, 25)     100         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1000, 25)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1000, 25)     0           dropout_17[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1000, 25)     5650        lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1000, 25)     100         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1000, 25)     0           batch_normalization_16[0][0]     \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1000, 25)     0           lambda_20[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1000, 25)     9400        lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1000, 25)     100         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 1000, 25)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1000, 25)     0           dropout_19[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1000, 25)     13150       lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1000, 25)     100         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1000, 25)     0           batch_normalization_18[0][0]     \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 1000, 25)     0           lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1000, 25)     0           dropout_20[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1000, 25)     1900        lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 1000, 25)     100         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 1000, 25)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1000, 25)     0           dropout_22[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 180)    223560      lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1000, 180)    720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1000, 180)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 1000, 180)    0           dropout_23[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 180)    390960      lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1000, 180)    720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 1000, 180)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1000, 180)    0           dropout_24[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1000, 181)    0           lambda_28[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 41, 180)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1000, 25)     0           dropout_14[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1000, 25)     650         lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1000, 25)     100         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1000, 25)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1000, 25)     0           dropout_15[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1000, 25)     1900        lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1000, 25)     100         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1000, 25)     0           batch_normalization_14[0][0]     \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1000, 25)     0           lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1000, 25)     0           dropout_16[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1000, 25)     3150        lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1000, 25)     100         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1000, 25)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1000, 25)     0           dropout_17[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1000, 25)     5650        lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1000, 25)     100         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1000, 25)     0           batch_normalization_16[0][0]     \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1000, 25)     0           lambda_20[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1000, 25)     9400        lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1000, 25)     100         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 1000, 25)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1000, 25)     0           dropout_19[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1000, 25)     13150       lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1000, 25)     100         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1000, 25)     0           batch_normalization_18[0][0]     \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 1000, 25)     0           lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1000, 25)     0           dropout_20[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1000, 25)     1900        lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 1000, 25)     100         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 1000, 25)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1000, 25)     0           dropout_22[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 180)    223560      lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1000, 180)    720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1000, 180)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 1000, 180)    0           dropout_23[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 180)    390960      lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1000, 180)    720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 1000, 180)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1000, 180)    0           dropout_24[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1000, 181)    0           lambda_28[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 41, 180)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.7332 - accuracy: 0.6989 - val_loss: 0.6537 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80679, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65367, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 113s 7ms/step - loss: 0.6309 - accuracy: 0.8212 - val_loss: 0.6262 - val_accuracy: 0.8258\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80679 to 0.82577, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.65367 to 0.62618, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 118s 7ms/step - loss: 0.5865 - accuracy: 0.8545 - val_loss: 0.5734 - val_accuracy: 0.8610\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82577 to 0.86102, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.62618 to 0.57340, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 118s 7ms/step - loss: 0.5546 - accuracy: 0.8760 - val_loss: 0.5402 - val_accuracy: 0.8808\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86102 to 0.88082, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57340 to 0.54024, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 132s 8ms/step - loss: 0.5284 - accuracy: 0.8871 - val_loss: 0.5134 - val_accuracy: 0.8886\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88082 to 0.88863, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54024 to 0.51344, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.5045 - accuracy: 0.8955 - val_loss: 0.4922 - val_accuracy: 0.8926\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88863 to 0.89264, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51344 to 0.49225, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 120s 7ms/step - loss: 0.4828 - accuracy: 0.9005 - val_loss: 0.4776 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89264 to 0.89787, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49225 to 0.47763, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.4626 - accuracy: 0.9052 - val_loss: 0.4555 - val_accuracy: 0.9006\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89787 to 0.90057, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47763 to 0.45549, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 120s 7ms/step - loss: 0.4437 - accuracy: 0.9094 - val_loss: 0.4449 - val_accuracy: 0.9020\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90057 to 0.90196, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45549 to 0.44490, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.4256 - accuracy: 0.9125 - val_loss: 0.4278 - val_accuracy: 0.9056\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90196 to 0.90556, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44490 to 0.42779, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 120s 7ms/step - loss: 0.4073 - accuracy: 0.9171 - val_loss: 0.4119 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90556 to 0.91080, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42779 to 0.41188, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.3913 - accuracy: 0.9194 - val_loss: 0.3954 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91080 to 0.91497, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41188 to 0.39543, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.3757 - accuracy: 0.9222 - val_loss: 0.3821 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91497\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39543 to 0.38212, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 120s 7ms/step - loss: 0.3613 - accuracy: 0.9242 - val_loss: 0.3713 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91497\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38212 to 0.37128, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 118s 7ms/step - loss: 0.3467 - accuracy: 0.9271 - val_loss: 0.3615 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91497 to 0.91509, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37128 to 0.36145, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 120s 7ms/step - loss: 0.3345 - accuracy: 0.9283 - val_loss: 0.3495 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91509 to 0.92237, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36145 to 0.34950, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 120s 7ms/step - loss: 0.3220 - accuracy: 0.9302 - val_loss: 0.3353 - val_accuracy: 0.9213\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92237\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34950 to 0.33531, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 121s 7ms/step - loss: 0.3113 - accuracy: 0.9321 - val_loss: 0.3369 - val_accuracy: 0.9187\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92237\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.33531\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.3002 - accuracy: 0.9339 - val_loss: 0.3217 - val_accuracy: 0.9217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92237\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33531 to 0.32173, saving model to D:/mulocdeep/lv1_result4/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 135s 8ms/step - loss: 0.2916 - accuracy: 0.9350 - val_loss: 0.3233 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92237\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32173\n",
      "doing 2th fold\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 1000, 25)     0           dropout_27[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1000, 25)     650         lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1000, 25)     100         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1000, 25)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1000, 25)     0           dropout_28[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1000, 25)     1900        lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1000, 25)     100         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 1000, 25)     0           batch_normalization_26[0][0]     \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 1000, 25)     0           lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1000, 25)     0           dropout_29[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1000, 25)     3150        lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1000, 25)     100         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 1000, 25)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 1000, 25)     0           dropout_30[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1000, 25)     5650        lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1000, 25)     100         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 1000, 25)     0           batch_normalization_28[0][0]     \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 1000, 25)     0           lambda_34[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1000, 25)     9400        lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 1000, 25)     100         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 1000, 25)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1000, 25)     0           dropout_32[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1000, 25)     13150       lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 1000, 25)     100         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 1000, 25)     0           batch_normalization_30[0][0]     \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 1000, 25)     0           lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 1000, 25)     0           dropout_33[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1000, 25)     1900        lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1000, 25)     100         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 1000, 25)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 1000, 25)     0           dropout_35[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 180)    223560      lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1000, 180)    720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 1000, 180)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 1000, 180)    0           dropout_36[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 180)    390960      lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 1000, 180)    720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1000, 180)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 1000, 180)    0           dropout_37[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 181)    0           lambda_42[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 41, 180)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 1000, 25)     0           dropout_27[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1000, 25)     650         lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1000, 25)     100         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1000, 25)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1000, 25)     0           dropout_28[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1000, 25)     1900        lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1000, 25)     100         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 1000, 25)     0           batch_normalization_26[0][0]     \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 1000, 25)     0           lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1000, 25)     0           dropout_29[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1000, 25)     3150        lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1000, 25)     100         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 1000, 25)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 1000, 25)     0           dropout_30[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1000, 25)     5650        lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1000, 25)     100         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 1000, 25)     0           batch_normalization_28[0][0]     \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 1000, 25)     0           lambda_34[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1000, 25)     9400        lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 1000, 25)     100         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 1000, 25)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1000, 25)     0           dropout_32[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1000, 25)     13150       lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 1000, 25)     100         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 1000, 25)     0           batch_normalization_30[0][0]     \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 1000, 25)     0           lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 1000, 25)     0           dropout_33[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1000, 25)     1900        lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1000, 25)     100         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 1000, 25)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 1000, 25)     0           dropout_35[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 180)    223560      lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1000, 180)    720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 1000, 180)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 1000, 180)    0           dropout_36[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 180)    390960      lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 1000, 180)    720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1000, 180)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 1000, 180)    0           dropout_37[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 181)    0           lambda_42[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 41, 180)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 133s 8ms/step - loss: 0.7410 - accuracy: 0.6808 - val_loss: 0.6943 - val_accuracy: 0.8169\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81688, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69426, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 121s 7ms/step - loss: 0.6335 - accuracy: 0.8187 - val_loss: 0.6172 - val_accuracy: 0.8507\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81688 to 0.85065, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.69426 to 0.61723, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 121s 7ms/step - loss: 0.5887 - accuracy: 0.8526 - val_loss: 0.5683 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85065 to 0.86644, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.61723 to 0.56825, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 125s 7ms/step - loss: 0.5556 - accuracy: 0.8747 - val_loss: 0.5381 - val_accuracy: 0.8824\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86644 to 0.88236, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56825 to 0.53813, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 123s 7ms/step - loss: 0.5293 - accuracy: 0.8867 - val_loss: 0.5116 - val_accuracy: 0.8902\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88236 to 0.89025, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53813 to 0.51163, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 137s 8ms/step - loss: 0.5060 - accuracy: 0.8939 - val_loss: 0.4888 - val_accuracy: 0.9014\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89025 to 0.90139, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51163 to 0.48884, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 125s 7ms/step - loss: 0.4843 - accuracy: 0.8999 - val_loss: 0.4781 - val_accuracy: 0.8986\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90139\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48884 to 0.47809, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 125s 7ms/step - loss: 0.4634 - accuracy: 0.9053 - val_loss: 0.4551 - val_accuracy: 0.9043\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90139 to 0.90435, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47809 to 0.45511, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 122s 7ms/step - loss: 0.4451 - accuracy: 0.9083 - val_loss: 0.4404 - val_accuracy: 0.9087\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90435 to 0.90865, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45511 to 0.44039, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 121s 7ms/step - loss: 0.4265 - accuracy: 0.9123 - val_loss: 0.4205 - val_accuracy: 0.9091\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90865 to 0.90912, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44039 to 0.42047, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 122s 7ms/step - loss: 0.4091 - accuracy: 0.9152 - val_loss: 0.4065 - val_accuracy: 0.9127\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90912 to 0.91271, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42047 to 0.40646, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 123s 7ms/step - loss: 0.3928 - accuracy: 0.9180 - val_loss: 0.3895 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91271 to 0.91575, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40646 to 0.38951, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 128s 7ms/step - loss: 0.3765 - accuracy: 0.9215 - val_loss: 0.3805 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91575 to 0.91659, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38951 to 0.38049, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 120s 7ms/step - loss: 0.3623 - accuracy: 0.9238 - val_loss: 0.3699 - val_accuracy: 0.9169\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91659 to 0.91693, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38049 to 0.36994, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 121s 7ms/step - loss: 0.3492 - accuracy: 0.9252 - val_loss: 0.3538 - val_accuracy: 0.9212\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91693 to 0.92123, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36994 to 0.35380, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 122s 7ms/step - loss: 0.3356 - accuracy: 0.9275 - val_loss: 0.3415 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92123 to 0.92296, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35380 to 0.34151, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 118s 7ms/step - loss: 0.3235 - accuracy: 0.9292 - val_loss: 0.3345 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92296\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34151 to 0.33451, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 120s 7ms/step - loss: 0.3132 - accuracy: 0.9303 - val_loss: 0.3236 - val_accuracy: 0.9235\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92296 to 0.92347, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33451 to 0.32358, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 123s 7ms/step - loss: 0.3015 - accuracy: 0.9330 - val_loss: 0.3149 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92347\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32358 to 0.31490, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 119s 7ms/step - loss: 0.2915 - accuracy: 0.9344 - val_loss: 0.3147 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92347\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31490 to 0.31472, saving model to D:/mulocdeep/lv1_result4/fold2_big_lv1_loss-weights.hdf5\n",
      "doing 3th fold\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 1000, 25)     0           dropout_40[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1000, 25)     650         lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1000, 25)     100         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 1000, 25)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 1000, 25)     0           dropout_41[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 1000, 25)     1900        lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1000, 25)     100         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 1000, 25)     0           batch_normalization_38[0][0]     \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 1000, 25)     0           lambda_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 1000, 25)     0           dropout_42[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1000, 25)     3150        lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 1000, 25)     100         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 1000, 25)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 1000, 25)     0           dropout_43[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1000, 25)     5650        lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 1000, 25)     100         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 1000, 25)     0           batch_normalization_40[0][0]     \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 1000, 25)     0           lambda_48[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1000, 25)     9400        lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 1000, 25)     100         conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 1000, 25)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 1000, 25)     0           dropout_45[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1000, 25)     13150       lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 1000, 25)     100         conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 1000, 25)     0           batch_normalization_42[0][0]     \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 1000, 25)     0           lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 1000, 25)     0           dropout_46[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1000, 25)     1900        lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 1000, 25)     100         conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 1000, 25)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 1000, 25)     0           dropout_48[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1000, 180)    223560      lambda_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1000, 180)    720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 1000, 180)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 1000, 180)    0           dropout_49[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1000, 180)    390960      lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 1000, 180)    720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 1000, 180)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 1000, 180)    0           dropout_50[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1000, 181)    0           lambda_56[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 41, 180)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 1000, 25)     0           dropout_40[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1000, 25)     650         lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1000, 25)     100         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 1000, 25)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 1000, 25)     0           dropout_41[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 1000, 25)     1900        lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1000, 25)     100         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 1000, 25)     0           batch_normalization_38[0][0]     \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 1000, 25)     0           lambda_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 1000, 25)     0           dropout_42[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1000, 25)     3150        lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 1000, 25)     100         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 1000, 25)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 1000, 25)     0           dropout_43[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1000, 25)     5650        lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 1000, 25)     100         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 1000, 25)     0           batch_normalization_40[0][0]     \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 1000, 25)     0           lambda_48[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1000, 25)     9400        lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 1000, 25)     100         conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 1000, 25)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 1000, 25)     0           dropout_45[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1000, 25)     13150       lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 1000, 25)     100         conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 1000, 25)     0           batch_normalization_42[0][0]     \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 1000, 25)     0           lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 1000, 25)     0           dropout_46[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1000, 25)     1900        lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 1000, 25)     100         conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 1000, 25)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 1000, 25)     0           dropout_48[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1000, 180)    223560      lambda_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1000, 180)    720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 1000, 180)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 1000, 180)    0           dropout_49[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1000, 180)    390960      lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 1000, 180)    720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 1000, 180)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 1000, 180)    0           dropout_50[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1000, 181)    0           lambda_56[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 41, 180)      0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 130s 8ms/step - loss: 0.7266 - accuracy: 0.7033 - val_loss: 0.6732 - val_accuracy: 0.8226\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82256, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67316, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 118s 7ms/step - loss: 0.6386 - accuracy: 0.8212 - val_loss: 0.6339 - val_accuracy: 0.8362\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82256 to 0.83623, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.67316 to 0.63389, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 119s 7ms/step - loss: 0.5927 - accuracy: 0.8496 - val_loss: 0.5727 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83623 to 0.86527, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.63389 to 0.57272, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 118s 7ms/step - loss: 0.5584 - accuracy: 0.8715 - val_loss: 0.5288 - val_accuracy: 0.8786\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86527 to 0.87862, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57272 to 0.52884, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 118s 7ms/step - loss: 0.5312 - accuracy: 0.8840 - val_loss: 0.5060 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87862 to 0.88718, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52884 to 0.50604, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 122s 7ms/step - loss: 0.5071 - accuracy: 0.8927 - val_loss: 0.4878 - val_accuracy: 0.8958\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88718 to 0.89578, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50604 to 0.48776, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 127s 7ms/step - loss: 0.4854 - accuracy: 0.8982 - val_loss: 0.4706 - val_accuracy: 0.9032\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89578 to 0.90320, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48776 to 0.47057, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 120s 7ms/step - loss: 0.4644 - accuracy: 0.9032 - val_loss: 0.4519 - val_accuracy: 0.9080\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90320 to 0.90795, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47057 to 0.45191, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 118s 7ms/step - loss: 0.4449 - accuracy: 0.9075 - val_loss: 0.4308 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90795 to 0.91132, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45191 to 0.43083, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 117s 7ms/step - loss: 0.4263 - accuracy: 0.9112 - val_loss: 0.4125 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91132 to 0.91509, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43083 to 0.41254, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 116s 7ms/step - loss: 0.4086 - accuracy: 0.9146 - val_loss: 0.4013 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91509\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41254 to 0.40125, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 118s 7ms/step - loss: 0.3922 - accuracy: 0.9175 - val_loss: 0.3833 - val_accuracy: 0.9177\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91509 to 0.91773, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40125 to 0.38326, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 118s 7ms/step - loss: 0.3766 - accuracy: 0.9207 - val_loss: 0.3712 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91773 to 0.91830, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38326 to 0.37118, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 118s 7ms/step - loss: 0.3616 - accuracy: 0.9235 - val_loss: 0.3537 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91830 to 0.92434, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37118 to 0.35373, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 122s 7ms/step - loss: 0.3487 - accuracy: 0.9245 - val_loss: 0.3568 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92434\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35373\n",
      "epoch 15\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 119s 7ms/step - loss: 0.3354 - accuracy: 0.9271 - val_loss: 0.3330 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92434\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35373 to 0.33296, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 118s 7ms/step - loss: 0.3232 - accuracy: 0.9290 - val_loss: 0.3239 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92434 to 0.92718, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33296 to 0.32387, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 117s 7ms/step - loss: 0.3118 - accuracy: 0.9307 - val_loss: 0.3131 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92718\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32387 to 0.31308, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 117s 7ms/step - loss: 0.3026 - accuracy: 0.9314 - val_loss: 0.3072 - val_accuracy: 0.9284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92718 to 0.92840, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31308 to 0.30721, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 121s 7ms/step - loss: 0.2914 - accuracy: 0.9337 - val_loss: 0.3056 - val_accuracy: 0.9246\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92840\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30721 to 0.30559, saving model to D:/mulocdeep/lv1_result4/fold3_big_lv1_loss-weights.hdf5\n",
      "doing 4th fold\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 1000, 25)     0           dropout_53[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1000, 25)     650         lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 1000, 25)     100         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 1000, 25)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 1000, 25)     0           dropout_54[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1000, 25)     1900        lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 1000, 25)     100         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 1000, 25)     0           batch_normalization_50[0][0]     \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 1000, 25)     0           lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 1000, 25)     0           dropout_55[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1000, 25)     3150        lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 1000, 25)     100         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 1000, 25)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 1000, 25)     0           dropout_56[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 1000, 25)     5650        lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 1000, 25)     100         conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 1000, 25)     0           batch_normalization_52[0][0]     \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 1000, 25)     0           lambda_62[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1000, 25)     9400        lambda_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1000, 25)     100         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 1000, 25)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 1000, 25)     0           dropout_58[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1000, 25)     13150       lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1000, 25)     100         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 1000, 25)     0           batch_normalization_54[0][0]     \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 1000, 25)     0           lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 1000, 25)     0           dropout_59[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1000, 25)     1900        lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1000, 25)     100         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 1000, 25)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 1000, 25)     0           dropout_61[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1000, 180)    223560      lambda_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 1000, 180)    720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 1000, 180)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 1000, 180)    0           dropout_62[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1000, 180)    390960      lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 1000, 180)    720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 1000, 180)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 1000, 180)    0           dropout_63[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1000, 181)    0           lambda_70[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 41, 180)      0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 1000, 25)     0           dropout_53[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1000, 25)     650         lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 1000, 25)     100         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 1000, 25)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 1000, 25)     0           dropout_54[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1000, 25)     1900        lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 1000, 25)     100         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 1000, 25)     0           batch_normalization_50[0][0]     \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 1000, 25)     0           lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 1000, 25)     0           dropout_55[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1000, 25)     3150        lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 1000, 25)     100         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 1000, 25)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 1000, 25)     0           dropout_56[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 1000, 25)     5650        lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 1000, 25)     100         conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 1000, 25)     0           batch_normalization_52[0][0]     \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 1000, 25)     0           lambda_62[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1000, 25)     9400        lambda_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1000, 25)     100         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 1000, 25)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 1000, 25)     0           dropout_58[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1000, 25)     13150       lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1000, 25)     100         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 1000, 25)     0           batch_normalization_54[0][0]     \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 1000, 25)     0           lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 1000, 25)     0           dropout_59[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1000, 25)     1900        lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1000, 25)     100         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 1000, 25)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 1000, 25)     0           dropout_61[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1000, 180)    223560      lambda_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 1000, 180)    720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 1000, 180)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 1000, 180)    0           dropout_62[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1000, 180)    390960      lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 1000, 180)    720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 1000, 180)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 1000, 180)    0           dropout_63[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1000, 181)    0           lambda_70[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 41, 180)      0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 133s 8ms/step - loss: 0.7416 - accuracy: 0.7144 - val_loss: 0.6652 - val_accuracy: 0.8096\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80955, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66517, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.6288 - accuracy: 0.8258 - val_loss: 0.6268 - val_accuracy: 0.8258\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80955 to 0.82580, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66517 to 0.62683, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.5886 - accuracy: 0.8536 - val_loss: 0.5724 - val_accuracy: 0.8637\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82580 to 0.86372, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.62683 to 0.57241, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 116s 7ms/step - loss: 0.5573 - accuracy: 0.8742 - val_loss: 0.5342 - val_accuracy: 0.8786\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86372 to 0.87856, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57241 to 0.53417, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.5305 - accuracy: 0.8852 - val_loss: 0.5142 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87856 to 0.88763, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53417 to 0.51419, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.5074 - accuracy: 0.8929 - val_loss: 0.4980 - val_accuracy: 0.8937\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88763 to 0.89367, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51419 to 0.49799, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.4862 - accuracy: 0.8991 - val_loss: 0.4818 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89367 to 0.89395, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49799 to 0.48185, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 125s 7ms/step - loss: 0.4662 - accuracy: 0.9033 - val_loss: 0.4593 - val_accuracy: 0.8999\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89395 to 0.89992, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48185 to 0.45928, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.4468 - accuracy: 0.9076 - val_loss: 0.4401 - val_accuracy: 0.9067\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89992 to 0.90665, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45928 to 0.44013, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.4292 - accuracy: 0.9105 - val_loss: 0.4209 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90665\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44013 to 0.42091, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 116s 7ms/step - loss: 0.4123 - accuracy: 0.9132 - val_loss: 0.4114 - val_accuracy: 0.9055\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90665\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42091 to 0.41141, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.3957 - accuracy: 0.9163 - val_loss: 0.3977 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90665 to 0.91499, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41141 to 0.39769, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.3801 - accuracy: 0.9194 - val_loss: 0.3777 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91499 to 0.91669, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39769 to 0.37769, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.3658 - accuracy: 0.9216 - val_loss: 0.3683 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91669\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37769 to 0.36828, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 119s 7ms/step - loss: 0.3519 - accuracy: 0.9244 - val_loss: 0.3532 - val_accuracy: 0.9180\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91669 to 0.91802, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36828 to 0.35315, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 123s 7ms/step - loss: 0.3392 - accuracy: 0.9260 - val_loss: 0.3430 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91802 to 0.92197, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35315 to 0.34295, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.3262 - accuracy: 0.9287 - val_loss: 0.3385 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92197\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34295 to 0.33851, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 117s 7ms/step - loss: 0.3150 - accuracy: 0.9301 - val_loss: 0.3221 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92197 to 0.92370, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33851 to 0.32215, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17102/17102 [==============================] - 118s 7ms/step - loss: 0.3044 - accuracy: 0.9310 - val_loss: 0.3222 - val_accuracy: 0.9185\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92370\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32215\n",
      "epoch 19\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 122s 7ms/step - loss: 0.2956 - accuracy: 0.9322 - val_loss: 0.3067 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92370 to 0.92386, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32215 to 0.30673, saving model to D:/mulocdeep/lv1_result4/fold4_big_lv1_loss-weights.hdf5\n",
      "doing 5th fold\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 1000, 25)     0           dropout_66[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 1000, 25)     650         lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1000, 25)     100         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 1000, 25)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 1000, 25)     0           dropout_67[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1000, 25)     1900        lambda_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1000, 25)     100         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 1000, 25)     0           batch_normalization_62[0][0]     \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 1000, 25)     0           lambda_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 1000, 25)     0           dropout_68[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1000, 25)     3150        lambda_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 1000, 25)     100         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 1000, 25)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 1000, 25)     0           dropout_69[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1000, 25)     5650        lambda_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 1000, 25)     100         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 1000, 25)     0           batch_normalization_64[0][0]     \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 1000, 25)     0           lambda_76[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1000, 25)     9400        lambda_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 1000, 25)     100         conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 1000, 25)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 1000, 25)     0           dropout_71[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 1000, 25)     13150       lambda_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1000, 25)     100         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 1000, 25)     0           batch_normalization_66[0][0]     \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 1000, 25)     0           lambda_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 1000, 25)     0           dropout_72[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1000, 25)     1900        lambda_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1000, 25)     100         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 1000, 25)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 1000, 25)     0           dropout_74[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1000, 180)    223560      lambda_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 1000, 180)    720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 1000, 180)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)              (None, 1000, 180)    0           dropout_75[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1000, 180)    390960      lambda_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 1000, 180)    720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 1000, 180)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, 1000, 180)    0           dropout_76[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1000, 181)    0           lambda_84[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 41, 180)      0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 1000, 25)     0           dropout_66[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 1000, 25)     650         lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1000, 25)     100         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 1000, 25)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 1000, 25)     0           dropout_67[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1000, 25)     1900        lambda_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1000, 25)     100         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 1000, 25)     0           batch_normalization_62[0][0]     \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 1000, 25)     0           lambda_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 1000, 25)     0           dropout_68[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1000, 25)     3150        lambda_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 1000, 25)     100         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 1000, 25)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 1000, 25)     0           dropout_69[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1000, 25)     5650        lambda_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 1000, 25)     100         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 1000, 25)     0           batch_normalization_64[0][0]     \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 1000, 25)     0           lambda_76[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1000, 25)     9400        lambda_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 1000, 25)     100         conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 1000, 25)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 1000, 25)     0           dropout_71[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 1000, 25)     13150       lambda_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1000, 25)     100         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 1000, 25)     0           batch_normalization_66[0][0]     \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 1000, 25)     0           lambda_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 1000, 25)     0           dropout_72[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1000, 25)     1900        lambda_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1000, 25)     100         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 1000, 25)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 1000, 25)     0           dropout_74[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1000, 180)    223560      lambda_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 1000, 180)    720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 1000, 180)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)              (None, 1000, 180)    0           dropout_75[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1000, 180)    390960      lambda_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 1000, 180)    720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 1000, 180)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, 1000, 180)    0           dropout_76[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1000, 181)    0           lambda_84[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 41, 180)      0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 133s 8ms/step - loss: 0.7223 - accuracy: 0.7012 - val_loss: 0.6626 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81435, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66264, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 121s 7ms/step - loss: 0.6291 - accuracy: 0.8261 - val_loss: 0.6050 - val_accuracy: 0.8439\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81435 to 0.84385, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66264 to 0.60503, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.5881 - accuracy: 0.8552 - val_loss: 0.5743 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84385 to 0.86016, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.60503 to 0.57433, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.5555 - accuracy: 0.8755 - val_loss: 0.5386 - val_accuracy: 0.8791\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86016 to 0.87912, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57433 to 0.53862, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.5288 - accuracy: 0.8862 - val_loss: 0.5138 - val_accuracy: 0.8882\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87912 to 0.88817, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53862 to 0.51378, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.5037 - accuracy: 0.8956 - val_loss: 0.4968 - val_accuracy: 0.8965\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88817 to 0.89646, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51378 to 0.49685, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.4832 - accuracy: 0.9002 - val_loss: 0.4736 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89646 to 0.89996, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49685 to 0.47360, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.4621 - accuracy: 0.9050 - val_loss: 0.4573 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89996\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47360 to 0.45733, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 122s 7ms/step - loss: 0.4433 - accuracy: 0.9082 - val_loss: 0.4382 - val_accuracy: 0.9038\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89996 to 0.90384, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45733 to 0.43819, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.4252 - accuracy: 0.9120 - val_loss: 0.4219 - val_accuracy: 0.9118\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90384 to 0.91178, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43819 to 0.42190, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 116s 7ms/step - loss: 0.4083 - accuracy: 0.9151 - val_loss: 0.4062 - val_accuracy: 0.9098\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91178\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42190 to 0.40623, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 120s 7ms/step - loss: 0.3922 - accuracy: 0.9183 - val_loss: 0.3893 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91178\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40623 to 0.38932, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.3771 - accuracy: 0.9202 - val_loss: 0.3886 - val_accuracy: 0.9118\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91178\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38932 to 0.38862, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.3617 - accuracy: 0.9235 - val_loss: 0.3690 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91178 to 0.91422, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38862 to 0.36900, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.3482 - accuracy: 0.9253 - val_loss: 0.3523 - val_accuracy: 0.9158\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91422 to 0.91576, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36900 to 0.35228, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 119s 7ms/step - loss: 0.3348 - accuracy: 0.9276 - val_loss: 0.3455 - val_accuracy: 0.9196\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91576 to 0.91960, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35228 to 0.34552, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 125s 7ms/step - loss: 0.3235 - accuracy: 0.9289 - val_loss: 0.3366 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91960\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34552 to 0.33659, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 120s 7ms/step - loss: 0.3132 - accuracy: 0.9303 - val_loss: 0.3230 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91960 to 0.92156, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33659 to 0.32301, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 120s 7ms/step - loss: 0.3019 - accuracy: 0.9330 - val_loss: 0.3203 - val_accuracy: 0.9202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92156\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32301 to 0.32033, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 121s 7ms/step - loss: 0.2909 - accuracy: 0.9348 - val_loss: 0.3065 - val_accuracy: 0.9215\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92156\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32033 to 0.30649, saving model to D:/mulocdeep/lv1_result4/fold5_big_lv1_loss-weights.hdf5\n",
      "doing 6th fold\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)              (None, 1000, 25)     0           dropout_79[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 1000, 25)     650         lambda_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1000, 25)     100         conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 1000, 25)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, 1000, 25)     0           dropout_80[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1000, 25)     1900        lambda_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1000, 25)     100         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)              (None, 1000, 25)     0           batch_normalization_74[0][0]     \n",
      "                                                                 dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 1000, 25)     0           lambda_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)              (None, 1000, 25)     0           dropout_81[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 1000, 25)     3150        lambda_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 1000, 25)     100         conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 1000, 25)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)              (None, 1000, 25)     0           dropout_82[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 1000, 25)     5650        lambda_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 1000, 25)     100         conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)              (None, 1000, 25)     0           batch_normalization_76[0][0]     \n",
      "                                                                 dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)              (None, 1000, 25)     0           lambda_90[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1000, 25)     9400        lambda_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 1000, 25)     100         conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 1000, 25)     0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)              (None, 1000, 25)     0           dropout_84[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 1000, 25)     13150       lambda_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 1000, 25)     100         conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)              (None, 1000, 25)     0           batch_normalization_78[0][0]     \n",
      "                                                                 dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 1000, 25)     0           lambda_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)              (None, 1000, 25)     0           dropout_85[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 1000, 25)     1900        lambda_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 1000, 25)     100         conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 1000, 25)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_96 (Lambda)              (None, 1000, 25)     0           dropout_87[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1000, 180)    223560      lambda_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 1000, 180)    720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 1000, 180)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_97 (Lambda)              (None, 1000, 180)    0           dropout_88[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1000, 180)    390960      lambda_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 1000, 180)    720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 1000, 180)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_98 (Lambda)              (None, 1000, 180)    0           dropout_89[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 181)    0           lambda_98[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 41, 180)      0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)              (None, 1000, 25)     0           dropout_79[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 1000, 25)     650         lambda_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1000, 25)     100         conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 1000, 25)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, 1000, 25)     0           dropout_80[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1000, 25)     1900        lambda_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1000, 25)     100         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)              (None, 1000, 25)     0           batch_normalization_74[0][0]     \n",
      "                                                                 dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 1000, 25)     0           lambda_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)              (None, 1000, 25)     0           dropout_81[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 1000, 25)     3150        lambda_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 1000, 25)     100         conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 1000, 25)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)              (None, 1000, 25)     0           dropout_82[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 1000, 25)     5650        lambda_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 1000, 25)     100         conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)              (None, 1000, 25)     0           batch_normalization_76[0][0]     \n",
      "                                                                 dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)              (None, 1000, 25)     0           lambda_90[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1000, 25)     9400        lambda_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 1000, 25)     100         conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 1000, 25)     0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)              (None, 1000, 25)     0           dropout_84[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 1000, 25)     13150       lambda_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 1000, 25)     100         conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)              (None, 1000, 25)     0           batch_normalization_78[0][0]     \n",
      "                                                                 dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 1000, 25)     0           lambda_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)              (None, 1000, 25)     0           dropout_85[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 1000, 25)     1900        lambda_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 1000, 25)     100         conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 1000, 25)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_96 (Lambda)              (None, 1000, 25)     0           dropout_87[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1000, 180)    223560      lambda_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 1000, 180)    720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 1000, 180)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_97 (Lambda)              (None, 1000, 180)    0           dropout_88[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1000, 180)    390960      lambda_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 1000, 180)    720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 1000, 180)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_98 (Lambda)              (None, 1000, 180)    0           dropout_89[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 181)    0           lambda_98[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 41, 180)      0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 134s 8ms/step - loss: 0.7236 - accuracy: 0.7222 - val_loss: 0.7195 - val_accuracy: 0.8109\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81089, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.71953, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 118s 7ms/step - loss: 0.6334 - accuracy: 0.8207 - val_loss: 0.6535 - val_accuracy: 0.8240\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81089 to 0.82402, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.71953 to 0.65347, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 132s 8ms/step - loss: 0.5905 - accuracy: 0.8505 - val_loss: 0.5621 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82402 to 0.87047, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.65347 to 0.56207, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 117s 7ms/step - loss: 0.5582 - accuracy: 0.8720 - val_loss: 0.5311 - val_accuracy: 0.8802\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87047 to 0.88025, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56207 to 0.53109, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 118s 7ms/step - loss: 0.5314 - accuracy: 0.8853 - val_loss: 0.5038 - val_accuracy: 0.8947\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88025 to 0.89473, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53109 to 0.50383, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 118s 7ms/step - loss: 0.5074 - accuracy: 0.8922 - val_loss: 0.4875 - val_accuracy: 0.9014\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89473 to 0.90140, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50383 to 0.48746, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 117s 7ms/step - loss: 0.4851 - accuracy: 0.8992 - val_loss: 0.4648 - val_accuracy: 0.9036\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90140 to 0.90359, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48746 to 0.46482, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 116s 7ms/step - loss: 0.4655 - accuracy: 0.9027 - val_loss: 0.4481 - val_accuracy: 0.9058\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90359 to 0.90579, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46482 to 0.44811, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 118s 7ms/step - loss: 0.4454 - accuracy: 0.9073 - val_loss: 0.4289 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90579 to 0.91301, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44811 to 0.42891, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 118s 7ms/step - loss: 0.4271 - accuracy: 0.9114 - val_loss: 0.4150 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91301 to 0.91488, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42891 to 0.41498, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 123s 7ms/step - loss: 0.4102 - accuracy: 0.9140 - val_loss: 0.4020 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91488 to 0.91608, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41498 to 0.40196, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 117s 7ms/step - loss: 0.3940 - accuracy: 0.9167 - val_loss: 0.3881 - val_accuracy: 0.9129\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91608\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40196 to 0.38807, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 117s 7ms/step - loss: 0.3790 - accuracy: 0.9197 - val_loss: 0.3728 - val_accuracy: 0.9180\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91608 to 0.91804, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38807 to 0.37279, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 117s 7ms/step - loss: 0.3634 - accuracy: 0.9228 - val_loss: 0.3631 - val_accuracy: 0.9204\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91804 to 0.92035, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37279 to 0.36314, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 118s 7ms/step - loss: 0.3497 - accuracy: 0.9251 - val_loss: 0.3527 - val_accuracy: 0.9211\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92035 to 0.92107, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36314 to 0.35269, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 118s 7ms/step - loss: 0.3376 - accuracy: 0.9260 - val_loss: 0.3417 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92107\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35269 to 0.34166, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 118s 7ms/step - loss: 0.3254 - accuracy: 0.9279 - val_loss: 0.3356 - val_accuracy: 0.9213\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92107 to 0.92135, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34166 to 0.33558, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 116s 7ms/step - loss: 0.3135 - accuracy: 0.9310 - val_loss: 0.3203 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92135 to 0.92386, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33558 to 0.32027, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 129s 8ms/step - loss: 0.3031 - accuracy: 0.9321 - val_loss: 0.3159 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92386 to 0.92398, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32027 to 0.31595, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 118s 7ms/step - loss: 0.2933 - accuracy: 0.9337 - val_loss: 0.3050 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92398 to 0.92590, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31595 to 0.30496, saving model to D:/mulocdeep/lv1_result4/fold6_big_lv1_loss-weights.hdf5\n",
      "doing 7th fold\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_99 (Lambda)              (None, 1000, 25)     0           dropout_92[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1000, 25)     650         lambda_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 1000, 25)     100         conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 1000, 25)     0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_100 (Lambda)             (None, 1000, 25)     0           dropout_93[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 1000, 25)     1900        lambda_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 1000, 25)     100         conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_101 (Lambda)             (None, 1000, 25)     0           batch_normalization_86[0][0]     \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 1000, 25)     0           lambda_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_102 (Lambda)             (None, 1000, 25)     0           dropout_94[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 1000, 25)     3150        lambda_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 1000, 25)     100         conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 1000, 25)     0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_103 (Lambda)             (None, 1000, 25)     0           dropout_95[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1000, 25)     5650        lambda_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 1000, 25)     100         conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_104 (Lambda)             (None, 1000, 25)     0           batch_normalization_88[0][0]     \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_105 (Lambda)             (None, 1000, 25)     0           lambda_104[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 1000, 25)     9400        lambda_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 1000, 25)     100         conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 1000, 25)     0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_106 (Lambda)             (None, 1000, 25)     0           dropout_97[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 1000, 25)     13150       lambda_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 1000, 25)     100         conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_107 (Lambda)             (None, 1000, 25)     0           batch_normalization_90[0][0]     \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 1000, 25)     0           lambda_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_109 (Lambda)             (None, 1000, 25)     0           dropout_98[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 1000, 25)     1900        lambda_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 1000, 25)     100         conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 1000, 25)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_110 (Lambda)             (None, 1000, 25)     0           dropout_100[0][0]                \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1000, 180)    223560      lambda_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 1000, 180)    720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 1000, 180)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_111 (Lambda)             (None, 1000, 180)    0           dropout_101[0][0]                \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1000, 180)    390960      lambda_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 1000, 180)    720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 1000, 180)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_112 (Lambda)             (None, 1000, 180)    0           dropout_102[0][0]                \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1000, 181)    0           lambda_112[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 41, 180)      0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_99 (Lambda)              (None, 1000, 25)     0           dropout_92[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1000, 25)     650         lambda_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 1000, 25)     100         conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 1000, 25)     0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_100 (Lambda)             (None, 1000, 25)     0           dropout_93[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 1000, 25)     1900        lambda_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 1000, 25)     100         conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_101 (Lambda)             (None, 1000, 25)     0           batch_normalization_86[0][0]     \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 1000, 25)     0           lambda_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_102 (Lambda)             (None, 1000, 25)     0           dropout_94[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 1000, 25)     3150        lambda_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 1000, 25)     100         conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 1000, 25)     0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_103 (Lambda)             (None, 1000, 25)     0           dropout_95[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1000, 25)     5650        lambda_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 1000, 25)     100         conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_104 (Lambda)             (None, 1000, 25)     0           batch_normalization_88[0][0]     \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_105 (Lambda)             (None, 1000, 25)     0           lambda_104[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 1000, 25)     9400        lambda_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 1000, 25)     100         conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 1000, 25)     0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_106 (Lambda)             (None, 1000, 25)     0           dropout_97[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 1000, 25)     13150       lambda_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 1000, 25)     100         conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_107 (Lambda)             (None, 1000, 25)     0           batch_normalization_90[0][0]     \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 1000, 25)     0           lambda_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_109 (Lambda)             (None, 1000, 25)     0           dropout_98[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 1000, 25)     1900        lambda_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 1000, 25)     100         conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 1000, 25)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_110 (Lambda)             (None, 1000, 25)     0           dropout_100[0][0]                \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1000, 180)    223560      lambda_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 1000, 180)    720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 1000, 180)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_111 (Lambda)             (None, 1000, 180)    0           dropout_101[0][0]                \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1000, 180)    390960      lambda_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 1000, 180)    720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 1000, 180)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_112 (Lambda)             (None, 1000, 180)    0           dropout_102[0][0]                \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1000, 181)    0           lambda_112[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 41, 180)      0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,325,213\n",
      "Trainable params: 1,323,781\n",
      "Non-trainable params: 1,432\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 134s 8ms/step - loss: 0.7273 - accuracy: 0.6882 - val_loss: 0.6937 - val_accuracy: 0.8212\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82119, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69373, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 119s 7ms/step - loss: 0.6365 - accuracy: 0.8243 - val_loss: 0.6544 - val_accuracy: 0.8289\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82119 to 0.82885, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.69373 to 0.65438, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 120s 7ms/step - loss: 0.5926 - accuracy: 0.8510 - val_loss: 0.5769 - val_accuracy: 0.8557\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82885 to 0.85573, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.65438 to 0.57690, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 131s 8ms/step - loss: 0.5605 - accuracy: 0.8697 - val_loss: 0.5301 - val_accuracy: 0.8870\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85573 to 0.88696, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57690 to 0.53014, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 119s 7ms/step - loss: 0.5333 - accuracy: 0.8838 - val_loss: 0.5056 - val_accuracy: 0.8941\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88696 to 0.89411, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53014 to 0.50561, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.5084 - accuracy: 0.8922 - val_loss: 0.4845 - val_accuracy: 0.9019\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89411 to 0.90190, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50561 to 0.48448, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.4879 - accuracy: 0.8973 - val_loss: 0.4693 - val_accuracy: 0.9036\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90190 to 0.90356, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48448 to 0.46933, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.4663 - accuracy: 0.9023 - val_loss: 0.4517 - val_accuracy: 0.9017\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90356\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46933 to 0.45167, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 120s 7ms/step - loss: 0.4469 - accuracy: 0.9067 - val_loss: 0.4369 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90356 to 0.91083, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45167 to 0.43687, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 121s 7ms/step - loss: 0.4282 - accuracy: 0.9107 - val_loss: 0.4236 - val_accuracy: 0.9120\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91083 to 0.91198, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43687 to 0.42364, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 124s 7ms/step - loss: 0.4108 - accuracy: 0.9140 - val_loss: 0.4032 - val_accuracy: 0.9160\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91198 to 0.91597, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42364 to 0.40324, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 119s 7ms/step - loss: 0.3945 - accuracy: 0.9166 - val_loss: 0.3917 - val_accuracy: 0.9147\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91597\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40324 to 0.39171, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 118s 7ms/step - loss: 0.3780 - accuracy: 0.9198 - val_loss: 0.3766 - val_accuracy: 0.9202\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91597 to 0.92020, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39171 to 0.37659, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 117s 7ms/step - loss: 0.3636 - accuracy: 0.9220 - val_loss: 0.3652 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92020 to 0.92213, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37659 to 0.36520, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 117s 7ms/step - loss: 0.3499 - accuracy: 0.9248 - val_loss: 0.3606 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92213\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36520 to 0.36057, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 118s 7ms/step - loss: 0.3373 - accuracy: 0.9262 - val_loss: 0.3381 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92213 to 0.92403, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36057 to 0.33808, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 118s 7ms/step - loss: 0.3258 - accuracy: 0.9283 - val_loss: 0.3326 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92403 to 0.92431, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33808 to 0.33263, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 118s 7ms/step - loss: 0.3135 - accuracy: 0.9300 - val_loss: 0.3240 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92431 to 0.92577, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33263 to 0.32399, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17053/17053 [==============================] - 127s 7ms/step - loss: 0.3033 - accuracy: 0.9323 - val_loss: 0.3272 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92577\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32399\n",
      "epoch 19\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 116s 7ms/step - loss: 0.2929 - accuracy: 0.9337 - val_loss: 0.3154 - val_accuracy: 0.9212\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92577\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32399 to 0.31544, saving model to D:/mulocdeep/lv1_result4/fold7_big_lv1_loss-weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-accused",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
