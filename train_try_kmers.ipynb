{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "import math\n",
    "from itertools import product\n",
    "import argparse\n",
    "import sys\n",
    "from utils_kmer import *\n",
    "import calendar\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "damaged-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eachseq(kmerfile,mask_seq,new_kmers):\n",
    "    global kmer3\n",
    "    if os.path.exists(kmerfile):  #如果pssm文件存在\n",
    "        #print(\"found \" + kmerfile + \"\\n\")  #输出找到pssm文件+换行\n",
    "        kmer3 = readKMER(kmerfile)  #读取kmer文件\n",
    "\n",
    "        \n",
    "\n",
    "    kmer3 = kmer3.astype(float)  #对kmer的数据类型转换为浮点型\n",
    "    new_kmers.append(kmer3)  #新的kmer空列表中添加kmer矩阵\n",
    "    mask_seq.append(gen_mask_mat(1, 0))  #mask序列空列表添加gen_mask矩阵，序列长度为行数，padnum为列数？？？\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metric-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpad(seqfile, labelfile, kmerdir=\"\", npzfile = \"\"): #定义endpad(序列文件，标签文件，pssm路径，npz文件)\n",
    "    if not os.path.exists(npzfile):  #如果npz文件不存在，建立新的pssm空列表，标签空列表，mask序列空列表，id空列表\n",
    "        new_kmers = []\n",
    "        labels = []\n",
    "        mask_seq = []\n",
    "        ids=[]\n",
    "        seqs=[]\n",
    "        f = open(seqfile, \"r\")  #f为打开序列文件\n",
    "        f2 = open(labelfile, \"r\")  #f2为打开标签文件\n",
    "        line = f.readline()  #读取序列文件的第一行\n",
    "        while line != '':\n",
    "            kmerfile = kmerdir + line[1:].strip() + \"_kmer.txt\"  #kmer文件名=kmer地址+id名+_kmer.txt\n",
    "            if line[0] == '>':  #如果该行第一个字符为>\n",
    "                id = line.strip()[1:]  #id为去掉>的字符\n",
    "                ids.append(id)   #在id空列表中添加id\n",
    "            label = f2.readline().strip()  #标签为f2（标签文件）中去掉首尾空格的内容\n",
    "            labels.append(label)  #在标签空列表中添加标签\n",
    "            seq = f.readline().strip()  #第一次seq为第2行的内容，实际seq为>行的下一行\n",
    "            #seql = len(seq)   #序列长度  \n",
    "            process_eachseq(kmerfile,mask_seq,new_kmers)\n",
    "            line = f.readline()  #继续读取下一行，即>行\n",
    "        x = np.array(new_kmers)  #把new_pssms列表变为数组，赋给x\n",
    "        y = [convertlabels_to_categorical(i) for i in labels]  #把标签列表转化为类别(i)\n",
    "        y = np.array(y)  #再把类别转化为数组\n",
    "        mask = np.array(mask_seq)  #把mask_seq（标注的序列？）转化为数组\n",
    "        mask = np.expand_dims(mask, axis=1)\n",
    "        #mask = np.expand_dims(mask, axis=1)\n",
    "        np.savez(npzfile, x=x, y=y, mask=mask, ids=ids)  #保存多个数组到同一个文件中,保存格式是.npz\n",
    "        return [x, y, mask,ids]  #返回pssm矩阵，类别，标注序列，名字id\n",
    "    else:  #如果上述都存在，直接转化为数组\n",
    "        mask = np.load(npzfile)['mask']\n",
    "        x = np.load(npzfile)['x']\n",
    "        y = np.load(npzfile)['y']\n",
    "        ids=np.load(npzfile)['ids']\n",
    "        return [x, y, mask,ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "warming-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MULocDeep(lv1_dir,kmer_dir,output_dir,foldnum):\n",
    "\n",
    "\n",
    "    # get big data 训练10分类的多分类\n",
    "    [train_x_big, train_y_big, train_mask_big, train_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_lab\",\n",
    "        kmer_dir,\n",
    "        \"E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/npz文件/lv1_train_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    [val_x_big, val_y_big, val_mask_big, val_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_lab\",\n",
    "        kmer_dir,\n",
    "        \"E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/npz文件/lv1_val_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model_big, model_small = singlemodel(train_x_big)  #模型为singlemodel\n",
    "\n",
    "    filepath_acc_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "    filepath_loss_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_loss-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    checkpoint_acc_big_lev1 = ModelCheckpoint(filepath_acc_big_lv1, monitor='val_accuracy', save_best_only=True,\n",
    "                                          mode='max',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "\n",
    "    \n",
    "    checkpoint_loss_big_lev1 = ModelCheckpoint(filepath_loss_big_lv1, monitor='val_loss', save_best_only=True,\n",
    "                                          mode='min',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "   \n",
    "    \n",
    "    for i in range(80):\n",
    "        # train small model\n",
    "        print(\"epoch \"+str(i)+\"\\n\")\n",
    "       \n",
    "        # train big model  \n",
    "        fitHistory_batch_big = model_big.fit([train_x_big, train_mask_big],\n",
    "                                             [getTrue4out1(train_y_big)],  #为何大模型没有train_y_big\n",
    "                                             batch_size=batch_size, epochs=1,  #等于1？？\n",
    "                                             validation_data=(\n",
    "                                             [val_x_big, val_mask_big], [getTrue4out1(val_y_big)]),  #也没有val_y_big\n",
    "                                             callbacks=[checkpoint_acc_big_lev1,checkpoint_loss_big_lev1], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alert-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_var(input_var,pssm_dir,output_dir,foldnum):\n",
    "    # get small data\n",
    "    [train_x,train_y,train_mask,train_ids]=endpad(input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_seq\",\n",
    "                                        input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_label\",\n",
    "                                        pssm_dir,\n",
    "                                        \"D:/deeploc/deeploc_40nr_8folds/train_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    [val_x,val_y,val_mask,val_ids]=endpad(input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_seq\",\n",
    "                                  input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_label\",\n",
    "                                  pssm_dir,\n",
    "                                  \"D:/deeploc/deeploc_40nr_8folds/val_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model = var_model(train_x)   #这里的模型是var_model\n",
    "\n",
    "    filepath_acc = output_dir+\"fold\" + str(foldnum) + \"acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "    checkpoint_acc = ModelCheckpoint(filepath_acc, monitor='val_accuracy', save_best_only=True, mode='max',\n",
    "                                 save_weights_only=True, verbose=1)\n",
    "    fitHistory_batch = model.fit([train_x,train_mask.reshape(-1,1000,1)],getTrue4out1(train_y),\n",
    "                                 batch_size=batch_size, epochs=20,\n",
    "                                 validation_data=([val_x,val_mask.reshape(-1,1000,1)], getTrue4out1(val_y)),\n",
    "                                 callbacks=[checkpoint_acc],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spiritual-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''我们常常可以把argparse的使用简化成下面四个步骤\n",
    "       1：import argparse\n",
    "       2：parser = argparse.ArgumentParser()\n",
    "       3：parser.add_argument()\n",
    "       4：parser.parse_args()\n",
    "       上面四个步骤解释如下：首先导入该模块；然后创建一个解析对象；然后向该对象中添加你要关注的命令行参数和选项，\n",
    "       每一个add_argument方法对应一个你要关注的参数或选项；最后调用parse_args()方法进行解析；解析成功之后即可使用'''\n",
    "    \n",
    "def main():\n",
    "    #加default\n",
    "    # description= 这个参数简要描述这个程度做什么以及怎么做\n",
    "    parser=argparse.ArgumentParser(\n",
    "        description='MULocDeep: interpretable protein localization classifier at sub-cellular and sub-organellar levels')\n",
    "    #MULocDeep_model  UniLoc-train-20nr\n",
    "    #--lv1_input_dir/--lv2_input_dir 亚细胞训练数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--lv1_input_dir', dest='lv1_dir', type=str, \n",
    "                        default=\"E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/MULocDeep-master/data/UniLoc-train-20nr/8folds/\",\n",
    "                        help='sub-cellular training data, contains 8 folds protein sequences and labels', required=False)\n",
    "\n",
    "    #--MULocDeep_model 添加它来训练MULocDeep模型，否则训练一个var模型\n",
    "    parser.add_argument('--MULocDeep_model', dest='modeltype', action='store_false',  #触发，store_true会触发DeepLoc\n",
    "                        #如果是store_false,则默认值是True，如果是store_true,则默认值是False  \n",
    "                        help='Add this to train the MULocDeep model, otherwise train a variant model', required=False)\n",
    "    #--model_output 受过训练的模型存储的目录的名称  需自己添加\n",
    "    parser.add_argument('--model_output', dest='outputdir', type=str, \n",
    "                       default=\"E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result\",\n",
    "                       help='the name of the directory where the trained model stores', required=False)  #由True改成False\n",
    "    \n",
    "    parser.add_argument('-existkmer', dest='existkmer', type=str,\n",
    "                        default=\"E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/data/\",\n",
    "                        help='the name of the existing kmer directory if there is one.', required=False)\n",
    "    \n",
    "    #var_model  deeploc_40nr_8folds\n",
    "    #--input_dir 训练var模型的数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--input_var', dest='var_dir', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_40nr_8folds\",\n",
    "                        help='data for traing the variant model, contains 8 folds protein sequences and labels', required=False)\n",
    "    #改true  并且还需要加一个model_ouput  一个是deeploc  一个是MULocDeep\n",
    "    parser.add_argument('--var_model_output', dest='var_outputdir', type=str, help='the name of the directory where the trained model stores', \n",
    "                        default=\"D:/deeploc/var_model_result1\",\n",
    "                        required=False)  #由True改成False\n",
    "    parser.add_argument('-var_existPSSM', dest='var_existPSSM', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_pssm\",\n",
    "                        help='the name of the existing PSSM directory if there is one.', required=False)\n",
    "    parser.set_defaults(feature=True)\n",
    "    #args = parser.parse_args()   #改\n",
    "    args = parser.parse_known_args()[0]   #jupyter下运行解析需要此代码\n",
    "    model_type=args.modeltype\n",
    "    input_lv1=args.lv1_dir\n",
    "    outputdir=args.outputdir\n",
    "    existkmer = args.existkmer\n",
    "\n",
    "\n",
    "    if model_type==True:\n",
    "        if not input_lv1[len(input_lv1) - 1] == \"/\":\n",
    "            input_lv1 = input_lv1 + \"/\"\n",
    "        if not outputdir[len(outputdir) - 1] == \"/\":\n",
    "            outputdir = outputdir + \"/\"\n",
    "        if not os.path.exists(outputdir):\n",
    "            os.mkdir(outputdir)\n",
    "        if existkmer != \"\":\n",
    "            if not existkmer[len(existkmer) - 1] == \"/\":\n",
    "                existkmer = existkmer + \"/\"\n",
    "        if ((existkmer == \"\") or (not os.path.exists(existkmer))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            kmerdir = outputdir + str(ts) + \"_kmer/\"\n",
    "            if not os.path.exists(kmerdir):\n",
    "                os.makedirs(kmerdir)\n",
    "            process_input_train(input_lv1 + \"lv1_train.txt\", kmerdir)\n",
    "            \n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, kmerdir, outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, existkmer, outputdir, foldnum)\n",
    "    elif model_type==False:\n",
    "        if not input_var[len(input_var) - 1] == \"/\":\n",
    "            input_var = input_var + \"/\"\n",
    "        if not var_outputdir[len(var_outputdir) - 1] == \"/\":\n",
    "            var_outputdir = var_outputdir + \"/\"\n",
    "        if not os.path.exists(var_outputdir):\n",
    "            os.mkdir(var_outputdir)\n",
    "        if existPSSM != \"\":\n",
    "            if not var_existPSSM[len(var_existPSSM) - 1] == \"/\":\n",
    "                var_existPSSM = var_existPSSM + \"/\"\n",
    "        if ((var_existPSSM == \"\") or (not os.path.exists(var_existPSSM))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            pssmdir = var_outputdir + str(ts) + \"_pssm/\"\n",
    "            if not os.path.exists(pssmdir):\n",
    "                os.makedirs(pssmdir)\n",
    "            process_input_train(input_var + \"processed_deeploc_train_S_seq\", pssmdir)\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, pssmdir, var_outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, var_existPSSM, var_outputdir, foldnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "associate-hearts",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing 0th fold\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 100)       0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1, 180)       406080      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1, 180)       720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1, 180)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 180)       0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1, 180)       521280      lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1, 180)       720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1, 180)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1, 180)       0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 181)       0           lambda_3[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 41, 180)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 100)       0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1, 180)       406080      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1, 180)       720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1, 180)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 180)       0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1, 180)       521280      lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1, 180)       720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1, 180)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1, 180)       0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 181)       0           lambda_3[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 41, 180)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev2 (Reshape)                  (None, 10, 8)        0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 7s 388us/step - loss: 1.9949 - accuracy: 0.4753 - val_loss: 1.8857 - val_accuracy: 0.5535\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55346, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.88572, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 207us/step - loss: 1.8727 - accuracy: 0.7284 - val_loss: 1.8515 - val_accuracy: 0.8420\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.55346 to 0.84196, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.88572 to 1.85153, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 222us/step - loss: 1.8327 - accuracy: 0.8388 - val_loss: 1.8285 - val_accuracy: 0.8424\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84196 to 0.84241, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.85153 to 1.82849, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 213us/step - loss: 1.8040 - accuracy: 0.8356 - val_loss: 1.7841 - val_accuracy: 0.8078\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84241\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.82849 to 1.78411, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 206us/step - loss: 1.7744 - accuracy: 0.8180 - val_loss: 1.7572 - val_accuracy: 0.8087\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84241\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.78411 to 1.75724, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 209us/step - loss: 1.7449 - accuracy: 0.8140 - val_loss: 1.7321 - val_accuracy: 0.8117\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84241\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.75724 to 1.73208, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 207us/step - loss: 1.7209 - accuracy: 0.8157 - val_loss: 1.7156 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84241\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.73208 to 1.71560, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 254us/step - loss: 1.6974 - accuracy: 0.8186 - val_loss: 1.6951 - val_accuracy: 0.8084\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84241\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.71560 to 1.69505, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 254us/step - loss: 1.6732 - accuracy: 0.8250 - val_loss: 1.6730 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84241\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.69505 to 1.67300, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 248us/step - loss: 1.6554 - accuracy: 0.8325 - val_loss: 1.6637 - val_accuracy: 0.8142\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84241\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.67300 to 1.66366, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 249us/step - loss: 1.6394 - accuracy: 0.8415 - val_loss: 1.6524 - val_accuracy: 0.8159\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84241\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.66366 to 1.65240, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 245us/step - loss: 1.6251 - accuracy: 0.8497 - val_loss: 1.6434 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84241\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.65240 to 1.64337, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 246us/step - loss: 1.6113 - accuracy: 0.8581 - val_loss: 1.6323 - val_accuracy: 0.8256\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84241\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.64337 to 1.63231, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 247us/step - loss: 1.5986 - accuracy: 0.8647 - val_loss: 1.6196 - val_accuracy: 0.8433\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84241 to 0.84327, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.63231 to 1.61963, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 247us/step - loss: 1.5866 - accuracy: 0.8705 - val_loss: 1.6120 - val_accuracy: 0.8396\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84327\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.61963 to 1.61198, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 245us/step - loss: 1.5754 - accuracy: 0.8752 - val_loss: 1.6039 - val_accuracy: 0.8476\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84327 to 0.84761, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.61198 to 1.60391, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 246us/step - loss: 1.5645 - accuracy: 0.8796 - val_loss: 1.5971 - val_accuracy: 0.8506\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84761 to 0.85063, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.60391 to 1.59706, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 247us/step - loss: 1.5543 - accuracy: 0.8844 - val_loss: 1.5911 - val_accuracy: 0.8517\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85063 to 0.85166, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.59706 to 1.59112, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 4s 240us/step - loss: 1.5458 - accuracy: 0.8854 - val_loss: 1.5826 - val_accuracy: 0.8617\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85166 to 0.86172, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.59112 to 1.58259, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 232us/step - loss: 1.5369 - accuracy: 0.8881 - val_loss: 1.5763 - val_accuracy: 0.8606\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86172\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.58259 to 1.57627, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 230us/step - loss: 1.5279 - accuracy: 0.8908 - val_loss: 1.5729 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86172\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57627 to 1.57293, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.5210 - accuracy: 0.8917 - val_loss: 1.5680 - val_accuracy: 0.8582\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86172\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57293 to 1.56798, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 231us/step - loss: 1.5134 - accuracy: 0.8942 - val_loss: 1.5630 - val_accuracy: 0.8626\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86172 to 0.86262, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56798 to 1.56304, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 231us/step - loss: 1.5063 - accuracy: 0.8947 - val_loss: 1.5542 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86262 to 0.86601, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56304 to 1.55416, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 232us/step - loss: 1.5001 - accuracy: 0.8958 - val_loss: 1.5531 - val_accuracy: 0.8625\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86601\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55416 to 1.55306, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 231us/step - loss: 1.4940 - accuracy: 0.8969 - val_loss: 1.5508 - val_accuracy: 0.8646\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86601\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55306 to 1.55083, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 232us/step - loss: 1.4877 - accuracy: 0.8981 - val_loss: 1.5456 - val_accuracy: 0.8645\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86601\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55083 to 1.54559, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 235us/step - loss: 1.4825 - accuracy: 0.8980 - val_loss: 1.5451 - val_accuracy: 0.8670\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86601 to 0.86699, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54559 to 1.54507, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 28\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 237us/step - loss: 1.4777 - accuracy: 0.8998 - val_loss: 1.5390 - val_accuracy: 0.8657\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86699\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54507 to 1.53902, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 241us/step - loss: 1.4736 - accuracy: 0.8994 - val_loss: 1.5443 - val_accuracy: 0.8640\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86699\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53902\n",
      "epoch 30\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 246us/step - loss: 1.4691 - accuracy: 0.9004 - val_loss: 1.5427 - val_accuracy: 0.8587\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86699\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53902\n",
      "epoch 31\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 235us/step - loss: 1.4646 - accuracy: 0.9006 - val_loss: 1.5387 - val_accuracy: 0.8623\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86699\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53902 to 1.53869, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 242us/step - loss: 1.4601 - accuracy: 0.9022 - val_loss: 1.5352 - val_accuracy: 0.8662\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86699\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53869 to 1.53522, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 255us/step - loss: 1.4568 - accuracy: 0.9020 - val_loss: 1.5312 - val_accuracy: 0.8659\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86699\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53522 to 1.53122, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 34\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 287us/step - loss: 1.4534 - accuracy: 0.9023 - val_loss: 1.5355 - val_accuracy: 0.8626\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86699\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53122\n",
      "epoch 35\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 311us/step - loss: 1.4498 - accuracy: 0.9027 - val_loss: 1.5343 - val_accuracy: 0.8621\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86699\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53122\n",
      "epoch 36\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 237us/step - loss: 1.4466 - accuracy: 0.9033 - val_loss: 1.5256 - val_accuracy: 0.8682\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86699 to 0.86822, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53122 to 1.52561, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 37\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.4432 - accuracy: 0.9043 - val_loss: 1.5208 - val_accuracy: 0.8641\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86822\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52561 to 1.52084, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 38\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 234us/step - loss: 1.4408 - accuracy: 0.9039 - val_loss: 1.5259 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86822 to 0.86949, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52084\n",
      "epoch 39\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 232us/step - loss: 1.4376 - accuracy: 0.9049 - val_loss: 1.5218 - val_accuracy: 0.8681\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52084\n",
      "epoch 40\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 230us/step - loss: 1.4362 - accuracy: 0.9037 - val_loss: 1.5192 - val_accuracy: 0.8692\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52084 to 1.51922, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 41\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 232us/step - loss: 1.4342 - accuracy: 0.9040 - val_loss: 1.5224 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51922\n",
      "epoch 42\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 236us/step - loss: 1.4308 - accuracy: 0.9054 - val_loss: 1.5284 - val_accuracy: 0.8636\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51922\n",
      "epoch 43\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 236us/step - loss: 1.4288 - accuracy: 0.9061 - val_loss: 1.5280 - val_accuracy: 0.8675\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51922\n",
      "epoch 44\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.4264 - accuracy: 0.9058 - val_loss: 1.5170 - val_accuracy: 0.8668\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51922 to 1.51705, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 45\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 232us/step - loss: 1.4246 - accuracy: 0.9058 - val_loss: 1.5190 - val_accuracy: 0.8670\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51705\n",
      "epoch 46\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 245us/step - loss: 1.4229 - accuracy: 0.9060 - val_loss: 1.5200 - val_accuracy: 0.8665\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51705\n",
      "epoch 47\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 259us/step - loss: 1.4212 - accuracy: 0.9062 - val_loss: 1.5260 - val_accuracy: 0.8630\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51705\n",
      "epoch 48\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.4189 - accuracy: 0.9065 - val_loss: 1.5230 - val_accuracy: 0.8659\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51705\n",
      "epoch 49\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 245us/step - loss: 1.4180 - accuracy: 0.9067 - val_loss: 1.5207 - val_accuracy: 0.8650\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51705\n",
      "epoch 50\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 265us/step - loss: 1.4161 - accuracy: 0.9069 - val_loss: 1.5208 - val_accuracy: 0.8675\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51705\n",
      "epoch 51\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 260us/step - loss: 1.4156 - accuracy: 0.9068 - val_loss: 1.5223 - val_accuracy: 0.8657\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51705\n",
      "epoch 52\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 266us/step - loss: 1.4144 - accuracy: 0.9068 - val_loss: 1.5193 - val_accuracy: 0.8685\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51705\n",
      "epoch 53\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 264us/step - loss: 1.4131 - accuracy: 0.9069 - val_loss: 1.5261 - val_accuracy: 0.8618\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51705\n",
      "epoch 54\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 251us/step - loss: 1.4101 - accuracy: 0.9081 - val_loss: 1.5229 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51705\n",
      "epoch 55\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 261us/step - loss: 1.4097 - accuracy: 0.9075 - val_loss: 1.5180 - val_accuracy: 0.8681\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51705\n",
      "epoch 56\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 251us/step - loss: 1.4086 - accuracy: 0.9084 - val_loss: 1.5210 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51705\n",
      "epoch 57\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 252us/step - loss: 1.4078 - accuracy: 0.9085 - val_loss: 1.5184 - val_accuracy: 0.8674\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86949\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51705\n",
      "epoch 58\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 247us/step - loss: 1.4061 - accuracy: 0.9084 - val_loss: 1.5164 - val_accuracy: 0.8719\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86949 to 0.87194, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51705 to 1.51637, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 59\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 251us/step - loss: 1.4060 - accuracy: 0.9088 - val_loss: 1.5180 - val_accuracy: 0.8679\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 60\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 265us/step - loss: 1.4038 - accuracy: 0.9088 - val_loss: 1.5267 - val_accuracy: 0.8641\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 61\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 4s 258us/step - loss: 1.4037 - accuracy: 0.9086 - val_loss: 1.5232 - val_accuracy: 0.8685\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 62\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 246us/step - loss: 1.4037 - accuracy: 0.9081 - val_loss: 1.5233 - val_accuracy: 0.8656\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 63\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 243us/step - loss: 1.4020 - accuracy: 0.9087 - val_loss: 1.5228 - val_accuracy: 0.8641\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 64\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 248us/step - loss: 1.4006 - accuracy: 0.9090 - val_loss: 1.5244 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 65\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 244us/step - loss: 1.4012 - accuracy: 0.9090 - val_loss: 1.5232 - val_accuracy: 0.8674\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 66\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 244us/step - loss: 1.3997 - accuracy: 0.9093 - val_loss: 1.5256 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 67\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 245us/step - loss: 1.3997 - accuracy: 0.9091 - val_loss: 1.5266 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 68\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 243us/step - loss: 1.3989 - accuracy: 0.9092 - val_loss: 1.5221 - val_accuracy: 0.8647\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 69\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 244us/step - loss: 1.3980 - accuracy: 0.9096 - val_loss: 1.5283 - val_accuracy: 0.8633\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 70\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 246us/step - loss: 1.3977 - accuracy: 0.9094 - val_loss: 1.5297 - val_accuracy: 0.8636\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 71\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 246us/step - loss: 1.3976 - accuracy: 0.9096 - val_loss: 1.5307 - val_accuracy: 0.8631\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 72\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 245us/step - loss: 1.3964 - accuracy: 0.9096 - val_loss: 1.5280 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 73\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 254us/step - loss: 1.3944 - accuracy: 0.9109 - val_loss: 1.5271 - val_accuracy: 0.8685\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 74\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 253us/step - loss: 1.3952 - accuracy: 0.9101 - val_loss: 1.5357 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 75\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 258us/step - loss: 1.3944 - accuracy: 0.9103 - val_loss: 1.5329 - val_accuracy: 0.8662\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 76\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 248us/step - loss: 1.3948 - accuracy: 0.9094 - val_loss: 1.5369 - val_accuracy: 0.8609\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 77\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 245us/step - loss: 1.3936 - accuracy: 0.9108 - val_loss: 1.5294 - val_accuracy: 0.8659\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 78\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 245us/step - loss: 1.3937 - accuracy: 0.9098 - val_loss: 1.5324 - val_accuracy: 0.8675\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "epoch 79\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 244us/step - loss: 1.3919 - accuracy: 0.9113 - val_loss: 1.5382 - val_accuracy: 0.8645\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87194\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51637\n",
      "doing 1th fold\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1, 100)       0           dropout_6[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1, 180)       406080      lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1, 180)       720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1, 180)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1, 180)       0           dropout_7[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1, 180)       521280      lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1, 180)       720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1, 180)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1, 180)       0           dropout_8[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 181)       0           lambda_6[0][0]                   \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 41, 180)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1, 100)       0           dropout_6[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1, 180)       406080      lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1, 180)       720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1, 180)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1, 180)       0           dropout_7[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1, 180)       521280      lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1, 180)       720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1, 180)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1, 180)       0           dropout_8[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 181)       0           lambda_6[0][0]                   \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 41, 180)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev2 (Reshape)                  (None, 10, 8)        0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 7s 400us/step - loss: 1.9908 - accuracy: 0.4701 - val_loss: 1.8673 - val_accuracy: 0.7185\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71849, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.86731, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.8745 - accuracy: 0.7589 - val_loss: 1.8523 - val_accuracy: 0.8450\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.71849 to 0.84503, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.86731 to 1.85226, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.8351 - accuracy: 0.8382 - val_loss: 1.8250 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84503\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.85226 to 1.82497, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.8052 - accuracy: 0.8320 - val_loss: 1.7886 - val_accuracy: 0.8166\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84503\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.82497 to 1.78855, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 238us/step - loss: 1.7747 - accuracy: 0.8157 - val_loss: 1.7518 - val_accuracy: 0.8161\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84503\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.78855 to 1.75182, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 245us/step - loss: 1.7461 - accuracy: 0.8136 - val_loss: 1.7275 - val_accuracy: 0.8144\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84503\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.75182 to 1.72755, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 254us/step - loss: 1.7194 - accuracy: 0.8154 - val_loss: 1.7088 - val_accuracy: 0.8133\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84503\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.72755 to 1.70881, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.6929 - accuracy: 0.8202 - val_loss: 1.6883 - val_accuracy: 0.8146\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84503\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.70881 to 1.68833, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 235us/step - loss: 1.6717 - accuracy: 0.8259 - val_loss: 1.6746 - val_accuracy: 0.8160\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84503\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.68833 to 1.67462, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 237us/step - loss: 1.6548 - accuracy: 0.8331 - val_loss: 1.6599 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84503\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.67462 to 1.65989, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 247us/step - loss: 1.6391 - accuracy: 0.8401 - val_loss: 1.6498 - val_accuracy: 0.8215\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84503\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.65989 to 1.64979, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 244us/step - loss: 1.6253 - accuracy: 0.8484 - val_loss: 1.6396 - val_accuracy: 0.8244\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84503\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.64979 to 1.63959, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 237us/step - loss: 1.6119 - accuracy: 0.8574 - val_loss: 1.6304 - val_accuracy: 0.8321\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84503\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.63959 to 1.63036, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 236us/step - loss: 1.5997 - accuracy: 0.8629 - val_loss: 1.6212 - val_accuracy: 0.8351\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84503\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.63036 to 1.62125, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 236us/step - loss: 1.5876 - accuracy: 0.8693 - val_loss: 1.6138 - val_accuracy: 0.8472\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84503 to 0.84724, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.62125 to 1.61375, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 235us/step - loss: 1.5763 - accuracy: 0.8737 - val_loss: 1.6061 - val_accuracy: 0.8419\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84724\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.61375 to 1.60613, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 237us/step - loss: 1.5650 - accuracy: 0.8791 - val_loss: 1.5972 - val_accuracy: 0.8510\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84724 to 0.85104, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.60613 to 1.59719, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 235us/step - loss: 1.5558 - accuracy: 0.8813 - val_loss: 1.5910 - val_accuracy: 0.8501\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.85104\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.59719 to 1.59104, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 4s 234us/step - loss: 1.5463 - accuracy: 0.8859 - val_loss: 1.5848 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.85104\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.59104 to 1.58477, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.5378 - accuracy: 0.8882 - val_loss: 1.5778 - val_accuracy: 0.8555\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85104 to 0.85546, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.58477 to 1.57778, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 248us/step - loss: 1.5293 - accuracy: 0.8895 - val_loss: 1.5708 - val_accuracy: 0.8561\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85546 to 0.85607, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57778 to 1.57078, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 234us/step - loss: 1.5210 - accuracy: 0.8924 - val_loss: 1.5659 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85607 to 0.85930, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57078 to 1.56587, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.5143 - accuracy: 0.8926 - val_loss: 1.5655 - val_accuracy: 0.8553\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.85930\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56587 to 1.56548, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.5086 - accuracy: 0.8936 - val_loss: 1.5596 - val_accuracy: 0.8573\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.85930\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56548 to 1.55956, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 235us/step - loss: 1.5017 - accuracy: 0.8949 - val_loss: 1.5567 - val_accuracy: 0.8596\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85930 to 0.85959, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55956 to 1.55668, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 232us/step - loss: 1.4952 - accuracy: 0.8961 - val_loss: 1.5503 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85959 to 0.86528, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55668 to 1.55034, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 234us/step - loss: 1.4895 - accuracy: 0.8977 - val_loss: 1.5463 - val_accuracy: 0.8652\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86528\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55034 to 1.54628, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.4841 - accuracy: 0.8987 - val_loss: 1.5470 - val_accuracy: 0.8631\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86528\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.54628\n",
      "epoch 28\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.4794 - accuracy: 0.8983 - val_loss: 1.5432 - val_accuracy: 0.8630\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86528\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54628 to 1.54325, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 235us/step - loss: 1.4747 - accuracy: 0.8990 - val_loss: 1.5397 - val_accuracy: 0.8632\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86528\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54325 to 1.53965, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 238us/step - loss: 1.4699 - accuracy: 0.9000 - val_loss: 1.5401 - val_accuracy: 0.8622\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86528\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53965\n",
      "epoch 31\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.4657 - accuracy: 0.9010 - val_loss: 1.5341 - val_accuracy: 0.8656\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86528 to 0.86556, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53965 to 1.53413, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 234us/step - loss: 1.4617 - accuracy: 0.9012 - val_loss: 1.5342 - val_accuracy: 0.8637\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86556\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53413\n",
      "epoch 33\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 236us/step - loss: 1.4580 - accuracy: 0.9018 - val_loss: 1.5290 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86556 to 0.86577, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53413 to 1.52899, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 34\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 256us/step - loss: 1.4544 - accuracy: 0.9021 - val_loss: 1.5282 - val_accuracy: 0.8675\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86577 to 0.86748, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52899 to 1.52824, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 295us/step - loss: 1.4512 - accuracy: 0.9026 - val_loss: 1.5260 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86748\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52824 to 1.52601, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 36\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 7s 391us/step - loss: 1.4480 - accuracy: 0.9029 - val_loss: 1.5266 - val_accuracy: 0.8636\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86748\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52601\n",
      "epoch 37\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 318us/step - loss: 1.4451 - accuracy: 0.9036 - val_loss: 1.5261 - val_accuracy: 0.8636\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86748\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52601\n",
      "epoch 38\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 276us/step - loss: 1.4425 - accuracy: 0.9030 - val_loss: 1.5235 - val_accuracy: 0.8665\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86748\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52601 to 1.52348, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 39\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 7s 431us/step - loss: 1.4394 - accuracy: 0.9041 - val_loss: 1.5232 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86748\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52348 to 1.52324, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 40\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 320us/step - loss: 1.4365 - accuracy: 0.9042 - val_loss: 1.5220 - val_accuracy: 0.8697\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86748 to 0.86969, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52324 to 1.52204, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 41\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 288us/step - loss: 1.4342 - accuracy: 0.9050 - val_loss: 1.5246 - val_accuracy: 0.8676\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86969\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52204\n",
      "epoch 42\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 277us/step - loss: 1.4319 - accuracy: 0.9052 - val_loss: 1.5194 - val_accuracy: 0.8690\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86969\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52204 to 1.51940, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 43\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 248us/step - loss: 1.4295 - accuracy: 0.9051 - val_loss: 1.5210 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86969\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51940\n",
      "epoch 44\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 248us/step - loss: 1.4276 - accuracy: 0.9053 - val_loss: 1.5162 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86969 to 0.87047, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51940 to 1.51625, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 45\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 249us/step - loss: 1.4256 - accuracy: 0.9057 - val_loss: 1.5199 - val_accuracy: 0.8674\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 46\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 262us/step - loss: 1.4240 - accuracy: 0.9064 - val_loss: 1.5232 - val_accuracy: 0.8647\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 47\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 255us/step - loss: 1.4224 - accuracy: 0.9060 - val_loss: 1.5203 - val_accuracy: 0.8670\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 48\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 251us/step - loss: 1.4212 - accuracy: 0.9055 - val_loss: 1.5201 - val_accuracy: 0.8686\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 49\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 254us/step - loss: 1.4192 - accuracy: 0.9073 - val_loss: 1.5210 - val_accuracy: 0.8665\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 50\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 249us/step - loss: 1.4179 - accuracy: 0.9062 - val_loss: 1.5167 - val_accuracy: 0.8692\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 51\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 248us/step - loss: 1.4156 - accuracy: 0.9068 - val_loss: 1.5195 - val_accuracy: 0.8671\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 52\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 248us/step - loss: 1.4149 - accuracy: 0.9071 - val_loss: 1.5242 - val_accuracy: 0.8651\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 53\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 249us/step - loss: 1.4135 - accuracy: 0.9075 - val_loss: 1.5218 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 54\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 250us/step - loss: 1.4121 - accuracy: 0.9071 - val_loss: 1.5252 - val_accuracy: 0.8648\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 55\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 255us/step - loss: 1.4110 - accuracy: 0.9074 - val_loss: 1.5231 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 56\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 248us/step - loss: 1.4095 - accuracy: 0.9079 - val_loss: 1.5253 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 57\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 250us/step - loss: 1.4085 - accuracy: 0.9079 - val_loss: 1.5263 - val_accuracy: 0.8656\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 58\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 282us/step - loss: 1.4070 - accuracy: 0.9084 - val_loss: 1.5269 - val_accuracy: 0.8685\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 59\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 255us/step - loss: 1.4073 - accuracy: 0.9078 - val_loss: 1.5234 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 60\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 4s 250us/step - loss: 1.4052 - accuracy: 0.9086 - val_loss: 1.5212 - val_accuracy: 0.8697\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 61\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 235us/step - loss: 1.4043 - accuracy: 0.9081 - val_loss: 1.5247 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 62\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 238us/step - loss: 1.4034 - accuracy: 0.9090 - val_loss: 1.5254 - val_accuracy: 0.8685\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 63\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 234us/step - loss: 1.4028 - accuracy: 0.9093 - val_loss: 1.5269 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 64\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.4030 - accuracy: 0.9082 - val_loss: 1.5282 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 65\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.4026 - accuracy: 0.9086 - val_loss: 1.5301 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 66\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.4013 - accuracy: 0.9088 - val_loss: 1.5308 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 67\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 244us/step - loss: 1.4012 - accuracy: 0.9087 - val_loss: 1.5290 - val_accuracy: 0.8696\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 68\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 234us/step - loss: 1.4004 - accuracy: 0.9090 - val_loss: 1.5313 - val_accuracy: 0.8677\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 69\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.3993 - accuracy: 0.9093 - val_loss: 1.5316 - val_accuracy: 0.8686\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 70\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.3988 - accuracy: 0.9092 - val_loss: 1.5300 - val_accuracy: 0.8685\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 71\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 233us/step - loss: 1.3970 - accuracy: 0.9099 - val_loss: 1.5292 - val_accuracy: 0.8691\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 72\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 232us/step - loss: 1.3967 - accuracy: 0.9095 - val_loss: 1.5259 - val_accuracy: 0.8685\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 73\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 235us/step - loss: 1.3966 - accuracy: 0.9099 - val_loss: 1.5328 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 74\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 234us/step - loss: 1.3966 - accuracy: 0.9092 - val_loss: 1.5314 - val_accuracy: 0.8676\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 75\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 259us/step - loss: 1.3952 - accuracy: 0.9103 - val_loss: 1.5330 - val_accuracy: 0.8697\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 76\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 277us/step - loss: 1.3955 - accuracy: 0.9098 - val_loss: 1.5322 - val_accuracy: 0.8694\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 77\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 5s 280us/step - loss: 1.3949 - accuracy: 0.9093 - val_loss: 1.5392 - val_accuracy: 0.8690\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 78\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 259us/step - loss: 1.3951 - accuracy: 0.9101 - val_loss: 1.5316 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "epoch 79\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 4s 247us/step - loss: 1.3934 - accuracy: 0.9103 - val_loss: 1.5387 - val_accuracy: 0.8703\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87047\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51625\n",
      "doing 2th fold\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1, 100)       0           dropout_11[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1, 180)       406080      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1, 180)       720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1, 180)       0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1, 180)       0           dropout_12[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1, 180)       521280      lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1, 180)       720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1, 180)       0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1, 180)       0           dropout_13[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 181)       0           lambda_9[0][0]                   \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 41, 180)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1, 100)       0           dropout_11[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1, 180)       406080      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1, 180)       720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1, 180)       0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1, 180)       0           dropout_12[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1, 180)       521280      lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1, 180)       720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1, 180)       0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1, 180)       0           dropout_13[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 181)       0           lambda_9[0][0]                   \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 41, 180)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev2 (Reshape)                  (None, 10, 8)        0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 7s 416us/step - loss: 2.0038 - accuracy: 0.4988 - val_loss: 1.8569 - val_accuracy: 0.6470\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64702, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.85688, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 230us/step - loss: 1.8861 - accuracy: 0.7229 - val_loss: 1.8501 - val_accuracy: 0.8471\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.64702 to 0.84707, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.85688 to 1.85006, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.8341 - accuracy: 0.8367 - val_loss: 1.8294 - val_accuracy: 0.8365\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.85006 to 1.82937, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.8038 - accuracy: 0.8336 - val_loss: 1.7855 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.82937 to 1.78549, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 240us/step - loss: 1.7726 - accuracy: 0.8169 - val_loss: 1.7535 - val_accuracy: 0.8157\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.78549 to 1.75355, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 250us/step - loss: 1.7432 - accuracy: 0.8108 - val_loss: 1.7309 - val_accuracy: 0.8144\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.75355 to 1.73087, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.7184 - accuracy: 0.8133 - val_loss: 1.7093 - val_accuracy: 0.8136\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.73087 to 1.70932, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.6959 - accuracy: 0.8167 - val_loss: 1.6917 - val_accuracy: 0.8165\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.70932 to 1.69175, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 238us/step - loss: 1.6725 - accuracy: 0.8246 - val_loss: 1.6755 - val_accuracy: 0.8172\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.69175 to 1.67551, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 238us/step - loss: 1.6539 - accuracy: 0.8332 - val_loss: 1.6633 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.67551 to 1.66333, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 237us/step - loss: 1.6379 - accuracy: 0.8403 - val_loss: 1.6511 - val_accuracy: 0.8244\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.66333 to 1.65111, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.6238 - accuracy: 0.8485 - val_loss: 1.6414 - val_accuracy: 0.8256\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.65111 to 1.64145, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 240us/step - loss: 1.6104 - accuracy: 0.8558 - val_loss: 1.6323 - val_accuracy: 0.8285\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.64145 to 1.63231, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 238us/step - loss: 1.5972 - accuracy: 0.8633 - val_loss: 1.6220 - val_accuracy: 0.8362\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.63231 to 1.62201, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 237us/step - loss: 1.5860 - accuracy: 0.8689 - val_loss: 1.6144 - val_accuracy: 0.8445\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.62201 to 1.61440, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.5752 - accuracy: 0.8737 - val_loss: 1.6097 - val_accuracy: 0.8448\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84707\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.61440 to 1.60974, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.5643 - accuracy: 0.8784 - val_loss: 1.5990 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84707 to 0.84833, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.60974 to 1.59904, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.5545 - accuracy: 0.8817 - val_loss: 1.5939 - val_accuracy: 0.8516\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84833 to 0.85158, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.59904 to 1.59390, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17214/17214 [==============================] - 4s 238us/step - loss: 1.5452 - accuracy: 0.8844 - val_loss: 1.5869 - val_accuracy: 0.8561\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85158 to 0.85606, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.59390 to 1.58691, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 237us/step - loss: 1.5371 - accuracy: 0.8870 - val_loss: 1.5809 - val_accuracy: 0.8473\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.85606\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.58691 to 1.58088, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 244us/step - loss: 1.5285 - accuracy: 0.8895 - val_loss: 1.5778 - val_accuracy: 0.8550\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.85606\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.58088 to 1.57784, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.5208 - accuracy: 0.8916 - val_loss: 1.5735 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85606 to 0.85703, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57784 to 1.57347, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.5135 - accuracy: 0.8925 - val_loss: 1.5654 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85703 to 0.86045, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57347 to 1.56544, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.5073 - accuracy: 0.8938 - val_loss: 1.5611 - val_accuracy: 0.8645\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86045 to 0.86446, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56544 to 1.56111, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.4999 - accuracy: 0.8957 - val_loss: 1.5567 - val_accuracy: 0.8608\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86446\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56111 to 1.55667, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.4943 - accuracy: 0.8958 - val_loss: 1.5521 - val_accuracy: 0.8648\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86446 to 0.86484, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55667 to 1.55206, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 234us/step - loss: 1.4879 - accuracy: 0.8974 - val_loss: 1.5472 - val_accuracy: 0.8634\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86484\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55206 to 1.54715, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.4837 - accuracy: 0.8976 - val_loss: 1.5488 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86484\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.54715\n",
      "epoch 28\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 241us/step - loss: 1.4783 - accuracy: 0.8990 - val_loss: 1.5423 - val_accuracy: 0.8652\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86484 to 0.86522, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54715 to 1.54230, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.4737 - accuracy: 0.8997 - val_loss: 1.5427 - val_accuracy: 0.8696\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86522 to 0.86957, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.54230\n",
      "epoch 30\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.4690 - accuracy: 0.8998 - val_loss: 1.5362 - val_accuracy: 0.8680\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54230 to 1.53619, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.4653 - accuracy: 0.9007 - val_loss: 1.5368 - val_accuracy: 0.8626\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53619\n",
      "epoch 32\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 238us/step - loss: 1.4615 - accuracy: 0.9000 - val_loss: 1.5347 - val_accuracy: 0.8631\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53619 to 1.53468, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 242us/step - loss: 1.4579 - accuracy: 0.9010 - val_loss: 1.5313 - val_accuracy: 0.8616\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53468 to 1.53132, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 34\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 258us/step - loss: 1.4538 - accuracy: 0.9018 - val_loss: 1.5274 - val_accuracy: 0.8691\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53132 to 1.52741, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 237us/step - loss: 1.4512 - accuracy: 0.9019 - val_loss: 1.5343 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52741\n",
      "epoch 36\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 240us/step - loss: 1.4480 - accuracy: 0.9024 - val_loss: 1.5342 - val_accuracy: 0.8596\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52741\n",
      "epoch 37\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.4448 - accuracy: 0.9030 - val_loss: 1.5293 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52741\n",
      "epoch 38\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.4425 - accuracy: 0.9028 - val_loss: 1.5255 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52741 to 1.52545, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 39\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 234us/step - loss: 1.4399 - accuracy: 0.9032 - val_loss: 1.5290 - val_accuracy: 0.8630\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52545\n",
      "epoch 40\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.4370 - accuracy: 0.9035 - val_loss: 1.5281 - val_accuracy: 0.8631\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52545\n",
      "epoch 41\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 237us/step - loss: 1.4352 - accuracy: 0.9039 - val_loss: 1.5251 - val_accuracy: 0.8643\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52545 to 1.52514, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 42\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.4334 - accuracy: 0.9040 - val_loss: 1.5212 - val_accuracy: 0.8673\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52514 to 1.52115, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 43\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.4307 - accuracy: 0.9041 - val_loss: 1.5229 - val_accuracy: 0.8677\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52115\n",
      "epoch 44\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.4288 - accuracy: 0.9045 - val_loss: 1.5238 - val_accuracy: 0.8674\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52115\n",
      "epoch 45\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.4262 - accuracy: 0.9049 - val_loss: 1.5214 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52115\n",
      "epoch 46\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.4243 - accuracy: 0.9057 - val_loss: 1.5204 - val_accuracy: 0.8678\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52115 to 1.52039, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 47\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.4240 - accuracy: 0.9052 - val_loss: 1.5228 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 48\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 239us/step - loss: 1.4214 - accuracy: 0.9061 - val_loss: 1.5217 - val_accuracy: 0.8681\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 49\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 250us/step - loss: 1.4196 - accuracy: 0.9056 - val_loss: 1.5249 - val_accuracy: 0.8666\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 50\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 238us/step - loss: 1.4185 - accuracy: 0.9056 - val_loss: 1.5248 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 51\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.4172 - accuracy: 0.9062 - val_loss: 1.5223 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 52\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.4146 - accuracy: 0.9068 - val_loss: 1.5271 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 53\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 234us/step - loss: 1.4139 - accuracy: 0.9071 - val_loss: 1.5238 - val_accuracy: 0.8693\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 54\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.4135 - accuracy: 0.9066 - val_loss: 1.5250 - val_accuracy: 0.8686\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 55\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.4124 - accuracy: 0.9063 - val_loss: 1.5232 - val_accuracy: 0.8656\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 56\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 235us/step - loss: 1.4113 - accuracy: 0.9071 - val_loss: 1.5218 - val_accuracy: 0.8701\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86957 to 0.87011, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 57\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 240us/step - loss: 1.4096 - accuracy: 0.9075 - val_loss: 1.5260 - val_accuracy: 0.8673\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 58\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 237us/step - loss: 1.4088 - accuracy: 0.9071 - val_loss: 1.5222 - val_accuracy: 0.8689\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 59\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.4069 - accuracy: 0.9079 - val_loss: 1.5279 - val_accuracy: 0.8670\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 60\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 237us/step - loss: 1.4068 - accuracy: 0.9077 - val_loss: 1.5279 - val_accuracy: 0.8687\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 61\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 237us/step - loss: 1.4052 - accuracy: 0.9077 - val_loss: 1.5285 - val_accuracy: 0.8664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 62\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 237us/step - loss: 1.4044 - accuracy: 0.9079 - val_loss: 1.5305 - val_accuracy: 0.8645\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 63\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 240us/step - loss: 1.4044 - accuracy: 0.9080 - val_loss: 1.5250 - val_accuracy: 0.8681\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 64\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 245us/step - loss: 1.4029 - accuracy: 0.9086 - val_loss: 1.5297 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 65\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 236us/step - loss: 1.4029 - accuracy: 0.9082 - val_loss: 1.5266 - val_accuracy: 0.8652\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 66\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 234us/step - loss: 1.4018 - accuracy: 0.9087 - val_loss: 1.5271 - val_accuracy: 0.8681\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 67\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 242us/step - loss: 1.4008 - accuracy: 0.9085 - val_loss: 1.5265 - val_accuracy: 0.8678\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 68\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 241us/step - loss: 1.4002 - accuracy: 0.9091 - val_loss: 1.5233 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 69\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 5s 275us/step - loss: 1.3996 - accuracy: 0.9094 - val_loss: 1.5278 - val_accuracy: 0.8688\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 70\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 5s 266us/step - loss: 1.3997 - accuracy: 0.9084 - val_loss: 1.5326 - val_accuracy: 0.8644\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 71\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 252us/step - loss: 1.3991 - accuracy: 0.9090 - val_loss: 1.5315 - val_accuracy: 0.8685\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 72\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 250us/step - loss: 1.3980 - accuracy: 0.9089 - val_loss: 1.5351 - val_accuracy: 0.8675\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 73\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 250us/step - loss: 1.3988 - accuracy: 0.9083 - val_loss: 1.5405 - val_accuracy: 0.8646\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 74\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 252us/step - loss: 1.3972 - accuracy: 0.9090 - val_loss: 1.5386 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87011\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 75\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 252us/step - loss: 1.3954 - accuracy: 0.9097 - val_loss: 1.5261 - val_accuracy: 0.8715\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87011 to 0.87151, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 76\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 251us/step - loss: 1.3969 - accuracy: 0.9092 - val_loss: 1.5303 - val_accuracy: 0.8662\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87151\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 77\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 250us/step - loss: 1.3960 - accuracy: 0.9095 - val_loss: 1.5395 - val_accuracy: 0.8639\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87151\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 78\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 258us/step - loss: 1.3961 - accuracy: 0.9088 - val_loss: 1.5384 - val_accuracy: 0.8682\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87151\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "epoch 79\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 4s 250us/step - loss: 1.3953 - accuracy: 0.9096 - val_loss: 1.5402 - val_accuracy: 0.8699\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87151\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52039\n",
      "doing 3th fold\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1, 100)       0           dropout_16[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1, 180)       406080      lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1, 180)       720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1, 180)       0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1, 180)       0           dropout_17[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1, 180)       521280      lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1, 180)       720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1, 180)       0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1, 180)       0           dropout_18[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1, 181)       0           lambda_12[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 41, 180)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1, 100)       0           dropout_16[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1, 180)       406080      lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1, 180)       720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1, 180)       0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1, 180)       0           dropout_17[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1, 180)       521280      lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1, 180)       720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1, 180)       0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1, 180)       0           dropout_18[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1, 181)       0           lambda_12[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 41, 180)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev2 (Reshape)                  (None, 10, 8)        0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 7s 419us/step - loss: 2.0046 - accuracy: 0.5141 - val_loss: 1.9449 - val_accuracy: 0.5802\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58024, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.94487, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 236us/step - loss: 1.9159 - accuracy: 0.6699 - val_loss: 1.7915 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.58024 to 0.83931, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.94487 to 1.79152, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 236us/step - loss: 1.8536 - accuracy: 0.7890 - val_loss: 1.7659 - val_accuracy: 0.8156\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83931\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.79152 to 1.76595, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 236us/step - loss: 1.8053 - accuracy: 0.7899 - val_loss: 1.7555 - val_accuracy: 0.7893\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83931\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.76595 to 1.75548, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 239us/step - loss: 1.7667 - accuracy: 0.7933 - val_loss: 1.7426 - val_accuracy: 0.8046\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83931\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.75548 to 1.74256, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 240us/step - loss: 1.7323 - accuracy: 0.8045 - val_loss: 1.7209 - val_accuracy: 0.8067\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83931\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.74256 to 1.72086, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 245us/step - loss: 1.7080 - accuracy: 0.8119 - val_loss: 1.7002 - val_accuracy: 0.8087\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83931\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.72086 to 1.70018, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 249us/step - loss: 1.6881 - accuracy: 0.8171 - val_loss: 1.6839 - val_accuracy: 0.8099\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83931\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.70018 to 1.68394, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 242us/step - loss: 1.6710 - accuracy: 0.8212 - val_loss: 1.6676 - val_accuracy: 0.8124\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83931\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.68394 to 1.66762, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.6537 - accuracy: 0.8285 - val_loss: 1.6550 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83931\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.66762 to 1.65498, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.6402 - accuracy: 0.8342 - val_loss: 1.6428 - val_accuracy: 0.8202\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83931\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.65498 to 1.64279, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 238us/step - loss: 1.6266 - accuracy: 0.8411 - val_loss: 1.6330 - val_accuracy: 0.8282\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83931\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.64279 to 1.63299, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 239us/step - loss: 1.6129 - accuracy: 0.8511 - val_loss: 1.6236 - val_accuracy: 0.8348\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83931\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.63299 to 1.62363, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 239us/step - loss: 1.6004 - accuracy: 0.8581 - val_loss: 1.6140 - val_accuracy: 0.8348\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83931\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.62363 to 1.61396, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 242us/step - loss: 1.5892 - accuracy: 0.8640 - val_loss: 1.6056 - val_accuracy: 0.8405\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83931 to 0.84053, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.61396 to 1.60556, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.5781 - accuracy: 0.8692 - val_loss: 1.5976 - val_accuracy: 0.8511\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84053 to 0.85108, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.60556 to 1.59759, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.5669 - accuracy: 0.8755 - val_loss: 1.5925 - val_accuracy: 0.8520\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85108 to 0.85205, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.59759 to 1.59250, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 238us/step - loss: 1.5577 - accuracy: 0.8774 - val_loss: 1.5871 - val_accuracy: 0.8579\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85205 to 0.85789, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.59250 to 1.58713, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17118/17118 [==============================] - 4s 235us/step - loss: 1.5482 - accuracy: 0.8822 - val_loss: 1.5817 - val_accuracy: 0.8590\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85789 to 0.85903, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.58713 to 1.58173, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 235us/step - loss: 1.5390 - accuracy: 0.8844 - val_loss: 1.5755 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.85903\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.58173 to 1.57553, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 238us/step - loss: 1.5311 - accuracy: 0.8868 - val_loss: 1.5671 - val_accuracy: 0.8629\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85903 to 0.86288, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57553 to 1.56708, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 260us/step - loss: 1.5236 - accuracy: 0.8886 - val_loss: 1.5712 - val_accuracy: 0.8578\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86288\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.56708\n",
      "epoch 22\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 258us/step - loss: 1.5160 - accuracy: 0.8906 - val_loss: 1.5659 - val_accuracy: 0.8545\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86288\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56708 to 1.56587, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 5s 269us/step - loss: 1.5085 - accuracy: 0.8924 - val_loss: 1.5586 - val_accuracy: 0.8607\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86288\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56587 to 1.55864, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 253us/step - loss: 1.5028 - accuracy: 0.8937 - val_loss: 1.5604 - val_accuracy: 0.8656\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86288 to 0.86560, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.55864\n",
      "epoch 25\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 252us/step - loss: 1.4962 - accuracy: 0.8949 - val_loss: 1.5520 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86560\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55864 to 1.55205, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 252us/step - loss: 1.4896 - accuracy: 0.8960 - val_loss: 1.5515 - val_accuracy: 0.8659\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86560 to 0.86592, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55205 to 1.55153, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 251us/step - loss: 1.4850 - accuracy: 0.8966 - val_loss: 1.5524 - val_accuracy: 0.8625\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86592\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.55153\n",
      "epoch 28\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 256us/step - loss: 1.4799 - accuracy: 0.8977 - val_loss: 1.5507 - val_accuracy: 0.8586\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86592\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55153 to 1.55071, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 259us/step - loss: 1.4753 - accuracy: 0.8984 - val_loss: 1.5420 - val_accuracy: 0.8626\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86592\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55071 to 1.54197, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 253us/step - loss: 1.4712 - accuracy: 0.8986 - val_loss: 1.5426 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86592\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.54197\n",
      "epoch 31\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 254us/step - loss: 1.4668 - accuracy: 0.9000 - val_loss: 1.5470 - val_accuracy: 0.8598\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86592\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.54197\n",
      "epoch 32\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 252us/step - loss: 1.4625 - accuracy: 0.9001 - val_loss: 1.5360 - val_accuracy: 0.8643\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86592\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54197 to 1.53602, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 254us/step - loss: 1.4582 - accuracy: 0.9009 - val_loss: 1.5344 - val_accuracy: 0.8639\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86592\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53602 to 1.53440, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 34\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 257us/step - loss: 1.4562 - accuracy: 0.9011 - val_loss: 1.5336 - val_accuracy: 0.8657\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86592\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53440 to 1.53361, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 262us/step - loss: 1.4522 - accuracy: 0.9014 - val_loss: 1.5334 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86592\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53361 to 1.53340, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 36\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 5s 267us/step - loss: 1.4488 - accuracy: 0.9019 - val_loss: 1.5356 - val_accuracy: 0.8622\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86592\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53340\n",
      "epoch 37\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 257us/step - loss: 1.4470 - accuracy: 0.9013 - val_loss: 1.5320 - val_accuracy: 0.8637\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86592\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53340 to 1.53204, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 38\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.4442 - accuracy: 0.9023 - val_loss: 1.5308 - val_accuracy: 0.8647\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86592\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53204 to 1.53084, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 39\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 236us/step - loss: 1.4410 - accuracy: 0.9027 - val_loss: 1.5279 - val_accuracy: 0.8680\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86592 to 0.86799, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53084 to 1.52786, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 40\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 235us/step - loss: 1.4385 - accuracy: 0.9029 - val_loss: 1.5281 - val_accuracy: 0.8643\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52786\n",
      "epoch 41\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.4357 - accuracy: 0.9035 - val_loss: 1.5284 - val_accuracy: 0.8633\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52786\n",
      "epoch 42\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 238us/step - loss: 1.4345 - accuracy: 0.9029 - val_loss: 1.5291 - val_accuracy: 0.8643\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52786\n",
      "epoch 43\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 238us/step - loss: 1.4320 - accuracy: 0.9034 - val_loss: 1.5295 - val_accuracy: 0.8645\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52786\n",
      "epoch 44\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.4294 - accuracy: 0.9039 - val_loss: 1.5302 - val_accuracy: 0.8641\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52786\n",
      "epoch 45\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.4282 - accuracy: 0.9041 - val_loss: 1.5279 - val_accuracy: 0.8657\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52786\n",
      "epoch 46\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 235us/step - loss: 1.4267 - accuracy: 0.9039 - val_loss: 1.5262 - val_accuracy: 0.8673\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52786 to 1.52624, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 47\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 238us/step - loss: 1.4251 - accuracy: 0.9041 - val_loss: 1.5301 - val_accuracy: 0.8623\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52624\n",
      "epoch 48\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 240us/step - loss: 1.4235 - accuracy: 0.9045 - val_loss: 1.5293 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52624\n",
      "epoch 49\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 241us/step - loss: 1.4213 - accuracy: 0.9046 - val_loss: 1.5299 - val_accuracy: 0.8637\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52624\n",
      "epoch 50\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 245us/step - loss: 1.4205 - accuracy: 0.9045 - val_loss: 1.5315 - val_accuracy: 0.8643\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52624\n",
      "epoch 51\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 238us/step - loss: 1.4181 - accuracy: 0.9058 - val_loss: 1.5247 - val_accuracy: 0.8643\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52624 to 1.52471, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 52\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 236us/step - loss: 1.4175 - accuracy: 0.9052 - val_loss: 1.5277 - val_accuracy: 0.8673\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 53\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 236us/step - loss: 1.4156 - accuracy: 0.9057 - val_loss: 1.5319 - val_accuracy: 0.8637\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 54\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.4153 - accuracy: 0.9057 - val_loss: 1.5287 - val_accuracy: 0.8633\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 55\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 236us/step - loss: 1.4142 - accuracy: 0.9059 - val_loss: 1.5304 - val_accuracy: 0.8655\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 56\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 238us/step - loss: 1.4123 - accuracy: 0.9065 - val_loss: 1.5324 - val_accuracy: 0.8616\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 57\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 241us/step - loss: 1.4117 - accuracy: 0.9060 - val_loss: 1.5248 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86799 to 0.86828, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 58\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 239us/step - loss: 1.4103 - accuracy: 0.9065 - val_loss: 1.5270 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86828\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 59\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 238us/step - loss: 1.4107 - accuracy: 0.9059 - val_loss: 1.5268 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86828\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 60\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 238us/step - loss: 1.4091 - accuracy: 0.9060 - val_loss: 1.5329 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86828\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 61\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 238us/step - loss: 1.4084 - accuracy: 0.9067 - val_loss: 1.5250 - val_accuracy: 0.8689\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86828 to 0.86893, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 62\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17118/17118 [==============================] - 4s 238us/step - loss: 1.4068 - accuracy: 0.9068 - val_loss: 1.5300 - val_accuracy: 0.8639\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86893\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 63\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 236us/step - loss: 1.4068 - accuracy: 0.9071 - val_loss: 1.5322 - val_accuracy: 0.8671\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86893\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 64\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 236us/step - loss: 1.4061 - accuracy: 0.9068 - val_loss: 1.5294 - val_accuracy: 0.8671\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86893\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 65\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 257us/step - loss: 1.4051 - accuracy: 0.9066 - val_loss: 1.5375 - val_accuracy: 0.8647\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86893\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 66\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 239us/step - loss: 1.4047 - accuracy: 0.9069 - val_loss: 1.5283 - val_accuracy: 0.8702\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86893 to 0.87018, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 67\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.4039 - accuracy: 0.9077 - val_loss: 1.5357 - val_accuracy: 0.8665\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87018\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 68\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 243us/step - loss: 1.4028 - accuracy: 0.9078 - val_loss: 1.5365 - val_accuracy: 0.8674\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87018\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 69\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.4029 - accuracy: 0.9071 - val_loss: 1.5381 - val_accuracy: 0.8691\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87018\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 70\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.4019 - accuracy: 0.9078 - val_loss: 1.5362 - val_accuracy: 0.8668\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87018\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 71\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 236us/step - loss: 1.4005 - accuracy: 0.9082 - val_loss: 1.5368 - val_accuracy: 0.8641\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87018\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 72\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.4008 - accuracy: 0.9078 - val_loss: 1.5402 - val_accuracy: 0.8656\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87018\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 73\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 239us/step - loss: 1.4006 - accuracy: 0.9080 - val_loss: 1.5374 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87018\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 74\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 235us/step - loss: 1.3999 - accuracy: 0.9084 - val_loss: 1.5433 - val_accuracy: 0.8656\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87018\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 75\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 236us/step - loss: 1.3993 - accuracy: 0.9079 - val_loss: 1.5462 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87018\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 76\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 237us/step - loss: 1.3982 - accuracy: 0.9083 - val_loss: 1.5412 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87018\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 77\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 252us/step - loss: 1.3989 - accuracy: 0.9082 - val_loss: 1.5451 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87018\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 78\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 241us/step - loss: 1.3976 - accuracy: 0.9086 - val_loss: 1.5459 - val_accuracy: 0.8668\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87018\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "epoch 79\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 4s 238us/step - loss: 1.3975 - accuracy: 0.9083 - val_loss: 1.5396 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87018\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.52471\n",
      "doing 4th fold\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1, 100)       0           dropout_21[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1, 180)       406080      lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1, 180)       720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 1, 180)       0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1, 180)       0           dropout_22[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1, 180)       521280      lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1, 180)       720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1, 180)       0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1, 180)       0           dropout_23[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1, 181)       0           lambda_15[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 41, 180)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1, 100)       0           dropout_21[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1, 180)       406080      lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1, 180)       720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 1, 180)       0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1, 180)       0           dropout_22[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1, 180)       521280      lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1, 180)       720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1, 180)       0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1, 180)       0           dropout_23[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1, 181)       0           lambda_15[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 41, 180)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev2 (Reshape)                  (None, 10, 8)        0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 8s 463us/step - loss: 2.0064 - accuracy: 0.4894 - val_loss: 1.8585 - val_accuracy: 0.5351\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53507, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.85849, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 239us/step - loss: 1.8766 - accuracy: 0.7130 - val_loss: 1.8372 - val_accuracy: 0.8606\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.53507 to 0.86058, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.85849 to 1.83720, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 238us/step - loss: 1.8358 - accuracy: 0.8366 - val_loss: 1.8128 - val_accuracy: 0.8437\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.83720 to 1.81284, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 238us/step - loss: 1.8055 - accuracy: 0.8224 - val_loss: 1.7779 - val_accuracy: 0.8178\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.81284 to 1.77790, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 239us/step - loss: 1.7740 - accuracy: 0.8027 - val_loss: 1.7487 - val_accuracy: 0.7962\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.77790 to 1.74868, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 242us/step - loss: 1.7412 - accuracy: 0.8093 - val_loss: 1.7236 - val_accuracy: 0.8123\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.74868 to 1.72363, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 241us/step - loss: 1.7125 - accuracy: 0.8158 - val_loss: 1.7028 - val_accuracy: 0.8124\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.72363 to 1.70279, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 239us/step - loss: 1.6894 - accuracy: 0.8185 - val_loss: 1.6863 - val_accuracy: 0.8109\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.70279 to 1.68632, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 249us/step - loss: 1.6686 - accuracy: 0.8265 - val_loss: 1.6716 - val_accuracy: 0.8148\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.68632 to 1.67163, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 246us/step - loss: 1.6521 - accuracy: 0.8348 - val_loss: 1.6555 - val_accuracy: 0.8210\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.67163 to 1.65547, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 240us/step - loss: 1.6371 - accuracy: 0.8433 - val_loss: 1.6453 - val_accuracy: 0.8256\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.65547 to 1.64534, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 238us/step - loss: 1.6234 - accuracy: 0.8513 - val_loss: 1.6332 - val_accuracy: 0.8336\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.64534 to 1.63321, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 239us/step - loss: 1.6095 - accuracy: 0.8590 - val_loss: 1.6245 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.63321 to 1.62454, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 240us/step - loss: 1.5970 - accuracy: 0.8670 - val_loss: 1.6131 - val_accuracy: 0.8368\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.62454 to 1.61306, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 239us/step - loss: 1.5858 - accuracy: 0.8713 - val_loss: 1.6039 - val_accuracy: 0.8512\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.61306 to 1.60388, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 241us/step - loss: 1.5743 - accuracy: 0.8766 - val_loss: 1.5966 - val_accuracy: 0.8573\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86058\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.60388 to 1.59658, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 241us/step - loss: 1.5633 - accuracy: 0.8808 - val_loss: 1.5894 - val_accuracy: 0.8632\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86058 to 0.86324, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.59658 to 1.58941, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 252us/step - loss: 1.5541 - accuracy: 0.8842 - val_loss: 1.5811 - val_accuracy: 0.8633\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86324 to 0.86332, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.58941 to 1.58109, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17102/17102 [==============================] - 4s 249us/step - loss: 1.5437 - accuracy: 0.8874 - val_loss: 1.5734 - val_accuracy: 0.8628\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86332\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.58109 to 1.57336, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 263us/step - loss: 1.5356 - accuracy: 0.8890 - val_loss: 1.5671 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86332 to 0.86687, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57336 to 1.56714, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 258us/step - loss: 1.5276 - accuracy: 0.8912 - val_loss: 1.5599 - val_accuracy: 0.8687\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86687 to 0.86868, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56714 to 1.55992, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 253us/step - loss: 1.5198 - accuracy: 0.8934 - val_loss: 1.5567 - val_accuracy: 0.8680\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86868\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55992 to 1.55669, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 239us/step - loss: 1.5123 - accuracy: 0.8942 - val_loss: 1.5490 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86868 to 0.87291, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55669 to 1.54903, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 5s 286us/step - loss: 1.5050 - accuracy: 0.8961 - val_loss: 1.5469 - val_accuracy: 0.8713\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87291\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54903 to 1.54693, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 5s 280us/step - loss: 1.4987 - accuracy: 0.8974 - val_loss: 1.5432 - val_accuracy: 0.8701\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87291\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54693 to 1.54315, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 5s 274us/step - loss: 1.4928 - accuracy: 0.8981 - val_loss: 1.5356 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87291 to 0.87336, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54315 to 1.53561, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 5s 282us/step - loss: 1.4871 - accuracy: 0.8987 - val_loss: 1.5317 - val_accuracy: 0.8737\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87336 to 0.87372, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53561 to 1.53172, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 5s 265us/step - loss: 1.4814 - accuracy: 0.8995 - val_loss: 1.5275 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87372 to 0.87501, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53172 to 1.52749, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 28\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 5s 269us/step - loss: 1.4769 - accuracy: 0.8997 - val_loss: 1.5254 - val_accuracy: 0.8742\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87501\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52749 to 1.52545, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 258us/step - loss: 1.4712 - accuracy: 0.9014 - val_loss: 1.5229 - val_accuracy: 0.8728\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87501\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52545 to 1.52288, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 254us/step - loss: 1.4671 - accuracy: 0.9018 - val_loss: 1.5195 - val_accuracy: 0.8762\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87501 to 0.87618, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52288 to 1.51947, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 255us/step - loss: 1.4631 - accuracy: 0.9022 - val_loss: 1.5161 - val_accuracy: 0.8738\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87618\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51947 to 1.51614, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 256us/step - loss: 1.4595 - accuracy: 0.9021 - val_loss: 1.5124 - val_accuracy: 0.8765\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87618 to 0.87650, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51614 to 1.51237, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 260us/step - loss: 1.4548 - accuracy: 0.9031 - val_loss: 1.5136 - val_accuracy: 0.8714\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87650\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51237\n",
      "epoch 34\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 257us/step - loss: 1.4520 - accuracy: 0.9028 - val_loss: 1.5120 - val_accuracy: 0.8756\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87650\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51237 to 1.51200, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 258us/step - loss: 1.4487 - accuracy: 0.9036 - val_loss: 1.5083 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87650\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51200 to 1.50826, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 36\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17102/17102 [==============================] - 5s 270us/step - loss: 1.4451 - accuracy: 0.9048 - val_loss: 1.5054 - val_accuracy: 0.8756\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87650\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50826 to 1.50538, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 37\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 249us/step - loss: 1.4422 - accuracy: 0.9052 - val_loss: 1.5046 - val_accuracy: 0.8733\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87650\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50538 to 1.50463, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 38\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 247us/step - loss: 1.4395 - accuracy: 0.9052 - val_loss: 1.5050 - val_accuracy: 0.8732\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87650\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50463\n",
      "epoch 39\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 249us/step - loss: 1.4368 - accuracy: 0.9054 - val_loss: 1.5028 - val_accuracy: 0.8747\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87650\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50463 to 1.50278, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 40\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 251us/step - loss: 1.4332 - accuracy: 0.9055 - val_loss: 1.5019 - val_accuracy: 0.8749\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87650\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50278 to 1.50193, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 41\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 249us/step - loss: 1.4317 - accuracy: 0.9053 - val_loss: 1.5002 - val_accuracy: 0.8737\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87650\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50193 to 1.50025, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 42\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 248us/step - loss: 1.4289 - accuracy: 0.9063 - val_loss: 1.4981 - val_accuracy: 0.8766\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87650 to 0.87662, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50025 to 1.49807, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 43\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 248us/step - loss: 1.4262 - accuracy: 0.9066 - val_loss: 1.4986 - val_accuracy: 0.8762\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87662\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49807\n",
      "epoch 44\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 248us/step - loss: 1.4254 - accuracy: 0.9068 - val_loss: 1.4965 - val_accuracy: 0.8746\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87662\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.49807 to 1.49648, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 45\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 249us/step - loss: 1.4234 - accuracy: 0.9066 - val_loss: 1.4947 - val_accuracy: 0.8757\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87662\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.49648 to 1.49472, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 46\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 250us/step - loss: 1.4208 - accuracy: 0.9069 - val_loss: 1.4963 - val_accuracy: 0.8767\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87662 to 0.87670, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49472\n",
      "epoch 47\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 248us/step - loss: 1.4190 - accuracy: 0.9078 - val_loss: 1.4943 - val_accuracy: 0.8771\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87670 to 0.87707, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.49472 to 1.49427, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 48\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 249us/step - loss: 1.4177 - accuracy: 0.9076 - val_loss: 1.4953 - val_accuracy: 0.8752\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87707\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49427\n",
      "epoch 49\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 249us/step - loss: 1.4164 - accuracy: 0.9076 - val_loss: 1.4956 - val_accuracy: 0.8776\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87707 to 0.87759, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49427\n",
      "epoch 50\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 260us/step - loss: 1.4151 - accuracy: 0.9075 - val_loss: 1.4929 - val_accuracy: 0.8771\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87759\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.49427 to 1.49291, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 51\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 250us/step - loss: 1.4127 - accuracy: 0.9084 - val_loss: 1.4932 - val_accuracy: 0.8765\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87759\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49291\n",
      "epoch 52\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 249us/step - loss: 1.4118 - accuracy: 0.9085 - val_loss: 1.4936 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87759\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49291\n",
      "epoch 53\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 250us/step - loss: 1.4099 - accuracy: 0.9086 - val_loss: 1.4902 - val_accuracy: 0.8780\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87759 to 0.87799, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.49291 to 1.49016, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 54\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 255us/step - loss: 1.4097 - accuracy: 0.9084 - val_loss: 1.4916 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 55\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 253us/step - loss: 1.4071 - accuracy: 0.9091 - val_loss: 1.4932 - val_accuracy: 0.8780\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87799 to 0.87803, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 56\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17102/17102 [==============================] - 4s 239us/step - loss: 1.4061 - accuracy: 0.9093 - val_loss: 1.4937 - val_accuracy: 0.8770\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 57\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 238us/step - loss: 1.4058 - accuracy: 0.9091 - val_loss: 1.4981 - val_accuracy: 0.8768\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 58\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 238us/step - loss: 1.4060 - accuracy: 0.9086 - val_loss: 1.4942 - val_accuracy: 0.8770\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 59\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 263us/step - loss: 1.4032 - accuracy: 0.9093 - val_loss: 1.4937 - val_accuracy: 0.8748\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 60\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 247us/step - loss: 1.4032 - accuracy: 0.9088 - val_loss: 1.4994 - val_accuracy: 0.8754\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 61\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 247us/step - loss: 1.4015 - accuracy: 0.9096 - val_loss: 1.4956 - val_accuracy: 0.8757\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 62\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 238us/step - loss: 1.4008 - accuracy: 0.9098 - val_loss: 1.4966 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 63\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 240us/step - loss: 1.3996 - accuracy: 0.9101 - val_loss: 1.4954 - val_accuracy: 0.8761\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 64\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 255us/step - loss: 1.3990 - accuracy: 0.9104 - val_loss: 1.4966 - val_accuracy: 0.8763\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 65\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 238us/step - loss: 1.3987 - accuracy: 0.9101 - val_loss: 1.4958 - val_accuracy: 0.8756\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 66\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 240us/step - loss: 1.3968 - accuracy: 0.9109 - val_loss: 1.4991 - val_accuracy: 0.8748\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 67\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 239us/step - loss: 1.3960 - accuracy: 0.9106 - val_loss: 1.5014 - val_accuracy: 0.8738\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 68\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 240us/step - loss: 1.3955 - accuracy: 0.9113 - val_loss: 1.4979 - val_accuracy: 0.8767\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 69\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 238us/step - loss: 1.3952 - accuracy: 0.9113 - val_loss: 1.5002 - val_accuracy: 0.8770\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 70\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 240us/step - loss: 1.3940 - accuracy: 0.9111 - val_loss: 1.5011 - val_accuracy: 0.8756\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 71\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 239us/step - loss: 1.3952 - accuracy: 0.9106 - val_loss: 1.5017 - val_accuracy: 0.8766\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 72\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 237us/step - loss: 1.3927 - accuracy: 0.9114 - val_loss: 1.5020 - val_accuracy: 0.8757\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 73\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 239us/step - loss: 1.3920 - accuracy: 0.9117 - val_loss: 1.5033 - val_accuracy: 0.8753\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 74\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 238us/step - loss: 1.3922 - accuracy: 0.9109 - val_loss: 1.5063 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 75\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 241us/step - loss: 1.3907 - accuracy: 0.9117 - val_loss: 1.5031 - val_accuracy: 0.8770\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 76\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 240us/step - loss: 1.3908 - accuracy: 0.9114 - val_loss: 1.5065 - val_accuracy: 0.8744\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 77\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 239us/step - loss: 1.3913 - accuracy: 0.9111 - val_loss: 1.5030 - val_accuracy: 0.8758\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 78\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 239us/step - loss: 1.3898 - accuracy: 0.9122 - val_loss: 1.5009 - val_accuracy: 0.8757\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "epoch 79\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 4s 248us/step - loss: 1.3891 - accuracy: 0.9120 - val_loss: 1.5021 - val_accuracy: 0.8746\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87803\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49016\n",
      "doing 5th fold\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1, 100)       0           dropout_26[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1, 180)       406080      lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1, 180)       720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1, 180)       0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1, 180)       0           dropout_27[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1, 180)       521280      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1, 180)       720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1, 180)       0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1, 180)       0           dropout_28[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1, 181)       0           lambda_18[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 41, 180)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1, 100)       0           dropout_26[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1, 180)       406080      lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1, 180)       720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1, 180)       0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1, 180)       0           dropout_27[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1, 180)       521280      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1, 180)       720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1, 180)       0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1, 180)       0           dropout_28[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1, 181)       0           lambda_18[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 41, 180)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev2 (Reshape)                  (None, 10, 8)        0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 8s 481us/step - loss: 1.9890 - accuracy: 0.4527 - val_loss: 1.8986 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74172, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.89863, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 251us/step - loss: 1.8731 - accuracy: 0.7604 - val_loss: 1.8494 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.74172 to 0.82220, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.89863 to 1.84936, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 242us/step - loss: 1.8317 - accuracy: 0.8346 - val_loss: 1.8175 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82220 to 0.83326, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.84936 to 1.81746, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 248us/step - loss: 1.8024 - accuracy: 0.8346 - val_loss: 1.7904 - val_accuracy: 0.8217\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83326\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.81746 to 1.79044, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 254us/step - loss: 1.7716 - accuracy: 0.8138 - val_loss: 1.7547 - val_accuracy: 0.8006\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83326\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.79044 to 1.75466, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 5s 267us/step - loss: 1.7439 - accuracy: 0.8116 - val_loss: 1.7346 - val_accuracy: 0.7948\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83326\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.75466 to 1.73460, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 5s 274us/step - loss: 1.7181 - accuracy: 0.8125 - val_loss: 1.7230 - val_accuracy: 0.8032\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83326\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.73460 to 1.72301, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 5s 284us/step - loss: 1.6893 - accuracy: 0.8210 - val_loss: 1.6940 - val_accuracy: 0.8127\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83326\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.72301 to 1.69398, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 255us/step - loss: 1.6703 - accuracy: 0.8276 - val_loss: 1.6759 - val_accuracy: 0.8220\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83326\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.69398 to 1.67587, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 257us/step - loss: 1.6528 - accuracy: 0.8343 - val_loss: 1.6647 - val_accuracy: 0.8269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83326\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.67587 to 1.66471, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 257us/step - loss: 1.6377 - accuracy: 0.8424 - val_loss: 1.6550 - val_accuracy: 0.8248\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83326\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.66471 to 1.65504, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 256us/step - loss: 1.6230 - accuracy: 0.8505 - val_loss: 1.6455 - val_accuracy: 0.8284\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83326\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.65504 to 1.64551, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 257us/step - loss: 1.6098 - accuracy: 0.8571 - val_loss: 1.6351 - val_accuracy: 0.8382\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83326 to 0.83817, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.64551 to 1.63513, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 254us/step - loss: 1.5972 - accuracy: 0.8640 - val_loss: 1.6296 - val_accuracy: 0.8433\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83817 to 0.84330, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.63513 to 1.62957, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 255us/step - loss: 1.5853 - accuracy: 0.8701 - val_loss: 1.6209 - val_accuracy: 0.8557\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84330 to 0.85572, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.62957 to 1.62086, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 255us/step - loss: 1.5745 - accuracy: 0.8749 - val_loss: 1.6141 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.85572\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.62086 to 1.61406, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 5s 279us/step - loss: 1.5642 - accuracy: 0.8777 - val_loss: 1.6048 - val_accuracy: 0.8564\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85572 to 0.85645, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.61406 to 1.60479, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 5s 277us/step - loss: 1.5541 - accuracy: 0.8826 - val_loss: 1.6009 - val_accuracy: 0.8594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85645 to 0.85935, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.60479 to 1.60095, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 251us/step - loss: 1.5451 - accuracy: 0.8847 - val_loss: 1.5975 - val_accuracy: 0.8577\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.85935\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.60095 to 1.59746, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 251us/step - loss: 1.5358 - accuracy: 0.8885 - val_loss: 1.5930 - val_accuracy: 0.8536\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.85935\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.59746 to 1.59295, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 258us/step - loss: 1.5282 - accuracy: 0.8886 - val_loss: 1.5875 - val_accuracy: 0.8582\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.85935\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.59295 to 1.58754, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 252us/step - loss: 1.5205 - accuracy: 0.8916 - val_loss: 1.5836 - val_accuracy: 0.8621\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85935 to 0.86208, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.58754 to 1.58358, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 251us/step - loss: 1.5137 - accuracy: 0.8929 - val_loss: 1.5765 - val_accuracy: 0.8611\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86208\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.58358 to 1.57646, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 251us/step - loss: 1.5068 - accuracy: 0.8933 - val_loss: 1.5774 - val_accuracy: 0.8592\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86208\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.57646\n",
      "epoch 24\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 253us/step - loss: 1.5000 - accuracy: 0.8957 - val_loss: 1.5721 - val_accuracy: 0.8586\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86208\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57646 to 1.57214, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 256us/step - loss: 1.4946 - accuracy: 0.8956 - val_loss: 1.5674 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86208\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57214 to 1.56742, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 252us/step - loss: 1.4885 - accuracy: 0.8974 - val_loss: 1.5683 - val_accuracy: 0.8599\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86208\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.56742\n",
      "epoch 27\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 5s 262us/step - loss: 1.4847 - accuracy: 0.8973 - val_loss: 1.5625 - val_accuracy: 0.8584\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86208\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56742 to 1.56252, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 28\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 253us/step - loss: 1.4785 - accuracy: 0.8992 - val_loss: 1.5544 - val_accuracy: 0.8642\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86208 to 0.86422, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56252 to 1.55436, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 254us/step - loss: 1.4730 - accuracy: 0.9000 - val_loss: 1.5522 - val_accuracy: 0.8643\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86422 to 0.86435, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55436 to 1.55223, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 251us/step - loss: 1.4691 - accuracy: 0.8994 - val_loss: 1.5501 - val_accuracy: 0.8613\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86435\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55223 to 1.55011, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 253us/step - loss: 1.4649 - accuracy: 0.9005 - val_loss: 1.5559 - val_accuracy: 0.8598\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86435\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.55011\n",
      "epoch 32\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 256us/step - loss: 1.4610 - accuracy: 0.9011 - val_loss: 1.5521 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86435\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.55011\n",
      "epoch 33\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 254us/step - loss: 1.4576 - accuracy: 0.9011 - val_loss: 1.5434 - val_accuracy: 0.8648\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86435 to 0.86477, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55011 to 1.54339, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 34\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 5s 277us/step - loss: 1.4538 - accuracy: 0.9019 - val_loss: 1.5469 - val_accuracy: 0.8643\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86477\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.54339\n",
      "epoch 35\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 254us/step - loss: 1.4512 - accuracy: 0.9022 - val_loss: 1.5478 - val_accuracy: 0.8622\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86477\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.54339\n",
      "epoch 36\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 253us/step - loss: 1.4476 - accuracy: 0.9029 - val_loss: 1.5453 - val_accuracy: 0.8644\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86477\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.54339\n",
      "epoch 37\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17241/17241 [==============================] - 4s 242us/step - loss: 1.4442 - accuracy: 0.9022 - val_loss: 1.5445 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86477 to 0.86674, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.54339\n",
      "epoch 38\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 238us/step - loss: 1.4412 - accuracy: 0.9036 - val_loss: 1.5420 - val_accuracy: 0.8650\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86674\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54339 to 1.54198, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 39\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 239us/step - loss: 1.4396 - accuracy: 0.9031 - val_loss: 1.5493 - val_accuracy: 0.8614\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86674\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.54198\n",
      "epoch 40\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 238us/step - loss: 1.4365 - accuracy: 0.9036 - val_loss: 1.5388 - val_accuracy: 0.8647\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86674\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54198 to 1.53881, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 41\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 239us/step - loss: 1.4336 - accuracy: 0.9044 - val_loss: 1.5387 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86674\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53881 to 1.53875, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 42\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 240us/step - loss: 1.4313 - accuracy: 0.9049 - val_loss: 1.5400 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86674\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53875\n",
      "epoch 43\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 259us/step - loss: 1.4295 - accuracy: 0.9048 - val_loss: 1.5385 - val_accuracy: 0.8639\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86674\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53875 to 1.53855, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 44\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 252us/step - loss: 1.4279 - accuracy: 0.9043 - val_loss: 1.5389 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86674\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53855\n",
      "epoch 45\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 5s 288us/step - loss: 1.4260 - accuracy: 0.9052 - val_loss: 1.5363 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86674\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53855 to 1.53632, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 46\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 252us/step - loss: 1.4234 - accuracy: 0.9058 - val_loss: 1.5380 - val_accuracy: 0.8670\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86674 to 0.86704, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53632\n",
      "epoch 47\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 240us/step - loss: 1.4215 - accuracy: 0.9063 - val_loss: 1.5436 - val_accuracy: 0.8629\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86704\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53632\n",
      "epoch 48\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 250us/step - loss: 1.4206 - accuracy: 0.9060 - val_loss: 1.5401 - val_accuracy: 0.8639\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86704\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53632\n",
      "epoch 49\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 240us/step - loss: 1.4192 - accuracy: 0.9060 - val_loss: 1.5348 - val_accuracy: 0.8693\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86704 to 0.86930, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53632 to 1.53477, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 50\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 243us/step - loss: 1.4170 - accuracy: 0.9066 - val_loss: 1.5409 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 51\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 241us/step - loss: 1.4157 - accuracy: 0.9064 - val_loss: 1.5407 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 52\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 245us/step - loss: 1.4138 - accuracy: 0.9075 - val_loss: 1.5432 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 53\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 243us/step - loss: 1.4135 - accuracy: 0.9068 - val_loss: 1.5415 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 54\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 240us/step - loss: 1.4127 - accuracy: 0.9068 - val_loss: 1.5396 - val_accuracy: 0.8665\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 55\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 241us/step - loss: 1.4108 - accuracy: 0.9071 - val_loss: 1.5424 - val_accuracy: 0.8682\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 56\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 241us/step - loss: 1.4088 - accuracy: 0.9077 - val_loss: 1.5458 - val_accuracy: 0.8603\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 57\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 243us/step - loss: 1.4089 - accuracy: 0.9069 - val_loss: 1.5429 - val_accuracy: 0.8685\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 58\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 240us/step - loss: 1.4083 - accuracy: 0.9076 - val_loss: 1.5492 - val_accuracy: 0.8641\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 59\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 241us/step - loss: 1.4073 - accuracy: 0.9080 - val_loss: 1.5507 - val_accuracy: 0.8636\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 60\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17241/17241 [==============================] - 4s 239us/step - loss: 1.4056 - accuracy: 0.9089 - val_loss: 1.5485 - val_accuracy: 0.8648\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 61\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 238us/step - loss: 1.4044 - accuracy: 0.9088 - val_loss: 1.5474 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 62\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 253us/step - loss: 1.4039 - accuracy: 0.9081 - val_loss: 1.5470 - val_accuracy: 0.8625\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 63\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 244us/step - loss: 1.4034 - accuracy: 0.9084 - val_loss: 1.5447 - val_accuracy: 0.8655\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 64\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 239us/step - loss: 1.4017 - accuracy: 0.9087 - val_loss: 1.5519 - val_accuracy: 0.8614\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 65\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 241us/step - loss: 1.4016 - accuracy: 0.9086 - val_loss: 1.5491 - val_accuracy: 0.8634\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 66\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 243us/step - loss: 1.4015 - accuracy: 0.9087 - val_loss: 1.5489 - val_accuracy: 0.8662\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 67\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 238us/step - loss: 1.3997 - accuracy: 0.9093 - val_loss: 1.5542 - val_accuracy: 0.8606\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 68\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 238us/step - loss: 1.3995 - accuracy: 0.9091 - val_loss: 1.5542 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 69\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 252us/step - loss: 1.3991 - accuracy: 0.9086 - val_loss: 1.5519 - val_accuracy: 0.8639\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 70\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 243us/step - loss: 1.3981 - accuracy: 0.9094 - val_loss: 1.5476 - val_accuracy: 0.8675\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 71\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 5s 262us/step - loss: 1.3982 - accuracy: 0.9092 - val_loss: 1.5505 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 72\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 245us/step - loss: 1.3984 - accuracy: 0.9093 - val_loss: 1.5517 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 73\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 239us/step - loss: 1.3959 - accuracy: 0.9100 - val_loss: 1.5511 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 74\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 239us/step - loss: 1.3963 - accuracy: 0.9092 - val_loss: 1.5538 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 75\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 240us/step - loss: 1.3956 - accuracy: 0.9100 - val_loss: 1.5544 - val_accuracy: 0.8655\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 76\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 240us/step - loss: 1.3946 - accuracy: 0.9099 - val_loss: 1.5550 - val_accuracy: 0.8629\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 77\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 250us/step - loss: 1.3952 - accuracy: 0.9097 - val_loss: 1.5635 - val_accuracy: 0.8611\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 78\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 239us/step - loss: 1.3940 - accuracy: 0.9105 - val_loss: 1.5578 - val_accuracy: 0.8642\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "epoch 79\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 4s 238us/step - loss: 1.3949 - accuracy: 0.9097 - val_loss: 1.5608 - val_accuracy: 0.8631\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.53477\n",
      "doing 6th fold\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1, 100)       0           dropout_31[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1, 180)       406080      lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1, 180)       720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 1, 180)       0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1, 180)       0           dropout_32[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1, 180)       521280      lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1, 180)       720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 1, 180)       0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1, 180)       0           dropout_33[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1, 181)       0           lambda_21[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 41, 180)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1, 100)       0           dropout_31[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1, 180)       406080      lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1, 180)       720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 1, 180)       0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1, 180)       0           dropout_32[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1, 180)       521280      lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1, 180)       720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 1, 180)       0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1, 180)       0           dropout_33[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1, 181)       0           lambda_21[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 41, 180)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev2 (Reshape)                  (None, 10, 8)        0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 8s 459us/step - loss: 2.0183 - accuracy: 0.4314 - val_loss: 1.8977 - val_accuracy: 0.4795\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.47953, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.89767, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 237us/step - loss: 1.9015 - accuracy: 0.5145 - val_loss: 1.8664 - val_accuracy: 0.6960\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.47953 to 0.69601, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.89767 to 1.86638, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 246us/step - loss: 1.8395 - accuracy: 0.7030 - val_loss: 1.8213 - val_accuracy: 0.7635\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.69601 to 0.76349, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.86638 to 1.82126, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 244us/step - loss: 1.7993 - accuracy: 0.7810 - val_loss: 1.7733 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.76349 to 0.79828, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.82126 to 1.77329, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 242us/step - loss: 1.7659 - accuracy: 0.7935 - val_loss: 1.7507 - val_accuracy: 0.7985\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.79828 to 0.79852, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.77329 to 1.75067, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 253us/step - loss: 1.7383 - accuracy: 0.8012 - val_loss: 1.7283 - val_accuracy: 0.7994\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.79852 to 0.79936, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.75067 to 1.72834, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 250us/step - loss: 1.7095 - accuracy: 0.8101 - val_loss: 1.7054 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.79936 to 0.79996, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.72834 to 1.70542, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 247us/step - loss: 1.6884 - accuracy: 0.8159 - val_loss: 1.6868 - val_accuracy: 0.8038\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.79996 to 0.80375, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.70542 to 1.68682, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 254us/step - loss: 1.6707 - accuracy: 0.8227 - val_loss: 1.6729 - val_accuracy: 0.8041\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80375 to 0.80407, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.68682 to 1.67294, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 246us/step - loss: 1.6551 - accuracy: 0.8293 - val_loss: 1.6600 - val_accuracy: 0.8049\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80407 to 0.80495, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.67294 to 1.65996, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 244us/step - loss: 1.6397 - accuracy: 0.8362 - val_loss: 1.6479 - val_accuracy: 0.8115\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80495 to 0.81153, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.65996 to 1.64792, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 242us/step - loss: 1.6253 - accuracy: 0.8448 - val_loss: 1.6379 - val_accuracy: 0.8133\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81153 to 0.81329, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.64792 to 1.63795, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 242us/step - loss: 1.6117 - accuracy: 0.8533 - val_loss: 1.6284 - val_accuracy: 0.8190\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81329 to 0.81903, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.63795 to 1.62840, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 243us/step - loss: 1.5991 - accuracy: 0.8612 - val_loss: 1.6174 - val_accuracy: 0.8299\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81903 to 0.82993, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.62840 to 1.61739, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 246us/step - loss: 1.5871 - accuracy: 0.8671 - val_loss: 1.6075 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82993 to 0.84621, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.61739 to 1.60747, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 243us/step - loss: 1.5758 - accuracy: 0.8725 - val_loss: 1.6023 - val_accuracy: 0.8312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84621\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.60747 to 1.60232, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 242us/step - loss: 1.5647 - accuracy: 0.8776 - val_loss: 1.5933 - val_accuracy: 0.8542\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84621 to 0.85419, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.60232 to 1.59333, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 243us/step - loss: 1.5546 - accuracy: 0.8818 - val_loss: 1.5858 - val_accuracy: 0.8485\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.85419\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.59333 to 1.58577, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 243us/step - loss: 1.5455 - accuracy: 0.8835 - val_loss: 1.5800 - val_accuracy: 0.8597\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85419 to 0.85966, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.58577 to 1.57998, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 253us/step - loss: 1.5365 - accuracy: 0.8875 - val_loss: 1.5753 - val_accuracy: 0.8564\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.85966\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57998 to 1.57533, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 248us/step - loss: 1.5283 - accuracy: 0.8894 - val_loss: 1.5667 - val_accuracy: 0.8671\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85966 to 0.86708, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57533 to 1.56667, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 242us/step - loss: 1.5208 - accuracy: 0.8915 - val_loss: 1.5618 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86708\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56667 to 1.56180, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 242us/step - loss: 1.5130 - accuracy: 0.8931 - val_loss: 1.5601 - val_accuracy: 0.8504\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86708\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56180 to 1.56015, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 284us/step - loss: 1.5063 - accuracy: 0.8932 - val_loss: 1.5528 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86708 to 0.86983, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56015 to 1.55280, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 246us/step - loss: 1.4996 - accuracy: 0.8954 - val_loss: 1.5480 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86983\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55280 to 1.54796, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 243us/step - loss: 1.4931 - accuracy: 0.8973 - val_loss: 1.5459 - val_accuracy: 0.8702\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86983 to 0.87015, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54796 to 1.54592, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 242us/step - loss: 1.4877 - accuracy: 0.8975 - val_loss: 1.5408 - val_accuracy: 0.8715\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87015 to 0.87147, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54592 to 1.54077, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 243us/step - loss: 1.4819 - accuracy: 0.8987 - val_loss: 1.5401 - val_accuracy: 0.8636\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87147\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54077 to 1.54009, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 28\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 246us/step - loss: 1.4770 - accuracy: 0.8993 - val_loss: 1.5369 - val_accuracy: 0.8699\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87147\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54009 to 1.53693, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 252us/step - loss: 1.4723 - accuracy: 0.9000 - val_loss: 1.5302 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87147\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53693 to 1.53020, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 247us/step - loss: 1.4675 - accuracy: 0.9012 - val_loss: 1.5302 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87147\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53020 to 1.53019, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 241us/step - loss: 1.4635 - accuracy: 0.9006 - val_loss: 1.5263 - val_accuracy: 0.8701\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87147\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53019 to 1.52625, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 241us/step - loss: 1.4583 - accuracy: 0.9021 - val_loss: 1.5252 - val_accuracy: 0.8694\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87147\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52625 to 1.52517, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17077/17077 [==============================] - 4s 246us/step - loss: 1.4553 - accuracy: 0.9018 - val_loss: 1.5215 - val_accuracy: 0.8737\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87147 to 0.87366, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52517 to 1.52147, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 34\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 252us/step - loss: 1.4511 - accuracy: 0.9029 - val_loss: 1.5201 - val_accuracy: 0.8702\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87366\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52147 to 1.52013, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 257us/step - loss: 1.4483 - accuracy: 0.9025 - val_loss: 1.5179 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87366\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52013 to 1.51787, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 36\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 270us/step - loss: 1.4447 - accuracy: 0.9038 - val_loss: 1.5186 - val_accuracy: 0.8677\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87366\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51787\n",
      "epoch 37\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 244us/step - loss: 1.4416 - accuracy: 0.9041 - val_loss: 1.5173 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87366\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51787 to 1.51732, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 38\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 242us/step - loss: 1.4391 - accuracy: 0.9043 - val_loss: 1.5181 - val_accuracy: 0.8690\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87366\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51732\n",
      "epoch 39\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 240us/step - loss: 1.4354 - accuracy: 0.9052 - val_loss: 1.5163 - val_accuracy: 0.8690\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87366\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51732 to 1.51628, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 40\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 240us/step - loss: 1.4335 - accuracy: 0.9054 - val_loss: 1.5122 - val_accuracy: 0.8722\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87366\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51628 to 1.51217, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 41\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 248us/step - loss: 1.4316 - accuracy: 0.9052 - val_loss: 1.5131 - val_accuracy: 0.8752\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87366 to 0.87522, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51217\n",
      "epoch 42\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 6s 324us/step - loss: 1.4285 - accuracy: 0.9055 - val_loss: 1.5138 - val_accuracy: 0.8692\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51217\n",
      "epoch 43\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 288us/step - loss: 1.4264 - accuracy: 0.9062 - val_loss: 1.5088 - val_accuracy: 0.8725\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51217 to 1.50876, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 44\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 255us/step - loss: 1.4231 - accuracy: 0.9068 - val_loss: 1.5143 - val_accuracy: 0.8727\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50876\n",
      "epoch 45\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 242us/step - loss: 1.4234 - accuracy: 0.9055 - val_loss: 1.5114 - val_accuracy: 0.8728\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50876\n",
      "epoch 46\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 240us/step - loss: 1.4205 - accuracy: 0.9063 - val_loss: 1.5136 - val_accuracy: 0.8716\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50876\n",
      "epoch 47\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 270us/step - loss: 1.4192 - accuracy: 0.9069 - val_loss: 1.5133 - val_accuracy: 0.8687\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50876\n",
      "epoch 48\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 305us/step - loss: 1.4167 - accuracy: 0.9077 - val_loss: 1.5139 - val_accuracy: 0.8682\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50876\n",
      "epoch 49\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 255us/step - loss: 1.4158 - accuracy: 0.9071 - val_loss: 1.5091 - val_accuracy: 0.8701\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50876\n",
      "epoch 50\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 263us/step - loss: 1.4137 - accuracy: 0.9075 - val_loss: 1.5114 - val_accuracy: 0.8708\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50876\n",
      "epoch 51\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 266us/step - loss: 1.4124 - accuracy: 0.9077 - val_loss: 1.5053 - val_accuracy: 0.8733\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50876 to 1.50534, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 52\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 273us/step - loss: 1.4113 - accuracy: 0.9081 - val_loss: 1.5112 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 53\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 269us/step - loss: 1.4106 - accuracy: 0.9073 - val_loss: 1.5078 - val_accuracy: 0.8710\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 54\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 263us/step - loss: 1.4089 - accuracy: 0.9084 - val_loss: 1.5055 - val_accuracy: 0.8743\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 55\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 272us/step - loss: 1.4072 - accuracy: 0.9085 - val_loss: 1.5107 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 56\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17077/17077 [==============================] - 5s 267us/step - loss: 1.4056 - accuracy: 0.9084 - val_loss: 1.5122 - val_accuracy: 0.8709\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 57\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 255us/step - loss: 1.4062 - accuracy: 0.9084 - val_loss: 1.5096 - val_accuracy: 0.8722\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 58\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 249us/step - loss: 1.4041 - accuracy: 0.9088 - val_loss: 1.5143 - val_accuracy: 0.8690\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 59\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 251us/step - loss: 1.4036 - accuracy: 0.9091 - val_loss: 1.5153 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 60\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 258us/step - loss: 1.4029 - accuracy: 0.9086 - val_loss: 1.5126 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 61\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 266us/step - loss: 1.4007 - accuracy: 0.9094 - val_loss: 1.5138 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 62\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 259us/step - loss: 1.4005 - accuracy: 0.9095 - val_loss: 1.5128 - val_accuracy: 0.8690\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 63\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 264us/step - loss: 1.3992 - accuracy: 0.9101 - val_loss: 1.5102 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 64\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 255us/step - loss: 1.4000 - accuracy: 0.9094 - val_loss: 1.5104 - val_accuracy: 0.8739\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 65\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 254us/step - loss: 1.3986 - accuracy: 0.9099 - val_loss: 1.5134 - val_accuracy: 0.8720\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 66\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 253us/step - loss: 1.3980 - accuracy: 0.9101 - val_loss: 1.5101 - val_accuracy: 0.8731\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 67\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 254us/step - loss: 1.3961 - accuracy: 0.9104 - val_loss: 1.5132 - val_accuracy: 0.8730\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 68\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 276us/step - loss: 1.3953 - accuracy: 0.9107 - val_loss: 1.5158 - val_accuracy: 0.8723\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 69\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 276us/step - loss: 1.3946 - accuracy: 0.9106 - val_loss: 1.5205 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 70\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 269us/step - loss: 1.3945 - accuracy: 0.9100 - val_loss: 1.5168 - val_accuracy: 0.8727\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 71\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 255us/step - loss: 1.3943 - accuracy: 0.9100 - val_loss: 1.5159 - val_accuracy: 0.8733\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 72\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 255us/step - loss: 1.3931 - accuracy: 0.9107 - val_loss: 1.5153 - val_accuracy: 0.8737\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 73\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 257us/step - loss: 1.3937 - accuracy: 0.9102 - val_loss: 1.5136 - val_accuracy: 0.8713\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 74\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 5s 266us/step - loss: 1.3924 - accuracy: 0.9109 - val_loss: 1.5155 - val_accuracy: 0.8688\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 75\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 258us/step - loss: 1.3921 - accuracy: 0.9109 - val_loss: 1.5211 - val_accuracy: 0.8710\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 76\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 258us/step - loss: 1.3918 - accuracy: 0.9112 - val_loss: 1.5159 - val_accuracy: 0.8726\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 77\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 263us/step - loss: 1.3904 - accuracy: 0.9116 - val_loss: 1.5170 - val_accuracy: 0.8721\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 78\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 256us/step - loss: 1.3903 - accuracy: 0.9114 - val_loss: 1.5119 - val_accuracy: 0.8713\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "epoch 79\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 4s 255us/step - loss: 1.3900 - accuracy: 0.9116 - val_loss: 1.5155 - val_accuracy: 0.8715\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.50534\n",
      "doing 7th fold\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1, 100)       0           dropout_36[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1, 180)       406080      lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 1, 180)       720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1, 180)       0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1, 180)       0           dropout_37[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1, 180)       521280      lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 1, 180)       720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1, 180)       0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1, 180)       0           dropout_38[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1, 181)       0           lambda_24[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 41, 180)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1, 100)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 1, 100)       0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1, 100)       0           dropout_36[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1, 180)       406080      lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 1, 180)       720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1, 180)       0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1, 180)       0           dropout_37[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1, 180)       521280      lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 1, 180)       720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1, 180)       0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1, 180)       0           dropout_38[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1, 181)       0           lambda_24[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 41, 180)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev2 (Reshape)                  (None, 10, 8)        0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev1 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,601,553\n",
      "Trainable params: 1,600,471\n",
      "Non-trainable params: 1,082\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 8s 476us/step - loss: 2.0143 - accuracy: 0.4635 - val_loss: 1.9079 - val_accuracy: 0.5617\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56170, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.90794, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 239us/step - loss: 1.9056 - accuracy: 0.6036 - val_loss: 1.8411 - val_accuracy: 0.7383\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.56170 to 0.73834, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.90794 to 1.84107, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 259us/step - loss: 1.8433 - accuracy: 0.7254 - val_loss: 1.8091 - val_accuracy: 0.8133\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.73834 to 0.81328, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.84107 to 1.80907, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 249us/step - loss: 1.7984 - accuracy: 0.7970 - val_loss: 1.7646 - val_accuracy: 0.8118\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.81328\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.80907 to 1.76455, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.7654 - accuracy: 0.8067 - val_loss: 1.7465 - val_accuracy: 0.8091\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.81328\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.76455 to 1.74651, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 243us/step - loss: 1.7401 - accuracy: 0.8075 - val_loss: 1.7308 - val_accuracy: 0.8049\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.81328\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.74651 to 1.73078, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 243us/step - loss: 1.7179 - accuracy: 0.8090 - val_loss: 1.7065 - val_accuracy: 0.8070\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.81328\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.73078 to 1.70654, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 243us/step - loss: 1.6968 - accuracy: 0.8142 - val_loss: 1.6956 - val_accuracy: 0.8078\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.81328\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.70654 to 1.69564, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 244us/step - loss: 1.6762 - accuracy: 0.8194 - val_loss: 1.6746 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.81328\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.69564 to 1.67462, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 242us/step - loss: 1.6559 - accuracy: 0.8286 - val_loss: 1.6595 - val_accuracy: 0.8087\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.81328\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.67462 to 1.65953, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 249us/step - loss: 1.6399 - accuracy: 0.8369 - val_loss: 1.6423 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81328 to 0.81964, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.65953 to 1.64232, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 246us/step - loss: 1.6251 - accuracy: 0.8474 - val_loss: 1.6309 - val_accuracy: 0.8309\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81964 to 0.83095, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.64232 to 1.63085, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 247us/step - loss: 1.6117 - accuracy: 0.8570 - val_loss: 1.6199 - val_accuracy: 0.8272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.83095\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.63085 to 1.61990, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 246us/step - loss: 1.5988 - accuracy: 0.8644 - val_loss: 1.6129 - val_accuracy: 0.8336\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83095 to 0.83356, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.61990 to 1.61290, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.5870 - accuracy: 0.8703 - val_loss: 1.6011 - val_accuracy: 0.8481\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83356 to 0.84814, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.61290 to 1.60107, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 244us/step - loss: 1.5754 - accuracy: 0.8754 - val_loss: 1.5960 - val_accuracy: 0.8472\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.84814\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.60107 to 1.59600, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 257us/step - loss: 1.5656 - accuracy: 0.8789 - val_loss: 1.5843 - val_accuracy: 0.8547\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84814 to 0.85470, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.59600 to 1.58432, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17053/17053 [==============================] - 4s 243us/step - loss: 1.5551 - accuracy: 0.8830 - val_loss: 1.5766 - val_accuracy: 0.8606\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85470 to 0.86063, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.58432 to 1.57662, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 243us/step - loss: 1.5456 - accuracy: 0.8867 - val_loss: 1.5701 - val_accuracy: 0.8634\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86063 to 0.86336, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57662 to 1.57011, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 248us/step - loss: 1.5371 - accuracy: 0.8879 - val_loss: 1.5661 - val_accuracy: 0.8622\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86336\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.57011 to 1.56609, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 244us/step - loss: 1.5287 - accuracy: 0.8914 - val_loss: 1.5589 - val_accuracy: 0.8662\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86336 to 0.86624, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.56609 to 1.55889, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 244us/step - loss: 1.5212 - accuracy: 0.8920 - val_loss: 1.5550 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86624\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55889 to 1.55500, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.5137 - accuracy: 0.8943 - val_loss: 1.5496 - val_accuracy: 0.8702\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86624 to 0.87020, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.55500 to 1.54955, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 246us/step - loss: 1.5073 - accuracy: 0.8949 - val_loss: 1.5443 - val_accuracy: 0.8709\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87020 to 0.87095, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54955 to 1.54430, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 250us/step - loss: 1.5007 - accuracy: 0.8963 - val_loss: 1.5385 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87095\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.54430 to 1.53848, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 248us/step - loss: 1.4942 - accuracy: 0.8978 - val_loss: 1.5334 - val_accuracy: 0.8730\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87095 to 0.87304, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53848 to 1.53337, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 249us/step - loss: 1.4886 - accuracy: 0.8988 - val_loss: 1.5286 - val_accuracy: 0.8728\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87304\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.53337 to 1.52865, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 246us/step - loss: 1.4825 - accuracy: 0.8995 - val_loss: 1.5259 - val_accuracy: 0.8710\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87304\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52865 to 1.52587, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 28\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 248us/step - loss: 1.4771 - accuracy: 0.8999 - val_loss: 1.5241 - val_accuracy: 0.8735\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87304 to 0.87352, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52587 to 1.52407, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 255us/step - loss: 1.4726 - accuracy: 0.9007 - val_loss: 1.5189 - val_accuracy: 0.8724\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87352\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.52407 to 1.51891, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 257us/step - loss: 1.4686 - accuracy: 0.9010 - val_loss: 1.5183 - val_accuracy: 0.8699\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87352\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51891 to 1.51826, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 254us/step - loss: 1.4644 - accuracy: 0.9014 - val_loss: 1.5157 - val_accuracy: 0.8713\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87352\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51826 to 1.51572, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 247us/step - loss: 1.4598 - accuracy: 0.9026 - val_loss: 1.5122 - val_accuracy: 0.8749\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87352 to 0.87490, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51572 to 1.51222, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 248us/step - loss: 1.4558 - accuracy: 0.9027 - val_loss: 1.5093 - val_accuracy: 0.8749\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87490 to 0.87494, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.51222 to 1.50929, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 34\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.4526 - accuracy: 0.9031 - val_loss: 1.5083 - val_accuracy: 0.8730\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87494\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50929 to 1.50827, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 5s 265us/step - loss: 1.4488 - accuracy: 0.9036 - val_loss: 1.5075 - val_accuracy: 0.8722\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87494\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50827 to 1.50752, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 36\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 5s 275us/step - loss: 1.4461 - accuracy: 0.9041 - val_loss: 1.5034 - val_accuracy: 0.8741\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87494\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50752 to 1.50335, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 37\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 5s 280us/step - loss: 1.4426 - accuracy: 0.9043 - val_loss: 1.5032 - val_accuracy: 0.8742\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87494\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50335 to 1.50322, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 38\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 246us/step - loss: 1.4411 - accuracy: 0.9039 - val_loss: 1.5025 - val_accuracy: 0.8752\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87494 to 0.87522, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50322 to 1.50249, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 39\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.4378 - accuracy: 0.9050 - val_loss: 1.5011 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50249 to 1.50105, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 40\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 246us/step - loss: 1.4356 - accuracy: 0.9046 - val_loss: 1.4992 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.50105 to 1.49918, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 41\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 5s 264us/step - loss: 1.4331 - accuracy: 0.9049 - val_loss: 1.4986 - val_accuracy: 0.8737\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.49918 to 1.49859, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 42\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 5s 278us/step - loss: 1.4305 - accuracy: 0.9055 - val_loss: 1.4996 - val_accuracy: 0.8739\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49859\n",
      "epoch 43\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.4285 - accuracy: 0.9051 - val_loss: 1.4949 - val_accuracy: 0.8749\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87522\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.49859 to 1.49493, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 44\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 256us/step - loss: 1.4259 - accuracy: 0.9058 - val_loss: 1.4993 - val_accuracy: 0.8753\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87522 to 0.87526, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49493\n",
      "epoch 45\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.4244 - accuracy: 0.9063 - val_loss: 1.4996 - val_accuracy: 0.8752\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87526\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49493\n",
      "epoch 46\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 252us/step - loss: 1.4229 - accuracy: 0.9067 - val_loss: 1.4959 - val_accuracy: 0.8742\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87526\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49493\n",
      "epoch 47\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 246us/step - loss: 1.4202 - accuracy: 0.9069 - val_loss: 1.5004 - val_accuracy: 0.8739\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87526\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49493\n",
      "epoch 48\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 246us/step - loss: 1.4199 - accuracy: 0.9067 - val_loss: 1.4955 - val_accuracy: 0.8756\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87526 to 0.87561, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49493\n",
      "epoch 49\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 246us/step - loss: 1.4166 - accuracy: 0.9075 - val_loss: 1.5007 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49493\n",
      "epoch 50\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.4159 - accuracy: 0.9075 - val_loss: 1.4981 - val_accuracy: 0.8739\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49493\n",
      "epoch 51\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 249us/step - loss: 1.4151 - accuracy: 0.9071 - val_loss: 1.4930 - val_accuracy: 0.8743\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.49493 to 1.49298, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 52\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.4139 - accuracy: 0.9072 - val_loss: 1.4933 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49298\n",
      "epoch 53\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 249us/step - loss: 1.4116 - accuracy: 0.9082 - val_loss: 1.4930 - val_accuracy: 0.8741\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.49298 to 1.49295, saving model to E:/论文真的非常重要请好好学习/2021.2 MULocDeep-master/kmer方法的mul/result/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 54\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 250us/step - loss: 1.4105 - accuracy: 0.9081 - val_loss: 1.4996 - val_accuracy: 0.8736\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 55\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.4104 - accuracy: 0.9076 - val_loss: 1.4991 - val_accuracy: 0.8725\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 56\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 247us/step - loss: 1.4087 - accuracy: 0.9083 - val_loss: 1.4973 - val_accuracy: 0.8728\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 57\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 246us/step - loss: 1.4076 - accuracy: 0.9081 - val_loss: 1.4976 - val_accuracy: 0.8723\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 58\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 257us/step - loss: 1.4064 - accuracy: 0.9080 - val_loss: 1.5035 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 59\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 250us/step - loss: 1.4058 - accuracy: 0.9087 - val_loss: 1.4952 - val_accuracy: 0.8728\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 60\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 244us/step - loss: 1.4037 - accuracy: 0.9089 - val_loss: 1.4984 - val_accuracy: 0.8731\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 61\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.4034 - accuracy: 0.9091 - val_loss: 1.5003 - val_accuracy: 0.8720\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 62\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 243us/step - loss: 1.4035 - accuracy: 0.9081 - val_loss: 1.5011 - val_accuracy: 0.8694\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 63\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.4011 - accuracy: 0.9097 - val_loss: 1.5020 - val_accuracy: 0.8711\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 64\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 244us/step - loss: 1.4022 - accuracy: 0.9088 - val_loss: 1.5023 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 65\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 247us/step - loss: 1.4003 - accuracy: 0.9093 - val_loss: 1.4974 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 66\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.4004 - accuracy: 0.9090 - val_loss: 1.5017 - val_accuracy: 0.8710\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 67\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 255us/step - loss: 1.3976 - accuracy: 0.9103 - val_loss: 1.5107 - val_accuracy: 0.8720\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 68\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 246us/step - loss: 1.3988 - accuracy: 0.9092 - val_loss: 1.5029 - val_accuracy: 0.8721\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 69\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 248us/step - loss: 1.3967 - accuracy: 0.9099 - val_loss: 1.5049 - val_accuracy: 0.8703\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 70\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.3967 - accuracy: 0.9100 - val_loss: 1.5068 - val_accuracy: 0.8712\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 71\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.3956 - accuracy: 0.9103 - val_loss: 1.5037 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 72\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 252us/step - loss: 1.3959 - accuracy: 0.9103 - val_loss: 1.5062 - val_accuracy: 0.8718\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 73\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 248us/step - loss: 1.3944 - accuracy: 0.9103 - val_loss: 1.5102 - val_accuracy: 0.8702\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 74\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 248us/step - loss: 1.3949 - accuracy: 0.9104 - val_loss: 1.4998 - val_accuracy: 0.8723\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 75\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.3936 - accuracy: 0.9109 - val_loss: 1.5018 - val_accuracy: 0.8745\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 76\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 246us/step - loss: 1.3919 - accuracy: 0.9108 - val_loss: 1.5065 - val_accuracy: 0.8730\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 77\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 246us/step - loss: 1.3935 - accuracy: 0.9111 - val_loss: 1.5080 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 78\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 245us/step - loss: 1.3919 - accuracy: 0.9113 - val_loss: 1.5075 - val_accuracy: 0.8727\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n",
      "epoch 79\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 4s 247us/step - loss: 1.3926 - accuracy: 0.9104 - val_loss: 1.5057 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.87561\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49295\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-accused",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
