{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "import math\n",
    "from itertools import product\n",
    "import argparse\n",
    "import sys\n",
    "from utils_cnn_CS import *\n",
    "import calendar\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "damaged-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eachseq(seq,pssmfile,mask_seq,new_pssms):\n",
    "    if os.path.exists(pssmfile):  #如果pssm文件存在\n",
    "        print(\"found \" + pssmfile + \"\\n\")  #输出找到pssm文件+换行\n",
    "        pssm = readPSSM(pssmfile)  #读取pssm文件\n",
    "    else:  #否则\n",
    "        print(\"using Blosum62\\n\")  #输出使用Blosum62+换行\n",
    "        #pssm = convertSampleToBlosum62(seq)  #把Blosum62矩阵当作pssm用\n",
    "        pssm = convertSampleToCBOW(seq)\n",
    "    pssm = pssm.astype(float)  #对pssm的数据类型转换为浮点型\n",
    "    PhyChem = convertSampleToPhysicsVector_pca(seq)  #将样本转化为物理向量\n",
    "    pssm = np.concatenate((PhyChem, pssm), axis=1)  #物化指标和pssm对应行进行数组拼接\n",
    "    seql = len(seq)   #序列长度  \n",
    "    if seql <= 1000:  #如果序列长度小于等于1000\n",
    "        padnum = 1000 - seql  #pad大小为1000-序列长度\n",
    "        padmatrix = np.zeros([padnum, 25])  #pad矩阵为行数为padnum，列数为25的全0矩阵，即用0填充不足的地方\n",
    "        pssm = np.concatenate((pssm, padmatrix), axis=0)  #物化指标和pssm进行数组拼接 \n",
    "        new_pssms.append(pssm)  #新的pssm空列表中添加pssm矩阵\n",
    "        mask_seq.append(gen_mask_mat(seql, padnum))  #mask序列空列表添加gen_mask矩阵，序列长度为行数，padnum为列数？？？\n",
    "    else:  #如果序列长度大于1000\n",
    "        pssm = np.concatenate((pssm[0:500, :], pssm[seql - 500:seql, :]), axis=0)  #pssm矩阵为前500行和后500行矩阵的拼接\n",
    "        new_pssms.append(pssm)  #新的pssm空列表中添加pssm矩阵\n",
    "        mask_seq.append(gen_mask_mat(1000, 0))  #mask序列空列表添加1000行0列的？？？gen_mask矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metric-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpad(seqfile, labelfile, pssmdir=\"\", npzfile = \"\"): #定义endpad(序列文件，标签文件，pssm路径，npz文件)\n",
    "    if not os.path.exists(npzfile):  #如果npz文件不存在，建立新的pssm空列表，标签空列表，mask序列空列表，id空列表\n",
    "        new_pssms = []\n",
    "        labels = []\n",
    "        mask_seq = []\n",
    "        ids=[]\n",
    "        seqs=[]\n",
    "        f = open(seqfile, \"r\")  #f为打开序列文件\n",
    "        f2 = open(labelfile, \"r\")  #f2为打开标签文件\n",
    "        line = f.readline()  #读取序列文件的第一行\n",
    "        while line != '':\n",
    "            pssmfile = pssmdir + line[1:].strip() + \"_pssm.txt\"  #pssm文件名=pssm地址+id名+_pssm.txt\n",
    "            if line[0] == '>':  #如果该行第一个字符为>\n",
    "                id = line.strip()[1:]  #id为去掉>的字符\n",
    "                ids.append(id)   #在id空列表中添加id\n",
    "            label = f2.readline().strip()  #标签为f2（标签文件）中去掉首尾空格的内容\n",
    "            labels.append(label)  #在标签空列表中添加标签\n",
    "            seq = f.readline().strip()  #第一次seq为第2行的内容，实际seq为>行的下一行\n",
    "            #seql = len(seq)   #序列长度  \n",
    "            process_eachseq(seq,pssmfile,mask_seq,new_pssms)\n",
    "            line = f.readline()  #继续读取下一行，即>行\n",
    "        x = np.array(new_pssms)  #把new_pssms列表变为数组，赋给x\n",
    "        y = [convertlabels_to_categorical(i) for i in labels]  #把标签列表转化为类别(i)\n",
    "        y = np.array(y)  #再把类别转化为数组\n",
    "        mask = np.array(mask_seq)  #把mask_seq（标注的序列？）转化为数组\n",
    "        np.savez(npzfile, x=x, y=y, mask=mask, ids=ids)  #保存多个数组到同一个文件中,保存格式是.npz\n",
    "        return [x, y, mask,ids]  #返回pssm矩阵，类别，标注序列，名字id\n",
    "    else:  #如果上述都存在，直接转化为数组\n",
    "        mask = np.load(npzfile)['mask']\n",
    "        x = np.load(npzfile)['x']\n",
    "        y = np.load(npzfile)['y']\n",
    "        ids=np.load(npzfile)['ids']\n",
    "        return [x, y, mask,ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "warming-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MULocDeep(lv1_dir,lv2_dir,pssm_dir,output_dir,foldnum):\n",
    "    # get small data\n",
    "    [train_x, train_y, train_mask, train_ids] = endpad(\n",
    "        lv2_dir+\"lv2_train_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv2_dir+\"lv2_train_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv2_train_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    [val_x, val_y, val_mask,val_ids] = endpad(\n",
    "        lv2_dir+\"lv2_val_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv2_dir+\"lv2_val_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv2_val_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "\n",
    "    # get big data 训练10分类的多分类\n",
    "    [train_x_big, train_y_big, train_mask_big, train_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv1_train_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    [val_x_big, val_y_big, val_mask_big, val_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv1_val_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model_big, model_small = singlemodel(train_x)  #模型为singlemodel\n",
    "\n",
    "    filepath_acc_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_acc_small_lv2 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_small_lv2_acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_loss_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_loss-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_loss_small_lv2 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_small_lv2_loss-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "    checkpoint_acc_big_lev1 = ModelCheckpoint(filepath_acc_big_lv1, monitor='val_accuracy', save_best_only=True,\n",
    "                                          mode='max',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "\n",
    "    checkpoint_acc_small_lev2 = ModelCheckpoint(filepath_acc_small_lv2, monitor='val_lev2_accuracy', save_best_only=True,\n",
    "                                          mode='max',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    checkpoint_loss_big_lev1 = ModelCheckpoint(filepath_loss_big_lv1, monitor='val_loss', save_best_only=True,\n",
    "                                          mode='min',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    checkpoint_loss_small_lev2 = ModelCheckpoint(filepath_loss_small_lv2, monitor='val_lev2_loss', save_best_only=True,\n",
    "                                          mode='min',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    \n",
    "    for i in range(20):\n",
    "        # train small model\n",
    "        print(\"epoch \"+str(i)+\"\\n\")\n",
    "        '''fitHistory_batch_small = model_small.fit([train_x, train_mask.reshape(-1, 1000, 1)],\n",
    "                                                 [train_y,getTrue4out1(train_y)],\n",
    "                                                 batch_size=batch_size, epochs=1,\n",
    "                                                 validation_data=(\n",
    "                                                 [val_x, val_mask.reshape(-1, 1000, 1)], [val_y,getTrue4out1(val_y)]),\n",
    "                                                 callbacks=[checkpoint_acc_small_lev2,checkpoint_loss_small_lev2],verbose=1)'''\n",
    "        \n",
    "        # train big model  \n",
    "        fitHistory_batch_big = model_big.fit([train_x_big, train_mask_big.reshape(-1, 1000, 1)],\n",
    "                                             [getTrue4out1(train_y_big)],  #为何大模型没有train_y_big\n",
    "                                             batch_size=batch_size, epochs=1,  #等于1？？\n",
    "                                             validation_data=(\n",
    "                                             [val_x_big, val_mask_big.reshape(-1, 1000, 1)], [getTrue4out1(val_y_big)]),  #也没有val_y_big\n",
    "                                             callbacks=[checkpoint_acc_big_lev1,checkpoint_loss_big_lev1], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alert-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_var(input_var,pssm_dir,output_dir,foldnum):\n",
    "    # get small data\n",
    "    [train_x,train_y,train_mask,train_ids]=endpad(input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_seq\",\n",
    "                                        input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_label\",\n",
    "                                        pssm_dir,\n",
    "                                        \"D:/deeploc/deeploc_40nr_8folds/train_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    [val_x,val_y,val_mask,val_ids]=endpad(input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_seq\",\n",
    "                                  input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_label\",\n",
    "                                  pssm_dir,\n",
    "                                  \"D:/deeploc/deeploc_40nr_8folds/val_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model = var_model(train_x)   #这里的模型是var_model\n",
    "\n",
    "    filepath_acc = output_dir+\"fold\" + str(foldnum) + \"acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "    checkpoint_acc = ModelCheckpoint(filepath_acc, monitor='val_accuracy', save_best_only=True, mode='max',\n",
    "                                 save_weights_only=True, verbose=1)\n",
    "    fitHistory_batch = model.fit([train_x,train_mask.reshape(-1,1000,1)],getTrue4out1(train_y),\n",
    "                                 batch_size=batch_size, epochs=20,\n",
    "                                 validation_data=([val_x,val_mask.reshape(-1,1000,1)], getTrue4out1(val_y)),\n",
    "                                 callbacks=[checkpoint_acc],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spiritual-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''我们常常可以把argparse的使用简化成下面四个步骤\n",
    "       1：import argparse\n",
    "       2：parser = argparse.ArgumentParser()\n",
    "       3：parser.add_argument()\n",
    "       4：parser.parse_args()\n",
    "       上面四个步骤解释如下：首先导入该模块；然后创建一个解析对象；然后向该对象中添加你要关注的命令行参数和选项，\n",
    "       每一个add_argument方法对应一个你要关注的参数或选项；最后调用parse_args()方法进行解析；解析成功之后即可使用'''\n",
    "    \n",
    "def main():\n",
    "    #加default\n",
    "    # description= 这个参数简要描述这个程度做什么以及怎么做\n",
    "    parser=argparse.ArgumentParser(\n",
    "        description='MULocDeep: interpretable protein localization classifier at sub-cellular and sub-organellar levels')\n",
    "    #MULocDeep_model  UniLoc-train-20nr\n",
    "    #--lv1_input_dir/--lv2_input_dir 亚细胞训练数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--lv1_input_dir', dest='lv1_dir', type=str, \n",
    "                        default=\"D:/mulocdeep/mul_data\",\n",
    "                        help='sub-cellular training data, contains 8 folds protein sequences and labels', required=False)\n",
    "    parser.add_argument('--lv2_input_dir', dest='lv2_dir', type=str,\n",
    "                       default=\"D:/mulocdeep/mul_data\",\n",
    "                       help='sub-cellular training data, contains 8 folds protein sequences and labels', required=False)\n",
    "    #--MULocDeep_model 添加它来训练MULocDeep模型，否则训练一个var模型\n",
    "    parser.add_argument('--MULocDeep_model', dest='modeltype', action='store_false',  #触发，store_true会触发DeepLoc\n",
    "                        #如果是store_false,则默认值是True，如果是store_true,则默认值是False  \n",
    "                        help='Add this to train the MULocDeep model, otherwise train a variant model', required=False)\n",
    "    #--model_output 受过训练的模型存储的目录的名称  需自己添加\n",
    "    parser.add_argument('--model_output', dest='outputdir', type=str, \n",
    "                       default=\"D:/mulocdeep/lv1_result1\",\n",
    "                       help='the name of the directory where the trained model stores', required=False)  #由True改成False\n",
    "    \n",
    "    parser.add_argument('-existPSSM', dest='existPSSM', type=str,\n",
    "                        default=\"D:/mulocdeep/mulocdeep_pssm_empty\",\n",
    "                        help='the name of the existing PSSM directory if there is one.', required=False)\n",
    "    \n",
    "    #var_model  deeploc_40nr_8folds\n",
    "    #--input_dir 训练var模型的数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--input_var', dest='var_dir', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_40nr_8folds\",\n",
    "                        help='data for traing the variant model, contains 8 folds protein sequences and labels', required=False)\n",
    "    #改true  并且还需要加一个model_ouput  一个是deeploc  一个是MULocDeep\n",
    "    parser.add_argument('--var_model_output', dest='var_outputdir', type=str, help='the name of the directory where the trained model stores', \n",
    "                        default=\"D:/deeploc/var_model_result1\",\n",
    "                        required=False)  #由True改成False\n",
    "    parser.add_argument('-var_existPSSM', dest='var_existPSSM', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_pssm\",\n",
    "                        help='the name of the existing PSSM directory if there is one.', required=False)\n",
    "    parser.set_defaults(feature=True)\n",
    "    #args = parser.parse_args()   #改\n",
    "    args = parser.parse_known_args()[0]   #jupyter下运行解析需要此代码\n",
    "    model_type=args.modeltype\n",
    "    input_lv1=args.lv1_dir\n",
    "    input_lv2 = args.lv2_dir\n",
    "    outputdir=args.outputdir\n",
    "    existPSSM = args.existPSSM\n",
    "    input_var=args.var_dir\n",
    "    var_outputdir=args.var_outputdir\n",
    "    var_existPSSM = args.var_existPSSM\n",
    "\n",
    "    if model_type==True:\n",
    "        if not input_lv1[len(input_lv1) - 1] == \"/\":\n",
    "            input_lv1 = input_lv1 + \"/\"\n",
    "        if not input_lv2[len(input_lv2) - 1] == \"/\":\n",
    "            input_lv2 = input_lv2 + \"/\"\n",
    "        if not outputdir[len(outputdir) - 1] == \"/\":\n",
    "            outputdir = outputdir + \"/\"\n",
    "        if not os.path.exists(outputdir):\n",
    "            os.mkdir(outputdir)\n",
    "        if existPSSM != \"\":\n",
    "            if not existPSSM[len(existPSSM) - 1] == \"/\":\n",
    "                existPSSM = existPSSM + \"/\"\n",
    "        if ((existPSSM == \"\") or (not os.path.exists(existPSSM))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            pssmdir = outputdir + str(ts) + \"_pssm/\"\n",
    "            if not os.path.exists(pssmdir):\n",
    "                os.makedirs(pssmdir)\n",
    "            process_input_train(input_lv1 + \"lv1_train.txt\", pssmdir)\n",
    "            process_input_train(input_lv2 + \"lv2_train.txt\", pssmdir)\n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, input_lv2, pssmdir, outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, input_lv2, existPSSM, outputdir, foldnum)\n",
    "    elif model_type==False:\n",
    "        if not input_var[len(input_var) - 1] == \"/\":\n",
    "            input_var = input_var + \"/\"\n",
    "        if not var_outputdir[len(var_outputdir) - 1] == \"/\":\n",
    "            var_outputdir = var_outputdir + \"/\"\n",
    "        if not os.path.exists(var_outputdir):\n",
    "            os.mkdir(var_outputdir)\n",
    "        if existPSSM != \"\":\n",
    "            if not var_existPSSM[len(var_existPSSM) - 1] == \"/\":\n",
    "                var_existPSSM = var_existPSSM + \"/\"\n",
    "        if ((var_existPSSM == \"\") or (not os.path.exists(var_existPSSM))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            pssmdir = var_outputdir + str(ts) + \"_pssm/\"\n",
    "            if not os.path.exists(pssmdir):\n",
    "                os.makedirs(pssmdir)\n",
    "            process_input_train(input_var + \"processed_deeploc_train_S_seq\", pssmdir)\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, pssmdir, var_outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, var_existPSSM, var_outputdir, foldnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-hearts",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing 0th fold\n",
      "WARNING:tensorflow:From C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1000, 25)     0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1000, 25)     650         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000, 25)     100         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 25)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1000, 25)     0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1000, 25)     1900        lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000, 25)     100         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 25)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1000, 25)     0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1000, 25)     3150        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1000, 25)     100         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000, 25)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1000, 25)     0           dropout_4[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1000, 25)     5650        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1000, 25)     100         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1000, 25)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1000, 25)     0           dropout_5[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1000, 25)     9400        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1000, 25)     100         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1000, 25)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1000, 25)     0           dropout_6[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1000, 25)     13150       lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 25)     100         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 25)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1000, 25)     0           dropout_7[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 180)    223560      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1000, 180)    720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1000, 180)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1000, 180)    0           dropout_8[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 180)    390960      lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1000, 180)    720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1000, 180)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1000, 180)    0           dropout_9[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 181)    0           lambda_9[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 41, 180)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1000, 25)     0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1000, 25)     650         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000, 25)     100         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 25)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1000, 25)     0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1000, 25)     1900        lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000, 25)     100         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 25)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1000, 25)     0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1000, 25)     3150        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1000, 25)     100         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000, 25)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1000, 25)     0           dropout_4[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1000, 25)     5650        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1000, 25)     100         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1000, 25)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1000, 25)     0           dropout_5[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1000, 25)     9400        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1000, 25)     100         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1000, 25)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1000, 25)     0           dropout_6[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1000, 25)     13150       lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 25)     100         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 25)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1000, 25)     0           dropout_7[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 180)    223560      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1000, 180)    720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1000, 180)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1000, 180)    0           dropout_8[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 180)    390960      lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1000, 180)    720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1000, 180)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1000, 180)    0           dropout_9[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 181)    0           lambda_9[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 41, 180)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 124s 7ms/step - loss: 0.7319 - accuracy: 0.7037 - val_loss: 0.6869 - val_accuracy: 0.8029\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80290, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68693, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 131s 8ms/step - loss: 0.6358 - accuracy: 0.8233 - val_loss: 0.6259 - val_accuracy: 0.8365\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80290 to 0.83648, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.68693 to 0.62585, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 112s 7ms/step - loss: 0.5943 - accuracy: 0.8519 - val_loss: 0.5742 - val_accuracy: 0.8605\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83648 to 0.86049, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.62585 to 0.57417, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.5652 - accuracy: 0.8670 - val_loss: 0.5462 - val_accuracy: 0.8715\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86049 to 0.87153, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57417 to 0.54624, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.5395 - accuracy: 0.8767 - val_loss: 0.5200 - val_accuracy: 0.8848\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87153 to 0.88479, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54624 to 0.51996, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 122s 7ms/step - loss: 0.5154 - accuracy: 0.8861 - val_loss: 0.4990 - val_accuracy: 0.8908\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88479 to 0.89084, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51996 to 0.49904, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.4929 - accuracy: 0.8934 - val_loss: 0.4770 - val_accuracy: 0.8995\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89084 to 0.89947, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49904 to 0.47698, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.4729 - accuracy: 0.8973 - val_loss: 0.4600 - val_accuracy: 0.9046\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89947 to 0.90458, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47698 to 0.46000, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 121s 7ms/step - loss: 0.4548 - accuracy: 0.9013 - val_loss: 0.4364 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90458 to 0.91014, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46000 to 0.43644, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 121s 7ms/step - loss: 0.4364 - accuracy: 0.9049 - val_loss: 0.4223 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91014 to 0.91284, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43644 to 0.42229, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 110s 6ms/step - loss: 0.4199 - accuracy: 0.9085 - val_loss: 0.4041 - val_accuracy: 0.9138\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91284 to 0.91378, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42229 to 0.40411, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.4035 - accuracy: 0.9109 - val_loss: 0.3916 - val_accuracy: 0.9131\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91378\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40411 to 0.39158, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.3882 - accuracy: 0.9135 - val_loss: 0.3781 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91378 to 0.91411, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39158 to 0.37805, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 119s 7ms/step - loss: 0.3739 - accuracy: 0.9158 - val_loss: 0.3637 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91411 to 0.91706, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37805 to 0.36370, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 118s 7ms/step - loss: 0.3610 - accuracy: 0.9178 - val_loss: 0.3539 - val_accuracy: 0.9174\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91706 to 0.91742, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36370 to 0.35391, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.3479 - accuracy: 0.9198 - val_loss: 0.3476 - val_accuracy: 0.9215\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91742 to 0.92151, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35391 to 0.34758, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 115s 7ms/step - loss: 0.3352 - accuracy: 0.9224 - val_loss: 0.3377 - val_accuracy: 0.9193\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92151\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34758 to 0.33766, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 117s 7ms/step - loss: 0.3250 - accuracy: 0.9240 - val_loss: 0.3210 - val_accuracy: 0.9214\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92151\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33766 to 0.32101, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.3154 - accuracy: 0.9255 - val_loss: 0.3117 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92151 to 0.92254, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32101 to 0.31170, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.3041 - accuracy: 0.9271 - val_loss: 0.3051 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92254 to 0.92601, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31170 to 0.30507, saving model to D:/mulocdeep/lv1_result1/fold0_big_lv1_loss-weights.hdf5\n",
      "doing 1th fold\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1000, 25)     0           dropout_12[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1000, 25)     650         lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1000, 25)     100         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1000, 25)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1000, 25)     0           dropout_13[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1000, 25)     1900        lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1000, 25)     100         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1000, 25)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1000, 25)     0           dropout_14[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1000, 25)     3150        lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1000, 25)     100         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1000, 25)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1000, 25)     0           dropout_15[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1000, 25)     5650        lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1000, 25)     100         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1000, 25)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1000, 25)     0           dropout_16[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1000, 25)     9400        lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1000, 25)     100         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1000, 25)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1000, 25)     0           dropout_17[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1000, 25)     13150       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1000, 25)     100         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1000, 25)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1000, 25)     0           dropout_18[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 180)    223560      lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1000, 180)    720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 1000, 180)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1000, 180)    0           dropout_19[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 180)    390960      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1000, 180)    720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 1000, 180)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1000, 180)    0           dropout_20[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1000, 181)    0           lambda_18[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 41, 180)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1000, 25)     0           dropout_12[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1000, 25)     650         lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1000, 25)     100         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1000, 25)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1000, 25)     0           dropout_13[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1000, 25)     1900        lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1000, 25)     100         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1000, 25)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1000, 25)     0           dropout_14[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1000, 25)     3150        lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1000, 25)     100         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1000, 25)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1000, 25)     0           dropout_15[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1000, 25)     5650        lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1000, 25)     100         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1000, 25)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1000, 25)     0           dropout_16[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1000, 25)     9400        lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1000, 25)     100         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1000, 25)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1000, 25)     0           dropout_17[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1000, 25)     13150       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1000, 25)     100         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1000, 25)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1000, 25)     0           dropout_18[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 180)    223560      lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1000, 180)    720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 1000, 180)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1000, 180)    0           dropout_19[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 180)    390960      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1000, 180)    720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 1000, 180)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1000, 180)    0           dropout_20[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1000, 181)    0           lambda_18[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 41, 180)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 114s 7ms/step - loss: 0.7415 - accuracy: 0.6820 - val_loss: 0.6724 - val_accuracy: 0.8094\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80937, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67238, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 109s 6ms/step - loss: 0.6407 - accuracy: 0.8129 - val_loss: 0.6303 - val_accuracy: 0.8246\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80937 to 0.82458, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.67238 to 0.63034, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 107s 6ms/step - loss: 0.5970 - accuracy: 0.8474 - val_loss: 0.5858 - val_accuracy: 0.8521\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82458 to 0.85215, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.63034 to 0.58584, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 106s 6ms/step - loss: 0.5659 - accuracy: 0.8658 - val_loss: 0.5689 - val_accuracy: 0.8716\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85215 to 0.87162, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.58584 to 0.56894, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 102s 6ms/step - loss: 0.5393 - accuracy: 0.8791 - val_loss: 0.5250 - val_accuracy: 0.8808\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87162 to 0.88082, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56894 to 0.52496, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 104s 6ms/step - loss: 0.5155 - accuracy: 0.8871 - val_loss: 0.5212 - val_accuracy: 0.8902\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88082 to 0.89018, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52496 to 0.52119, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 102s 6ms/step - loss: 0.4922 - accuracy: 0.8938 - val_loss: 0.4903 - val_accuracy: 0.8919\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89018 to 0.89190, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52119 to 0.49032, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 102s 6ms/step - loss: 0.4718 - accuracy: 0.8986 - val_loss: 0.4662 - val_accuracy: 0.8960\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89190 to 0.89603, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49032 to 0.46624, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 106s 6ms/step - loss: 0.4534 - accuracy: 0.9024 - val_loss: 0.4482 - val_accuracy: 0.8989\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89603 to 0.89890, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46624 to 0.44816, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 108s 6ms/step - loss: 0.4351 - accuracy: 0.9059 - val_loss: 0.4313 - val_accuracy: 0.9055\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89890 to 0.90552, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44816 to 0.43126, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 106s 6ms/step - loss: 0.4179 - accuracy: 0.9090 - val_loss: 0.4163 - val_accuracy: 0.9047\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90552\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43126 to 0.41634, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 106s 6ms/step - loss: 0.4016 - accuracy: 0.9115 - val_loss: 0.4036 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90552 to 0.91039, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41634 to 0.40357, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 107s 6ms/step - loss: 0.3872 - accuracy: 0.9138 - val_loss: 0.3919 - val_accuracy: 0.9083\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91039\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40357 to 0.39192, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 105s 6ms/step - loss: 0.3718 - accuracy: 0.9168 - val_loss: 0.3755 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91039 to 0.91186, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39192 to 0.37550, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 106s 6ms/step - loss: 0.3589 - accuracy: 0.9179 - val_loss: 0.3663 - val_accuracy: 0.9112\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91186\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37550 to 0.36629, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 105s 6ms/step - loss: 0.3460 - accuracy: 0.9204 - val_loss: 0.3549 - val_accuracy: 0.9140\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91186 to 0.91403, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36629 to 0.35493, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 109s 6ms/step - loss: 0.3330 - accuracy: 0.9235 - val_loss: 0.3440 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91403 to 0.91566, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35493 to 0.34396, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 108s 6ms/step - loss: 0.3225 - accuracy: 0.9253 - val_loss: 0.3360 - val_accuracy: 0.9161\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91566 to 0.91611, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34396 to 0.33603, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 105s 6ms/step - loss: 0.3130 - accuracy: 0.9260 - val_loss: 0.3278 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91611 to 0.91734, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33603 to 0.32781, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 108s 6ms/step - loss: 0.3025 - accuracy: 0.9276 - val_loss: 0.3177 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91734\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32781 to 0.31767, saving model to D:/mulocdeep/lv1_result1/fold1_big_lv1_loss-weights.hdf5\n",
      "doing 2th fold\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1000, 25)     0           dropout_23[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1000, 25)     650         lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1000, 25)     100         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 1000, 25)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1000, 25)     0           dropout_24[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1000, 25)     1900        lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1000, 25)     100         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 1000, 25)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1000, 25)     0           dropout_25[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1000, 25)     3150        lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1000, 25)     100         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1000, 25)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1000, 25)     0           dropout_26[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1000, 25)     5650        lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1000, 25)     100         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1000, 25)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1000, 25)     0           dropout_27[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1000, 25)     9400        lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1000, 25)     100         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1000, 25)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1000, 25)     0           dropout_28[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1000, 25)     13150       lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1000, 25)     100         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 1000, 25)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1000, 25)     0           dropout_29[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 180)    223560      lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1000, 180)    720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 1000, 180)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1000, 180)    0           dropout_30[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 180)    390960      lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1000, 180)    720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1000, 180)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 1000, 180)    0           dropout_31[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 181)    0           lambda_27[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 41, 180)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1000, 25)     0           dropout_23[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1000, 25)     650         lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1000, 25)     100         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 1000, 25)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1000, 25)     0           dropout_24[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1000, 25)     1900        lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1000, 25)     100         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 1000, 25)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1000, 25)     0           dropout_25[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1000, 25)     3150        lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1000, 25)     100         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1000, 25)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1000, 25)     0           dropout_26[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1000, 25)     5650        lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1000, 25)     100         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1000, 25)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1000, 25)     0           dropout_27[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1000, 25)     9400        lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1000, 25)     100         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1000, 25)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1000, 25)     0           dropout_28[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1000, 25)     13150       lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1000, 25)     100         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 1000, 25)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1000, 25)     0           dropout_29[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 180)    223560      lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1000, 180)    720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 1000, 180)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1000, 180)    0           dropout_30[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 180)    390960      lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1000, 180)    720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1000, 180)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 1000, 180)    0           dropout_31[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 181)    0           lambda_27[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 41, 180)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 114s 7ms/step - loss: 0.7400 - accuracy: 0.6811 - val_loss: 0.6481 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79831, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64813, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 111s 6ms/step - loss: 0.6349 - accuracy: 0.8210 - val_loss: 0.6393 - val_accuracy: 0.8517\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.79831 to 0.85171, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.64813 to 0.63929, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 106s 6ms/step - loss: 0.5948 - accuracy: 0.8507 - val_loss: 0.5834 - val_accuracy: 0.8637\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85171 to 0.86370, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.63929 to 0.58345, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.5668 - accuracy: 0.8665 - val_loss: 0.5549 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86370 to 0.87514, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.58345 to 0.55495, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.5405 - accuracy: 0.8791 - val_loss: 0.5369 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87514 to 0.87514, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55495 to 0.53693, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 100s 6ms/step - loss: 0.5161 - accuracy: 0.8874 - val_loss: 0.5089 - val_accuracy: 0.8896\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87514 to 0.88962, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53693 to 0.50890, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.4928 - accuracy: 0.8948 - val_loss: 0.4836 - val_accuracy: 0.8946\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88962 to 0.89460, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50890 to 0.48363, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 113s 7ms/step - loss: 0.4726 - accuracy: 0.8978 - val_loss: 0.4642 - val_accuracy: 0.8992\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89460 to 0.89920, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48363 to 0.46418, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.4539 - accuracy: 0.9012 - val_loss: 0.4466 - val_accuracy: 0.9043\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89920 to 0.90431, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46418 to 0.44662, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.4364 - accuracy: 0.9040 - val_loss: 0.4283 - val_accuracy: 0.9065\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90431 to 0.90650, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44662 to 0.42834, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 109s 6ms/step - loss: 0.4196 - accuracy: 0.9074 - val_loss: 0.4267 - val_accuracy: 0.9002\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90650\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42834 to 0.42668, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 110s 6ms/step - loss: 0.4034 - accuracy: 0.9109 - val_loss: 0.3985 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90650 to 0.91220, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42668 to 0.39849, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 113s 7ms/step - loss: 0.3890 - accuracy: 0.9131 - val_loss: 0.3936 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91220\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39849 to 0.39359, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 111s 6ms/step - loss: 0.3754 - accuracy: 0.9149 - val_loss: 0.3771 - val_accuracy: 0.9140\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91220 to 0.91401, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39359 to 0.37711, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 108s 6ms/step - loss: 0.3611 - accuracy: 0.9177 - val_loss: 0.3636 - val_accuracy: 0.9174\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91401 to 0.91743, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37711 to 0.36359, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 110s 6ms/step - loss: 0.3488 - accuracy: 0.9195 - val_loss: 0.3486 - val_accuracy: 0.9180\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91743 to 0.91798, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36359 to 0.34864, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 110s 6ms/step - loss: 0.3368 - accuracy: 0.9215 - val_loss: 0.3382 - val_accuracy: 0.9187\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91798 to 0.91866, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34864 to 0.33821, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 111s 6ms/step - loss: 0.3257 - accuracy: 0.9236 - val_loss: 0.3309 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91866\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33821 to 0.33088, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17214/17214 [==============================] - 106s 6ms/step - loss: 0.3148 - accuracy: 0.9253 - val_loss: 0.3224 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91866 to 0.92229, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33088 to 0.32237, saving model to D:/mulocdeep/lv1_result1/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 107s 6ms/step - loss: 0.3046 - accuracy: 0.9270 - val_loss: 0.3297 - val_accuracy: 0.9195\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92229\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32237\n",
      "doing 3th fold\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1000, 25)     0           dropout_34[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1000, 25)     650         lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1000, 25)     100         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 1000, 25)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 1000, 25)     0           dropout_35[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1000, 25)     1900        lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1000, 25)     100         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 1000, 25)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1000, 25)     0           dropout_36[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1000, 25)     3150        lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1000, 25)     100         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1000, 25)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 1000, 25)     0           dropout_37[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1000, 25)     5650        lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 1000, 25)     100         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1000, 25)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1000, 25)     0           dropout_38[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1000, 25)     9400        lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 1000, 25)     100         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 1000, 25)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 1000, 25)     0           dropout_39[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1000, 25)     13150       lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1000, 25)     100         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 1000, 25)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 1000, 25)     0           dropout_40[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1000, 180)    223560      lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1000, 180)    720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 1000, 180)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 1000, 180)    0           dropout_41[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1000, 180)    390960      lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1000, 180)    720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 1000, 180)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1000, 180)    0           dropout_42[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1000, 181)    0           lambda_36[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 41, 180)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1000, 25)     0           dropout_34[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1000, 25)     650         lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1000, 25)     100         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 1000, 25)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 1000, 25)     0           dropout_35[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1000, 25)     1900        lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1000, 25)     100         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 1000, 25)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1000, 25)     0           dropout_36[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1000, 25)     3150        lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1000, 25)     100         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1000, 25)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 1000, 25)     0           dropout_37[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1000, 25)     5650        lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 1000, 25)     100         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1000, 25)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1000, 25)     0           dropout_38[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1000, 25)     9400        lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 1000, 25)     100         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 1000, 25)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 1000, 25)     0           dropout_39[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1000, 25)     13150       lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1000, 25)     100         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 1000, 25)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 1000, 25)     0           dropout_40[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1000, 180)    223560      lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1000, 180)    720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 1000, 180)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 1000, 180)    0           dropout_41[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1000, 180)    390960      lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1000, 180)    720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 1000, 180)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1000, 180)    0           dropout_42[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1000, 181)    0           lambda_36[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 41, 180)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 118s 7ms/step - loss: 0.7355 - accuracy: 0.6832 - val_loss: 0.7012 - val_accuracy: 0.8181\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81805, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70124, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 109s 6ms/step - loss: 0.6401 - accuracy: 0.8176 - val_loss: 0.6319 - val_accuracy: 0.8415\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81805 to 0.84150, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.70124 to 0.63189, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.5988 - accuracy: 0.8488 - val_loss: 0.5900 - val_accuracy: 0.8622\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84150 to 0.86215, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.63189 to 0.59002, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 107s 6ms/step - loss: 0.5694 - accuracy: 0.8646 - val_loss: 0.5514 - val_accuracy: 0.8779\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86215 to 0.87789, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.59002 to 0.55142, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.5422 - accuracy: 0.8779 - val_loss: 0.5531 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87789 to 0.88828, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.55142\n",
      "epoch 5\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 107s 6ms/step - loss: 0.5186 - accuracy: 0.8854 - val_loss: 0.4976 - val_accuracy: 0.8931\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88828 to 0.89314, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55142 to 0.49760, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 109s 6ms/step - loss: 0.4955 - accuracy: 0.8922 - val_loss: 0.4768 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89314 to 0.89396, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49760 to 0.47678, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 115s 7ms/step - loss: 0.4746 - accuracy: 0.8964 - val_loss: 0.4578 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89396 to 0.89959, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47678 to 0.45782, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 105s 6ms/step - loss: 0.4566 - accuracy: 0.9008 - val_loss: 0.4411 - val_accuracy: 0.9009\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89959 to 0.90093, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45782 to 0.44114, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 108s 6ms/step - loss: 0.4378 - accuracy: 0.9043 - val_loss: 0.4286 - val_accuracy: 0.9066\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90093 to 0.90661, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44114 to 0.42856, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.4215 - accuracy: 0.9071 - val_loss: 0.4116 - val_accuracy: 0.9089\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90661 to 0.90893, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42856 to 0.41159, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 106s 6ms/step - loss: 0.4045 - accuracy: 0.9104 - val_loss: 0.3954 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90893 to 0.91071, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41159 to 0.39540, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 104s 6ms/step - loss: 0.3897 - accuracy: 0.9125 - val_loss: 0.3796 - val_accuracy: 0.9147\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91071 to 0.91473, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39540 to 0.37963, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 102s 6ms/step - loss: 0.3752 - accuracy: 0.9154 - val_loss: 0.3670 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91473\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37963 to 0.36698, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 104s 6ms/step - loss: 0.3620 - accuracy: 0.9176 - val_loss: 0.3569 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91473\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36698 to 0.35686, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 103s 6ms/step - loss: 0.3501 - accuracy: 0.9187 - val_loss: 0.3465 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91473 to 0.91895, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35686 to 0.34647, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 109s 6ms/step - loss: 0.3376 - accuracy: 0.9214 - val_loss: 0.3372 - val_accuracy: 0.9206\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91895 to 0.92065, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34647 to 0.33720, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 104s 6ms/step - loss: 0.3262 - accuracy: 0.9233 - val_loss: 0.3253 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92065 to 0.92304, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33720 to 0.32526, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17118/17118 [==============================] - 109s 6ms/step - loss: 0.3169 - accuracy: 0.9240 - val_loss: 0.3166 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92304\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32526 to 0.31657, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 110s 6ms/step - loss: 0.3064 - accuracy: 0.9265 - val_loss: 0.3106 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92304\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31657 to 0.31062, saving model to D:/mulocdeep/lv1_result1/fold3_big_lv1_loss-weights.hdf5\n",
      "doing 4th fold\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 1000, 25)     0           dropout_45[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1000, 25)     650         lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 1000, 25)     100         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 1000, 25)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 1000, 25)     0           dropout_46[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 1000, 25)     1900        lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 1000, 25)     100         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 1000, 25)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 1000, 25)     0           dropout_47[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1000, 25)     3150        lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 1000, 25)     100         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 1000, 25)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 1000, 25)     0           dropout_48[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1000, 25)     5650        lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 1000, 25)     100         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 1000, 25)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 1000, 25)     0           dropout_49[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1000, 25)     9400        lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1000, 25)     100         conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 1000, 25)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 1000, 25)     0           dropout_50[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1000, 25)     13150       lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 1000, 25)     100         conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 1000, 25)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 1000, 25)     0           dropout_51[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1000, 180)    223560      lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 1000, 180)    720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 1000, 180)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 1000, 180)    0           dropout_52[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1000, 180)    390960      lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 1000, 180)    720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 1000, 180)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 1000, 180)    0           dropout_53[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1000, 181)    0           lambda_45[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 41, 180)      0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 1000, 25)     0           dropout_45[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1000, 25)     650         lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 1000, 25)     100         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 1000, 25)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 1000, 25)     0           dropout_46[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 1000, 25)     1900        lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 1000, 25)     100         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 1000, 25)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 1000, 25)     0           dropout_47[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1000, 25)     3150        lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 1000, 25)     100         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 1000, 25)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 1000, 25)     0           dropout_48[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1000, 25)     5650        lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 1000, 25)     100         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 1000, 25)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 1000, 25)     0           dropout_49[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1000, 25)     9400        lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1000, 25)     100         conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 1000, 25)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 1000, 25)     0           dropout_50[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1000, 25)     13150       lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 1000, 25)     100         conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 1000, 25)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 1000, 25)     0           dropout_51[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1000, 180)    223560      lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 1000, 180)    720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 1000, 180)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 1000, 180)    0           dropout_52[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1000, 180)    390960      lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 1000, 180)    720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 1000, 180)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 1000, 180)    0           dropout_53[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1000, 181)    0           lambda_45[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 41, 180)      0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 117s 7ms/step - loss: 0.7279 - accuracy: 0.6953 - val_loss: 0.6772 - val_accuracy: 0.7704\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77037, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67718, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 107s 6ms/step - loss: 0.6380 - accuracy: 0.8113 - val_loss: 0.6258 - val_accuracy: 0.8379\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.77037 to 0.83789, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.67718 to 0.62578, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 117s 7ms/step - loss: 0.5961 - accuracy: 0.8484 - val_loss: 0.5789 - val_accuracy: 0.8547\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83789 to 0.85466, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.62578 to 0.57895, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 101s 6ms/step - loss: 0.5662 - accuracy: 0.8645 - val_loss: 0.5477 - val_accuracy: 0.8725\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85466 to 0.87247, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.57895 to 0.54770, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 103s 6ms/step - loss: 0.5377 - accuracy: 0.8795 - val_loss: 0.5213 - val_accuracy: 0.8806\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87247 to 0.88057, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54770 to 0.52131, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 102s 6ms/step - loss: 0.5133 - accuracy: 0.8885 - val_loss: 0.4993 - val_accuracy: 0.8928\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88057 to 0.89279, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52131 to 0.49932, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 101s 6ms/step - loss: 0.4920 - accuracy: 0.8935 - val_loss: 0.4829 - val_accuracy: 0.8945\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89279 to 0.89448, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49932 to 0.48293, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 103s 6ms/step - loss: 0.4719 - accuracy: 0.8980 - val_loss: 0.4634 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.89448\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48293 to 0.46338, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 102s 6ms/step - loss: 0.4541 - accuracy: 0.9011 - val_loss: 0.4428 - val_accuracy: 0.8999\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89448 to 0.89992, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46338 to 0.44280, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 105s 6ms/step - loss: 0.4367 - accuracy: 0.9048 - val_loss: 0.4271 - val_accuracy: 0.9040\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89992 to 0.90399, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44280 to 0.42707, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 103s 6ms/step - loss: 0.4201 - accuracy: 0.9079 - val_loss: 0.4109 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90399 to 0.90689, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42707 to 0.41087, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 107s 6ms/step - loss: 0.4047 - accuracy: 0.9102 - val_loss: 0.4002 - val_accuracy: 0.9120\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90689 to 0.91197, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41087 to 0.40024, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 106s 6ms/step - loss: 0.3892 - accuracy: 0.9134 - val_loss: 0.3824 - val_accuracy: 0.9109\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91197\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40024 to 0.38245, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 102s 6ms/step - loss: 0.3745 - accuracy: 0.9160 - val_loss: 0.3843 - val_accuracy: 0.9109\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91197\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38245\n",
      "epoch 14\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 102s 6ms/step - loss: 0.3611 - accuracy: 0.9184 - val_loss: 0.3657 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91197 to 0.91395, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38245 to 0.36567, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 107s 6ms/step - loss: 0.3487 - accuracy: 0.9203 - val_loss: 0.3474 - val_accuracy: 0.9176\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91395 to 0.91757, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36567 to 0.34738, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 103s 6ms/step - loss: 0.3374 - accuracy: 0.9216 - val_loss: 0.3400 - val_accuracy: 0.9186\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91757 to 0.91858, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34738 to 0.34004, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 101s 6ms/step - loss: 0.3255 - accuracy: 0.9243 - val_loss: 0.3295 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91858\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34004 to 0.32950, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 104s 6ms/step - loss: 0.3153 - accuracy: 0.9258 - val_loss: 0.3187 - val_accuracy: 0.9225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91858 to 0.92245, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32950 to 0.31866, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 102s 6ms/step - loss: 0.3039 - accuracy: 0.9287 - val_loss: 0.3116 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92245 to 0.92277, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31866 to 0.31164, saving model to D:/mulocdeep/lv1_result1/fold4_big_lv1_loss-weights.hdf5\n",
      "doing 5th fold\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 1000, 25)     0           dropout_56[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1000, 25)     650         lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 1000, 25)     100         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 1000, 25)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 1000, 25)     0           dropout_57[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1000, 25)     1900        lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 1000, 25)     100         conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 1000, 25)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 1000, 25)     0           dropout_58[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1000, 25)     3150        lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1000, 25)     100         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 1000, 25)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 1000, 25)     0           dropout_59[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1000, 25)     5650        lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1000, 25)     100         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 1000, 25)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 1000, 25)     0           dropout_60[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1000, 25)     9400        lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 1000, 25)     100         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 1000, 25)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 1000, 25)     0           dropout_61[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 1000, 25)     13150       lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1000, 25)     100         conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 1000, 25)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 1000, 25)     0           dropout_62[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1000, 180)    223560      lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 1000, 180)    720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 1000, 180)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 1000, 180)    0           dropout_63[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1000, 180)    390960      lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 1000, 180)    720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 1000, 180)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 1000, 180)    0           dropout_64[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1000, 181)    0           lambda_54[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 41, 180)      0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 1000, 25)     0           dropout_56[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1000, 25)     650         lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 1000, 25)     100         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 1000, 25)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 1000, 25)     0           dropout_57[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1000, 25)     1900        lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 1000, 25)     100         conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 1000, 25)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 1000, 25)     0           dropout_58[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1000, 25)     3150        lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1000, 25)     100         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 1000, 25)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 1000, 25)     0           dropout_59[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1000, 25)     5650        lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1000, 25)     100         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 1000, 25)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 1000, 25)     0           dropout_60[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1000, 25)     9400        lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 1000, 25)     100         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 1000, 25)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 1000, 25)     0           dropout_61[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 1000, 25)     13150       lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1000, 25)     100         conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 1000, 25)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 1000, 25)     0           dropout_62[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1000, 180)    223560      lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 1000, 180)    720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 1000, 180)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 1000, 180)    0           dropout_63[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1000, 180)    390960      lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 1000, 180)    720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 1000, 180)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 1000, 180)    0           dropout_64[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1000, 181)    0           lambda_54[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 41, 180)      0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 117s 7ms/step - loss: 0.7345 - accuracy: 0.6760 - val_loss: 0.6870 - val_accuracy: 0.8061\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80606, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68703, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 108s 6ms/step - loss: 0.6403 - accuracy: 0.8178 - val_loss: 0.6377 - val_accuracy: 0.8364\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80606 to 0.83642, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.68703 to 0.63765, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 110s 6ms/step - loss: 0.5963 - accuracy: 0.8519 - val_loss: 0.5861 - val_accuracy: 0.8545\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83642 to 0.85448, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.63765 to 0.58609, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 108s 6ms/step - loss: 0.5672 - accuracy: 0.8667 - val_loss: 0.5460 - val_accuracy: 0.8696\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85448 to 0.86960, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.58609 to 0.54595, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 111s 6ms/step - loss: 0.5408 - accuracy: 0.8795 - val_loss: 0.5254 - val_accuracy: 0.8836\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86960 to 0.88360, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54595 to 0.52543, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 110s 6ms/step - loss: 0.5161 - accuracy: 0.8869 - val_loss: 0.5028 - val_accuracy: 0.8834\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.88360\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52543 to 0.50277, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 111s 6ms/step - loss: 0.4927 - accuracy: 0.8935 - val_loss: 0.4858 - val_accuracy: 0.8905\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88360 to 0.89048, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50277 to 0.48583, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 112s 6ms/step - loss: 0.4718 - accuracy: 0.8987 - val_loss: 0.4623 - val_accuracy: 0.8947\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89048 to 0.89466, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48583 to 0.46234, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 118s 7ms/step - loss: 0.4536 - accuracy: 0.9025 - val_loss: 0.4467 - val_accuracy: 0.8990\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89466 to 0.89898, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46234 to 0.44671, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 107s 6ms/step - loss: 0.4361 - accuracy: 0.9053 - val_loss: 0.4299 - val_accuracy: 0.9074\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89898 to 0.90739, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44671 to 0.42990, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 105s 6ms/step - loss: 0.4174 - accuracy: 0.9099 - val_loss: 0.4093 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90739 to 0.90773, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42990 to 0.40933, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 107s 6ms/step - loss: 0.4022 - accuracy: 0.9116 - val_loss: 0.3944 - val_accuracy: 0.9105\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90773 to 0.91050, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40933 to 0.39440, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 107s 6ms/step - loss: 0.3869 - accuracy: 0.9140 - val_loss: 0.3811 - val_accuracy: 0.9129\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91050 to 0.91289, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39440 to 0.38110, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 105s 6ms/step - loss: 0.3726 - accuracy: 0.9158 - val_loss: 0.3689 - val_accuracy: 0.9100\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91289\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38110 to 0.36890, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 104s 6ms/step - loss: 0.3595 - accuracy: 0.9181 - val_loss: 0.3580 - val_accuracy: 0.9158\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91289 to 0.91580, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36890 to 0.35800, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 106s 6ms/step - loss: 0.3455 - accuracy: 0.9209 - val_loss: 0.3464 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91580 to 0.91721, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35800 to 0.34639, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 105s 6ms/step - loss: 0.3340 - accuracy: 0.9231 - val_loss: 0.3351 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91721 to 0.91990, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34639 to 0.33508, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 104s 6ms/step - loss: 0.3224 - accuracy: 0.9249 - val_loss: 0.3280 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91990\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33508 to 0.32800, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17241/17241 [==============================] - 104s 6ms/step - loss: 0.3115 - accuracy: 0.9269 - val_loss: 0.3252 - val_accuracy: 0.9176\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91990\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32800 to 0.32524, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 106s 6ms/step - loss: 0.3024 - accuracy: 0.9281 - val_loss: 0.3179 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91990\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32524 to 0.31794, saving model to D:/mulocdeep/lv1_result1/fold5_big_lv1_loss-weights.hdf5\n",
      "doing 6th fold\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 1000, 25)     0           dropout_67[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1000, 25)     650         lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1000, 25)     100         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 1000, 25)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 1000, 25)     0           dropout_68[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1000, 25)     1900        lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1000, 25)     100         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 1000, 25)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 1000, 25)     0           dropout_69[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1000, 25)     3150        lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 1000, 25)     100         conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 1000, 25)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 1000, 25)     0           dropout_70[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1000, 25)     5650        lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 1000, 25)     100         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 1000, 25)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 1000, 25)     0           dropout_71[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 1000, 25)     9400        lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 1000, 25)     100         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 1000, 25)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 1000, 25)     0           dropout_72[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1000, 25)     13150       lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1000, 25)     100         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 1000, 25)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 1000, 25)     0           dropout_73[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1000, 180)    223560      lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 1000, 180)    720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 1000, 180)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 1000, 180)    0           dropout_74[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1000, 180)    390960      lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1000, 180)    720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 1000, 180)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 1000, 180)    0           dropout_75[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 181)    0           lambda_63[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 41, 180)      0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 1000, 25)     0           dropout_67[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1000, 25)     650         lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1000, 25)     100         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 1000, 25)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 1000, 25)     0           dropout_68[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1000, 25)     1900        lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1000, 25)     100         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 1000, 25)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 1000, 25)     0           dropout_69[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1000, 25)     3150        lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 1000, 25)     100         conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 1000, 25)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 1000, 25)     0           dropout_70[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1000, 25)     5650        lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 1000, 25)     100         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 1000, 25)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 1000, 25)     0           dropout_71[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 1000, 25)     9400        lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 1000, 25)     100         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 1000, 25)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 1000, 25)     0           dropout_72[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1000, 25)     13150       lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1000, 25)     100         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 1000, 25)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 1000, 25)     0           dropout_73[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1000, 180)    223560      lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 1000, 180)    720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 1000, 180)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 1000, 180)    0           dropout_74[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1000, 180)    390960      lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 1000, 180)    720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 1000, 180)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 1000, 180)    0           dropout_75[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 181)    0           lambda_63[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 41, 180)      0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 123s 7ms/step - loss: 0.7587 - accuracy: 0.6672 - val_loss: 0.6673 - val_accuracy: 0.7822\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78220, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66728, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 112s 7ms/step - loss: 0.6483 - accuracy: 0.8034 - val_loss: 0.6464 - val_accuracy: 0.8220\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.78220 to 0.82203, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66728 to 0.64639, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 110s 6ms/step - loss: 0.6053 - accuracy: 0.8418 - val_loss: 0.6065 - val_accuracy: 0.8617\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82203 to 0.86165, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.64639 to 0.60646, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 110s 6ms/step - loss: 0.5711 - accuracy: 0.8647 - val_loss: 0.5570 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86165 to 0.87055, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.60646 to 0.55705, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 111s 6ms/step - loss: 0.5433 - accuracy: 0.8763 - val_loss: 0.5203 - val_accuracy: 0.8881\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87055 to 0.88811, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55705 to 0.52028, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 110s 6ms/step - loss: 0.5188 - accuracy: 0.8851 - val_loss: 0.5006 - val_accuracy: 0.8905\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88811 to 0.89054, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52028 to 0.50058, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 111s 6ms/step - loss: 0.4966 - accuracy: 0.8919 - val_loss: 0.4739 - val_accuracy: 0.8954\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89054 to 0.89541, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50058 to 0.47392, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 111s 6ms/step - loss: 0.4757 - accuracy: 0.8971 - val_loss: 0.4560 - val_accuracy: 0.9063\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89541 to 0.90634, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47392 to 0.45602, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 111s 6ms/step - loss: 0.4570 - accuracy: 0.9011 - val_loss: 0.4384 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90634\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45602 to 0.43836, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 111s 6ms/step - loss: 0.4386 - accuracy: 0.9053 - val_loss: 0.4190 - val_accuracy: 0.9092\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90634 to 0.90922, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43836 to 0.41905, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 110s 6ms/step - loss: 0.4220 - accuracy: 0.9084 - val_loss: 0.4077 - val_accuracy: 0.9099\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90922 to 0.90994, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41905 to 0.40771, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 111s 6ms/step - loss: 0.4065 - accuracy: 0.9109 - val_loss: 0.3898 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90994 to 0.91548, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40771 to 0.38978, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 122s 7ms/step - loss: 0.3905 - accuracy: 0.9139 - val_loss: 0.3806 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91548 to 0.91656, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38978 to 0.38061, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 112s 7ms/step - loss: 0.3774 - accuracy: 0.9155 - val_loss: 0.3671 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91656 to 0.91891, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38061 to 0.36711, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 110s 6ms/step - loss: 0.3637 - accuracy: 0.9176 - val_loss: 0.3613 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91891\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36711 to 0.36133, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 113s 7ms/step - loss: 0.3518 - accuracy: 0.9194 - val_loss: 0.3437 - val_accuracy: 0.9197\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91891 to 0.91967, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36133 to 0.34371, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 118s 7ms/step - loss: 0.3388 - accuracy: 0.9226 - val_loss: 0.3336 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91967 to 0.92326, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34371 to 0.33357, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 119s 7ms/step - loss: 0.3280 - accuracy: 0.9236 - val_loss: 0.3252 - val_accuracy: 0.9248\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92326 to 0.92478, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33357 to 0.32521, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 116s 7ms/step - loss: 0.3165 - accuracy: 0.9266 - val_loss: 0.3201 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92478\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32521 to 0.32011, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 120s 7ms/step - loss: 0.3072 - accuracy: 0.9271 - val_loss: 0.3096 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92478 to 0.92518, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32011 to 0.30959, saving model to D:/mulocdeep/lv1_result1/fold6_big_lv1_loss-weights.hdf5\n",
      "doing 7th fold\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 1000, 25)     0           dropout_78[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1000, 25)     650         lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 1000, 25)     100         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 1000, 25)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 1000, 25)     0           dropout_79[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1000, 25)     1900        lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 1000, 25)     100         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 1000, 25)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 1000, 25)     0           dropout_80[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1000, 25)     3150        lambda_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1000, 25)     100         conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 1000, 25)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 1000, 25)     0           dropout_81[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 1000, 25)     5650        lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1000, 25)     100         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 1000, 25)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 1000, 25)     0           dropout_82[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1000, 25)     9400        lambda_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 1000, 25)     100         conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 1000, 25)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 1000, 25)     0           dropout_83[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1000, 25)     13150       lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 1000, 25)     100         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 1000, 25)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 1000, 25)     0           dropout_84[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1000, 180)    223560      lambda_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 1000, 180)    720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 1000, 180)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 1000, 180)    0           dropout_85[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1000, 180)    390960      lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 1000, 180)    720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 1000, 180)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 1000, 180)    0           dropout_86[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1000, 181)    0           lambda_72[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 41, 180)      0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 1000, 25)     0           dropout_78[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 1000, 25)     650         lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 1000, 25)     100         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 1000, 25)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 1000, 25)     0           dropout_79[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 1000, 25)     1900        lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 1000, 25)     100         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 1000, 25)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 1000, 25)     0           dropout_80[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 1000, 25)     3150        lambda_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1000, 25)     100         conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 1000, 25)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 1000, 25)     0           dropout_81[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 1000, 25)     5650        lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1000, 25)     100         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 1000, 25)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 1000, 25)     0           dropout_82[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1000, 25)     9400        lambda_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 1000, 25)     100         conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 1000, 25)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 1000, 25)     0           dropout_83[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1000, 25)     13150       lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 1000, 25)     100         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 1000, 25)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 1000, 25)     0           dropout_84[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1000, 180)    223560      lambda_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 1000, 180)    720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 1000, 180)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 1000, 180)    0           dropout_85[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1000, 180)    390960      lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 1000, 180)    720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 1000, 180)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 1000, 180)    0           dropout_86[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1000, 181)    0           lambda_72[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 41, 180)      0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,323,213\n",
      "Trainable params: 1,321,831\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 132s 8ms/step - loss: 0.7329 - accuracy: 0.7082 - val_loss: 0.7423 - val_accuracy: 0.7900\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79000, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.74230, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 118s 7ms/step - loss: 0.6367 - accuracy: 0.8164 - val_loss: 0.6123 - val_accuracy: 0.8432\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.79000 to 0.84320, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.74230 to 0.61228, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 117s 7ms/step - loss: 0.5938 - accuracy: 0.8503 - val_loss: 0.5846 - val_accuracy: 0.8598\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84320 to 0.85980, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.61228 to 0.58461, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 116s 7ms/step - loss: 0.5640 - accuracy: 0.8654 - val_loss: 0.5355 - val_accuracy: 0.8801\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85980 to 0.88008, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.58461 to 0.53550, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 117s 7ms/step - loss: 0.5372 - accuracy: 0.8797 - val_loss: 0.5122 - val_accuracy: 0.8869\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88008 to 0.88692, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.53550 to 0.51221, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 116s 7ms/step - loss: 0.5134 - accuracy: 0.8873 - val_loss: 0.4958 - val_accuracy: 0.8933\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88692 to 0.89328, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51221 to 0.49577, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 117s 7ms/step - loss: 0.4916 - accuracy: 0.8924 - val_loss: 0.4770 - val_accuracy: 0.8934\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89328 to 0.89336, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49577 to 0.47696, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 116s 7ms/step - loss: 0.4728 - accuracy: 0.8969 - val_loss: 0.4487 - val_accuracy: 0.9053\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89336 to 0.90526, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47696 to 0.44873, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 118s 7ms/step - loss: 0.4540 - accuracy: 0.9020 - val_loss: 0.4501 - val_accuracy: 0.9040\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90526\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.44873\n",
      "epoch 9\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 117s 7ms/step - loss: 0.4370 - accuracy: 0.9047 - val_loss: 0.4271 - val_accuracy: 0.9079\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90526 to 0.90794, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44873 to 0.42709, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 117s 7ms/step - loss: 0.4200 - accuracy: 0.9077 - val_loss: 0.4115 - val_accuracy: 0.9079\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90794\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42709 to 0.41153, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 129s 8ms/step - loss: 0.4043 - accuracy: 0.9110 - val_loss: 0.3910 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90794 to 0.91549, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41153 to 0.39097, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 122s 7ms/step - loss: 0.3895 - accuracy: 0.9136 - val_loss: 0.3903 - val_accuracy: 0.9138\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91549\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39097 to 0.39031, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 119s 7ms/step - loss: 0.3747 - accuracy: 0.9154 - val_loss: 0.3793 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91549\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39031 to 0.37930, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 115s 7ms/step - loss: 0.3622 - accuracy: 0.9176 - val_loss: 0.3605 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91549 to 0.91921, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37930 to 0.36051, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 115s 7ms/step - loss: 0.3486 - accuracy: 0.9202 - val_loss: 0.3450 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91921 to 0.92281, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36051 to 0.34502, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 117s 7ms/step - loss: 0.3361 - accuracy: 0.9223 - val_loss: 0.3376 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92281 to 0.92316, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34502 to 0.33761, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 115s 7ms/step - loss: 0.3247 - accuracy: 0.9243 - val_loss: 0.3279 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92316\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33761 to 0.32793, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 115s 7ms/step - loss: 0.3141 - accuracy: 0.9260 - val_loss: 0.3239 - val_accuracy: 0.9226\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92316\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32793 to 0.32389, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 115s 7ms/step - loss: 0.3055 - accuracy: 0.9270 - val_loss: 0.3119 - val_accuracy: 0.9235\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92316 to 0.92352, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32389 to 0.31192, saving model to D:/mulocdeep/lv1_result1/fold7_big_lv1_loss-weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-accused",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
