{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "import math\n",
    "from itertools import product\n",
    "import argparse\n",
    "import sys\n",
    "from utils_3gruCS import *\n",
    "import calendar\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "damaged-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eachseq(seq,pssmfile,mask_seq,new_pssms):\n",
    "    if os.path.exists(pssmfile):  #如果pssm文件存在\n",
    "        print(\"found \" + pssmfile + \"\\n\")  #输出找到pssm文件+换行\n",
    "        pssm = readPSSM(pssmfile)  #读取pssm文件\n",
    "    else:  #否则\n",
    "        print(\"using Blosum62\\n\")  #输出使用Blosum62+换行\n",
    "        #pssm = convertSampleToBlosum62(seq)  #把Blosum62矩阵当作pssm用\n",
    "        pssm = convertSampleToCBOW(seq)\n",
    "    pssm = pssm.astype(float)  #对pssm的数据类型转换为浮点型\n",
    "    PhyChem = convertSampleToPhysicsVector_pca(seq)  #将样本转化为物理向量\n",
    "    pssm = np.concatenate((PhyChem, pssm), axis=1)  #物化指标和pssm对应行进行数组拼接\n",
    "    seql = len(seq)   #序列长度  \n",
    "    if seql <= 1000:  #如果序列长度小于等于1000\n",
    "        padnum = 1000 - seql  #pad大小为1000-序列长度\n",
    "        padmatrix = np.zeros([padnum, 25])  #pad矩阵为行数为padnum，列数为25的全0矩阵，即用0填充不足的地方\n",
    "        pssm = np.concatenate((pssm, padmatrix), axis=0)  #物化指标和pssm进行数组拼接 \n",
    "        new_pssms.append(pssm)  #新的pssm空列表中添加pssm矩阵\n",
    "        mask_seq.append(gen_mask_mat(seql, padnum))  #mask序列空列表添加gen_mask矩阵，序列长度为行数，padnum为列数？？？\n",
    "    else:  #如果序列长度大于1000\n",
    "        pssm = np.concatenate((pssm[0:500, :], pssm[seql - 500:seql, :]), axis=0)  #pssm矩阵为前500行和后500行矩阵的拼接\n",
    "        new_pssms.append(pssm)  #新的pssm空列表中添加pssm矩阵\n",
    "        mask_seq.append(gen_mask_mat(1000, 0))  #mask序列空列表添加1000行0列的？？？gen_mask矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metric-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpad(seqfile, labelfile, pssmdir=\"\", npzfile = \"\"): #定义endpad(序列文件，标签文件，pssm路径，npz文件)\n",
    "    if not os.path.exists(npzfile):  #如果npz文件不存在，建立新的pssm空列表，标签空列表，mask序列空列表，id空列表\n",
    "        new_pssms = []\n",
    "        labels = []\n",
    "        mask_seq = []\n",
    "        ids=[]\n",
    "        seqs=[]\n",
    "        f = open(seqfile, \"r\")  #f为打开序列文件\n",
    "        f2 = open(labelfile, \"r\")  #f2为打开标签文件\n",
    "        line = f.readline()  #读取序列文件的第一行\n",
    "        while line != '':\n",
    "            pssmfile = pssmdir + line[1:].strip() + \"_pssm.txt\"  #pssm文件名=pssm地址+id名+_pssm.txt\n",
    "            if line[0] == '>':  #如果该行第一个字符为>\n",
    "                id = line.strip()[1:]  #id为去掉>的字符\n",
    "                ids.append(id)   #在id空列表中添加id\n",
    "            label = f2.readline().strip()  #标签为f2（标签文件）中去掉首尾空格的内容\n",
    "            labels.append(label)  #在标签空列表中添加标签\n",
    "            seq = f.readline().strip()  #第一次seq为第2行的内容，实际seq为>行的下一行\n",
    "            #seql = len(seq)   #序列长度  \n",
    "            process_eachseq(seq,pssmfile,mask_seq,new_pssms)\n",
    "            line = f.readline()  #继续读取下一行，即>行\n",
    "        x = np.array(new_pssms)  #把new_pssms列表变为数组，赋给x\n",
    "        y = [convertlabels_to_categorical(i) for i in labels]  #把标签列表转化为类别(i)\n",
    "        y = np.array(y)  #再把类别转化为数组\n",
    "        mask = np.array(mask_seq)  #把mask_seq（标注的序列？）转化为数组\n",
    "        np.savez(npzfile, x=x, y=y, mask=mask, ids=ids)  #保存多个数组到同一个文件中,保存格式是.npz\n",
    "        return [x, y, mask,ids]  #返回pssm矩阵，类别，标注序列，名字id\n",
    "    else:  #如果上述都存在，直接转化为数组\n",
    "        mask = np.load(npzfile)['mask']\n",
    "        x = np.load(npzfile)['x']\n",
    "        y = np.load(npzfile)['y']\n",
    "        ids=np.load(npzfile)['ids']\n",
    "        return [x, y, mask,ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "warming-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MULocDeep(lv1_dir,lv2_dir,pssm_dir,output_dir,foldnum):\n",
    "    # get small data\n",
    "    [train_x, train_y, train_mask, train_ids] = endpad(\n",
    "        lv2_dir+\"lv2_train_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv2_dir+\"lv2_train_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv2_train_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    [val_x, val_y, val_mask,val_ids] = endpad(\n",
    "        lv2_dir+\"lv2_val_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv2_dir+\"lv2_val_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv2_val_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "\n",
    "    # get big data 训练10分类的多分类\n",
    "    [train_x_big, train_y_big, train_mask_big, train_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_train_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv1_train_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    [val_x_big, val_y_big, val_mask_big, val_ids_big] = endpad(\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_seq\",\n",
    "        lv1_dir + \"lv1_val_fold\" + str(foldnum) + \"_lab\",\n",
    "        pssm_dir,\n",
    "        \"D:/mulocdeep/mul_data/lv1_val_fold\" + str(foldnum) + \"_seq.npz\")\n",
    "\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model_big, model_small = singlemodel(train_x)  #模型为singlemodel\n",
    "\n",
    "    filepath_acc_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_acc_small_lv2 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_small_lv2_acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_loss_big_lv1 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_big_lv1_loss-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "    filepath_loss_small_lv2 = output_dir+\"fold\" + str(\n",
    "        foldnum) + \"_small_lv2_loss-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "    checkpoint_acc_big_lev1 = ModelCheckpoint(filepath_acc_big_lv1, monitor='val_accuracy', save_best_only=True,\n",
    "                                          mode='max',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "\n",
    "    checkpoint_acc_small_lev2 = ModelCheckpoint(filepath_acc_small_lv2, monitor='val_lev2_accuracy', save_best_only=True,\n",
    "                                          mode='max',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    checkpoint_loss_big_lev1 = ModelCheckpoint(filepath_loss_big_lv1, monitor='val_loss', save_best_only=True,\n",
    "                                          mode='min',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    checkpoint_loss_small_lev2 = ModelCheckpoint(filepath_loss_small_lv2, monitor='val_lev2_loss', save_best_only=True,\n",
    "                                          mode='min',\n",
    "                                          save_weights_only=True, verbose=1)\n",
    "    \n",
    "    \n",
    "    for i in range(80):\n",
    "        # train small model\n",
    "        print(\"epoch \"+str(i)+\"\\n\")\n",
    "        '''fitHistory_batch_small = model_small.fit([train_x, train_mask.reshape(-1, 1000, 1)],\n",
    "                                                 [train_y,getTrue4out1(train_y)],\n",
    "                                                 batch_size=batch_size, epochs=1,\n",
    "                                                 validation_data=(\n",
    "                                                 [val_x, val_mask.reshape(-1, 1000, 1)], [val_y,getTrue4out1(val_y)]),\n",
    "                                                 callbacks=[checkpoint_acc_small_lev2,checkpoint_loss_small_lev2],verbose=1)'''\n",
    "        \n",
    "        # train big model  \n",
    "        fitHistory_batch_big = model_big.fit([train_x_big, train_mask_big.reshape(-1, 1000, 1)],\n",
    "                                             [getTrue4out1(train_y_big)],  #为何大模型没有train_y_big\n",
    "                                             batch_size=batch_size, epochs=1,  #等于1？？\n",
    "                                             validation_data=(\n",
    "                                             [val_x_big, val_mask_big.reshape(-1, 1000, 1)], [getTrue4out1(val_y_big)]),  #也没有val_y_big\n",
    "                                             callbacks=[checkpoint_acc_big_lev1,checkpoint_loss_big_lev1], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alert-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_var(input_var,pssm_dir,output_dir,foldnum):\n",
    "    # get small data\n",
    "    [train_x,train_y,train_mask,train_ids]=endpad(input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_seq\",\n",
    "                                        input_var+\"deeploc_40nr_train_fold\"+str(foldnum)+\"_label\",\n",
    "                                        pssm_dir,\n",
    "                                        \"D:/deeploc/deeploc_40nr_8folds/train_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    [val_x,val_y,val_mask,val_ids]=endpad(input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_seq\",\n",
    "                                  input_var+\"deeploc_40nr_val_fold\"+str(foldnum)+\"_label\",\n",
    "                                  pssm_dir,\n",
    "                                  \"D:/deeploc/deeploc_40nr_8folds/val_fold\"+str(foldnum)+\"_seq.npz\")\n",
    "    batch_size = 128\n",
    "    print(\"doing \" + str(foldnum) + \"th fold\")\n",
    "    model = var_model(train_x)   #这里的模型是var_model\n",
    "\n",
    "    filepath_acc = output_dir+\"fold\" + str(foldnum) + \"acc-weights.hdf5\"  # -improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "    checkpoint_acc = ModelCheckpoint(filepath_acc, monitor='val_accuracy', save_best_only=True, mode='max',\n",
    "                                 save_weights_only=True, verbose=1)\n",
    "    fitHistory_batch = model.fit([train_x,train_mask.reshape(-1,1000,1)],getTrue4out1(train_y),\n",
    "                                 batch_size=batch_size, epochs=20,\n",
    "                                 validation_data=([val_x,val_mask.reshape(-1,1000,1)], getTrue4out1(val_y)),\n",
    "                                 callbacks=[checkpoint_acc],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spiritual-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''我们常常可以把argparse的使用简化成下面四个步骤\n",
    "       1：import argparse\n",
    "       2：parser = argparse.ArgumentParser()\n",
    "       3：parser.add_argument()\n",
    "       4：parser.parse_args()\n",
    "       上面四个步骤解释如下：首先导入该模块；然后创建一个解析对象；然后向该对象中添加你要关注的命令行参数和选项，\n",
    "       每一个add_argument方法对应一个你要关注的参数或选项；最后调用parse_args()方法进行解析；解析成功之后即可使用'''\n",
    "    \n",
    "def main():\n",
    "    #加default\n",
    "    # description= 这个参数简要描述这个程度做什么以及怎么做\n",
    "    parser=argparse.ArgumentParser(\n",
    "        description='MULocDeep: interpretable protein localization classifier at sub-cellular and sub-organellar levels')\n",
    "    #MULocDeep_model  UniLoc-train-20nr\n",
    "    #--lv1_input_dir/--lv2_input_dir 亚细胞训练数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--lv1_input_dir', dest='lv1_dir', type=str, \n",
    "                        default=\"D:/mulocdeep/mul_data\",\n",
    "                        help='sub-cellular training data, contains 8 folds protein sequences and labels', required=False)\n",
    "    parser.add_argument('--lv2_input_dir', dest='lv2_dir', type=str,\n",
    "                       default=\"D:/mulocdeep/mul_data\",\n",
    "                       help='sub-cellular training data, contains 8 folds protein sequences and labels', required=False)\n",
    "    #--MULocDeep_model 添加它来训练MULocDeep模型，否则训练一个var模型\n",
    "    parser.add_argument('--MULocDeep_model', dest='modeltype', action='store_false',  #触发，store_true会触发DeepLoc\n",
    "                        #如果是store_false,则默认值是True，如果是store_true,则默认值是False  \n",
    "                        help='Add this to train the MULocDeep model, otherwise train a variant model', required=False)\n",
    "    #--model_output 受过训练的模型存储的目录的名称  需自己添加\n",
    "    parser.add_argument('--model_output', dest='outputdir', type=str, \n",
    "                       default=\"D:/mulocdeep/lv1_result22\",\n",
    "                       help='the name of the directory where the trained model stores', required=False)  #由True改成False\n",
    "    \n",
    "    parser.add_argument('-existPSSM', dest='existPSSM', type=str,\n",
    "                        default=\"D:/mulocdeep/mulocdeep_pssm_empty\",\n",
    "                        help='the name of the existing PSSM directory if there is one.', required=False)\n",
    "    \n",
    "    #var_model  deeploc_40nr_8folds\n",
    "    #--input_dir 训练var模型的数据，包含8折蛋白质序列和标记  需自己添加\n",
    "    parser.add_argument('--input_var', dest='var_dir', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_40nr_8folds\",\n",
    "                        help='data for traing the variant model, contains 8 folds protein sequences and labels', required=False)\n",
    "    #改true  并且还需要加一个model_ouput  一个是deeploc  一个是MULocDeep\n",
    "    parser.add_argument('--var_model_output', dest='var_outputdir', type=str, help='the name of the directory where the trained model stores', \n",
    "                        default=\"D:/deeploc/var_model_result1\",\n",
    "                        required=False)  #由True改成False\n",
    "    parser.add_argument('-var_existPSSM', dest='var_existPSSM', type=str,\n",
    "                        default=\"D:/deeploc/deeploc_pssm\",\n",
    "                        help='the name of the existing PSSM directory if there is one.', required=False)\n",
    "    parser.set_defaults(feature=True)\n",
    "    #args = parser.parse_args()   #改\n",
    "    args = parser.parse_known_args()[0]   #jupyter下运行解析需要此代码\n",
    "    model_type=args.modeltype\n",
    "    input_lv1=args.lv1_dir\n",
    "    input_lv2 = args.lv2_dir\n",
    "    outputdir=args.outputdir\n",
    "    existPSSM = args.existPSSM\n",
    "    input_var=args.var_dir\n",
    "    var_outputdir=args.var_outputdir\n",
    "    var_existPSSM = args.var_existPSSM\n",
    "\n",
    "    if model_type==True:\n",
    "        if not input_lv1[len(input_lv1) - 1] == \"/\":\n",
    "            input_lv1 = input_lv1 + \"/\"\n",
    "        if not input_lv2[len(input_lv2) - 1] == \"/\":\n",
    "            input_lv2 = input_lv2 + \"/\"\n",
    "        if not outputdir[len(outputdir) - 1] == \"/\":\n",
    "            outputdir = outputdir + \"/\"\n",
    "        if not os.path.exists(outputdir):\n",
    "            os.mkdir(outputdir)\n",
    "        if existPSSM != \"\":\n",
    "            if not existPSSM[len(existPSSM) - 1] == \"/\":\n",
    "                existPSSM = existPSSM + \"/\"\n",
    "        if ((existPSSM == \"\") or (not os.path.exists(existPSSM))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            pssmdir = outputdir + str(ts) + \"_pssm/\"\n",
    "            if not os.path.exists(pssmdir):\n",
    "                os.makedirs(pssmdir)\n",
    "            process_input_train(input_lv1 + \"lv1_train.txt\", pssmdir)\n",
    "            process_input_train(input_lv2 + \"lv2_train.txt\", pssmdir)\n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, input_lv2, pssmdir, outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_MULocDeep(input_lv1, input_lv2, existPSSM, outputdir, foldnum)\n",
    "    elif model_type==False:\n",
    "        if not input_var[len(input_var) - 1] == \"/\":\n",
    "            input_var = input_var + \"/\"\n",
    "        if not var_outputdir[len(var_outputdir) - 1] == \"/\":\n",
    "            var_outputdir = var_outputdir + \"/\"\n",
    "        if not os.path.exists(var_outputdir):\n",
    "            os.mkdir(var_outputdir)\n",
    "        if existPSSM != \"\":\n",
    "            if not var_existPSSM[len(var_existPSSM) - 1] == \"/\":\n",
    "                var_existPSSM = var_existPSSM + \"/\"\n",
    "        if ((var_existPSSM == \"\") or (not os.path.exists(var_existPSSM))):\n",
    "            ts = calendar.timegm(time.gmtime())\n",
    "            pssmdir = var_outputdir + str(ts) + \"_pssm/\"\n",
    "            if not os.path.exists(pssmdir):\n",
    "                os.makedirs(pssmdir)\n",
    "            process_input_train(input_var + \"processed_deeploc_train_S_seq\", pssmdir)\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, pssmdir, var_outputdir, foldnum)\n",
    "        else:\n",
    "            for foldnum in range(8):\n",
    "                train_var(input_var, var_existPSSM, var_outputdir, foldnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "associate-hearts",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing 0th fold\n",
      "WARNING:tensorflow:From C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1000, 25)     0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 180)    223560      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000, 180)    720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 180)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1000, 180)    0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 180)    390960      lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000, 180)    720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 180)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1000, 180)    0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 180)    390960      lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1000, 180)    720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000, 180)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1000, 180)    0           dropout_4[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 181)    0           lambda_4[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 41, 180)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1000, 25)     0           dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 180)    223560      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000, 180)    720         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 180)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1000, 180)    0           dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 180)    390960      lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000, 180)    720         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 180)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1000, 180)    0           dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 180)    390960      lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1000, 180)    720         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000, 180)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1000, 180)    0           dropout_4[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 181)    0           lambda_4[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 41, 180), (N 81549       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 41, 180)      720         attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 41, 180)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7380)         0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7380)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80)           590480      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 8, 1)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 10, 8, 1)     4           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 8, 1)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vipuser\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 177s 10ms/step - loss: 0.7348 - accuracy: 0.6884 - val_loss: 0.6781 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80000, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67809, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 175s 10ms/step - loss: 0.6267 - accuracy: 0.8314 - val_loss: 0.5998 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80000 to 0.84965, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.67809 to 0.59978, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 164s 10ms/step - loss: 0.5779 - accuracy: 0.8639 - val_loss: 0.5582 - val_accuracy: 0.8724\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84965 to 0.87243, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.59978 to 0.55816, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 163s 9ms/step - loss: 0.5461 - accuracy: 0.8842 - val_loss: 0.5195 - val_accuracy: 0.8944\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87243 to 0.89440, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55816 to 0.51952, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 160s 9ms/step - loss: 0.5190 - accuracy: 0.8950 - val_loss: 0.5041 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89440 to 0.90601, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51952 to 0.50411, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 160s 9ms/step - loss: 0.4938 - accuracy: 0.9047 - val_loss: 0.4845 - val_accuracy: 0.9049\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90601\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50411 to 0.48453, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 158s 9ms/step - loss: 0.4718 - accuracy: 0.9110 - val_loss: 0.4626 - val_accuracy: 0.9076\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90601 to 0.90761, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48453 to 0.46256, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 165s 10ms/step - loss: 0.4489 - accuracy: 0.9169 - val_loss: 0.4495 - val_accuracy: 0.9134\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90761 to 0.91337, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46256 to 0.44950, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 160s 9ms/step - loss: 0.4285 - accuracy: 0.9215 - val_loss: 0.4305 - val_accuracy: 0.9114\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91337\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44950 to 0.43054, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 160s 9ms/step - loss: 0.4078 - accuracy: 0.9267 - val_loss: 0.4124 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91337 to 0.92196, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43054 to 0.41239, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 160s 9ms/step - loss: 0.3880 - accuracy: 0.9313 - val_loss: 0.3950 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92196 to 0.92286, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41239 to 0.39500, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 159s 9ms/step - loss: 0.3703 - accuracy: 0.9346 - val_loss: 0.3811 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92286 to 0.92368, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39500 to 0.38114, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 159s 9ms/step - loss: 0.3527 - accuracy: 0.9389 - val_loss: 0.3678 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92368 to 0.92724, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38114 to 0.36781, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 159s 9ms/step - loss: 0.3363 - accuracy: 0.9414 - val_loss: 0.3589 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92724\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36781 to 0.35887, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 169s 10ms/step - loss: 0.3206 - accuracy: 0.9445 - val_loss: 0.3421 - val_accuracy: 0.9296\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92724 to 0.92957, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35887 to 0.34205, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 159s 9ms/step - loss: 0.3056 - accuracy: 0.9469 - val_loss: 0.3424 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34205\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 157s 9ms/step - loss: 0.2920 - accuracy: 0.9492 - val_loss: 0.3315 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92957\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34205 to 0.33147, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 158s 9ms/step - loss: 0.2798 - accuracy: 0.9514 - val_loss: 0.3191 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92957\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33147 to 0.31906, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 156s 9ms/step - loss: 0.2663 - accuracy: 0.9540 - val_loss: 0.3113 - val_accuracy: 0.9291\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92957\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31906 to 0.31134, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 158s 9ms/step - loss: 0.2553 - accuracy: 0.9556 - val_loss: 0.3030 - val_accuracy: 0.9312\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92957 to 0.93121, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31134 to 0.30304, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 164s 10ms/step - loss: 0.2438 - accuracy: 0.9578 - val_loss: 0.3004 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30304 to 0.30043, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 157s 9ms/step - loss: 0.2336 - accuracy: 0.9594 - val_loss: 0.3025 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30043\n",
      "epoch 22\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 158s 9ms/step - loss: 0.2236 - accuracy: 0.9615 - val_loss: 0.2890 - val_accuracy: 0.9317\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93121 to 0.93174, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30043 to 0.28899, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 157s 9ms/step - loss: 0.2151 - accuracy: 0.9629 - val_loss: 0.2857 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93174\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28899 to 0.28568, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 158s 9ms/step - loss: 0.2047 - accuracy: 0.9649 - val_loss: 0.2831 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93174\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28568 to 0.28309, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 157s 9ms/step - loss: 0.1973 - accuracy: 0.9657 - val_loss: 0.2728 - val_accuracy: 0.9324\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93174 to 0.93239, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28309 to 0.27278, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 165s 10ms/step - loss: 0.1889 - accuracy: 0.9673 - val_loss: 0.2760 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27278\n",
      "epoch 27\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 159s 9ms/step - loss: 0.1826 - accuracy: 0.9679 - val_loss: 0.2739 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27278\n",
      "epoch 28\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 156s 9ms/step - loss: 0.1748 - accuracy: 0.9695 - val_loss: 0.2782 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27278\n",
      "epoch 29\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 158s 9ms/step - loss: 0.1674 - accuracy: 0.9708 - val_loss: 0.2760 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27278\n",
      "epoch 30\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 158s 9ms/step - loss: 0.1611 - accuracy: 0.9721 - val_loss: 0.2720 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27278 to 0.27197, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 158s 9ms/step - loss: 0.1559 - accuracy: 0.9723 - val_loss: 0.2707 - val_accuracy: 0.9303\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27197 to 0.27069, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 168s 10ms/step - loss: 0.1506 - accuracy: 0.9731 - val_loss: 0.2723 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27069\n",
      "epoch 33\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 159s 9ms/step - loss: 0.1447 - accuracy: 0.9745 - val_loss: 0.2738 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27069\n",
      "epoch 34\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 158s 9ms/step - loss: 0.1400 - accuracy: 0.9749 - val_loss: 0.2736 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27069\n",
      "epoch 35\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 156s 9ms/step - loss: 0.1341 - accuracy: 0.9763 - val_loss: 0.2611 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27069 to 0.26109, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 36\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 157s 9ms/step - loss: 0.1291 - accuracy: 0.9770 - val_loss: 0.2626 - val_accuracy: 0.9317\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26109\n",
      "epoch 37\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 157s 9ms/step - loss: 0.1256 - accuracy: 0.9777 - val_loss: 0.2640 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26109\n",
      "epoch 38\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 165s 10ms/step - loss: 0.1212 - accuracy: 0.9781 - val_loss: 0.2796 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26109\n",
      "epoch 39\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 157s 9ms/step - loss: 0.1172 - accuracy: 0.9787 - val_loss: 0.2657 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26109\n",
      "epoch 40\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 156s 9ms/step - loss: 0.1127 - accuracy: 0.9799 - val_loss: 0.2677 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26109\n",
      "epoch 41\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 156s 9ms/step - loss: 0.1092 - accuracy: 0.9802 - val_loss: 0.2571 - val_accuracy: 0.9323\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26109 to 0.25706, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 42\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 159s 9ms/step - loss: 0.1048 - accuracy: 0.9813 - val_loss: 0.2645 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25706\n",
      "epoch 43\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 159s 9ms/step - loss: 0.1025 - accuracy: 0.9814 - val_loss: 0.2605 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25706\n",
      "epoch 44\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 164s 10ms/step - loss: 0.1002 - accuracy: 0.9815 - val_loss: 0.2542 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25706 to 0.25421, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_loss-weights.hdf5\n",
      "epoch 45\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 154s 9ms/step - loss: 0.0965 - accuracy: 0.9823 - val_loss: 0.2588 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 46\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 158s 9ms/step - loss: 0.0933 - accuracy: 0.9833 - val_loss: 0.2641 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 47\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0909 - accuracy: 0.9833 - val_loss: 0.2592 - val_accuracy: 0.9330\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93239 to 0.93297, saving model to D:/mulocdeep/lv1_result22/fold0_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 48\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 147s 9ms/step - loss: 0.0880 - accuracy: 0.9840 - val_loss: 0.2662 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 49\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.0854 - accuracy: 0.9840 - val_loss: 0.2742 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 50\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 157s 9ms/step - loss: 0.0824 - accuracy: 0.9849 - val_loss: 0.2595 - val_accuracy: 0.9324\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 51\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 148s 9ms/step - loss: 0.0794 - accuracy: 0.9857 - val_loss: 0.2692 - val_accuracy: 0.9298\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 52\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.0806 - accuracy: 0.9847 - val_loss: 0.2728 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 53\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 148s 9ms/step - loss: 0.0751 - accuracy: 0.9864 - val_loss: 0.2778 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 54\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 148s 9ms/step - loss: 0.0731 - accuracy: 0.9868 - val_loss: 0.2755 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 55\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 154s 9ms/step - loss: 0.0727 - accuracy: 0.9865 - val_loss: 0.2628 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 56\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 157s 9ms/step - loss: 0.0691 - accuracy: 0.9875 - val_loss: 0.2925 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 57\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0688 - accuracy: 0.9871 - val_loss: 0.2728 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 58\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0655 - accuracy: 0.9882 - val_loss: 0.2933 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 59\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 146s 9ms/step - loss: 0.0652 - accuracy: 0.9879 - val_loss: 0.2725 - val_accuracy: 0.9312\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 60\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0625 - accuracy: 0.9885 - val_loss: 0.2763 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 61\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 147s 9ms/step - loss: 0.0597 - accuracy: 0.9894 - val_loss: 0.2694 - val_accuracy: 0.9317\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 62\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.0589 - accuracy: 0.9893 - val_loss: 0.2808 - val_accuracy: 0.9308\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 63\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 157s 9ms/step - loss: 0.0575 - accuracy: 0.9897 - val_loss: 0.2973 - val_accuracy: 0.9298\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 64\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 148s 9ms/step - loss: 0.0560 - accuracy: 0.9896 - val_loss: 0.2870 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 65\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.0549 - accuracy: 0.9899 - val_loss: 0.2841 - val_accuracy: 0.9291\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 66\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 148s 9ms/step - loss: 0.0535 - accuracy: 0.9904 - val_loss: 0.2857 - val_accuracy: 0.9310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 67\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0519 - accuracy: 0.9905 - val_loss: 0.3169 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 68\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 148s 9ms/step - loss: 0.0509 - accuracy: 0.9906 - val_loss: 0.2945 - val_accuracy: 0.9310\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 69\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 158s 9ms/step - loss: 0.0511 - accuracy: 0.9904 - val_loss: 0.2990 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 70\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0486 - accuracy: 0.9913 - val_loss: 0.2939 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 71\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 148s 9ms/step - loss: 0.0475 - accuracy: 0.9915 - val_loss: 0.3035 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 72\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 148s 9ms/step - loss: 0.0455 - accuracy: 0.9918 - val_loss: 0.3166 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 73\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.0461 - accuracy: 0.9915 - val_loss: 0.3057 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 74\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0472 - accuracy: 0.9908 - val_loss: 0.2923 - val_accuracy: 0.9296\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 75\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 160s 9ms/step - loss: 0.0479 - accuracy: 0.9902 - val_loss: 0.2989 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 76\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0434 - accuracy: 0.9920 - val_loss: 0.2921 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 77\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0429 - accuracy: 0.9921 - val_loss: 0.3105 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 78\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.0430 - accuracy: 0.9918 - val_loss: 0.3216 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "epoch 79\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 148s 9ms/step - loss: 0.0413 - accuracy: 0.9922 - val_loss: 0.2914 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93297\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25421\n",
      "doing 1th fold\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1000, 25)     0           dropout_7[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 180)    223560      lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 180)    720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1000, 180)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1000, 180)    0           dropout_8[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 180)    390960      lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1000, 180)    720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1000, 180)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1000, 180)    0           dropout_9[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 180)    390960      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1000, 180)    720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 1000, 180)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1000, 180)    0           dropout_10[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1000, 181)    0           lambda_8[0][0]                   \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 41, 180)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1000, 25)     0           dropout_7[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 180)    223560      lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1000, 180)    720         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1000, 180)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1000, 180)    0           dropout_8[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 180)    390960      lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1000, 180)    720         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1000, 180)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1000, 180)    0           dropout_9[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 180)    390960      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1000, 180)    720         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 1000, 180)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1000, 180)    0           dropout_10[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1000, 181)    0           lambda_8[0][0]                   \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         [(None, 41, 180), (N 81549       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 41, 180)      720         attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 41, 180)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7380)         0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 7380)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 80)           590480      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 8, 1)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 10, 8, 1)     4           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 8, 1)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 174s 10ms/step - loss: 0.7344 - accuracy: 0.6809 - val_loss: 0.6588 - val_accuracy: 0.7829\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78290, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65875, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.6270 - accuracy: 0.8254 - val_loss: 0.6054 - val_accuracy: 0.8353\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.78290 to 0.83534, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.65875 to 0.60540, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 148s 9ms/step - loss: 0.5793 - accuracy: 0.8604 - val_loss: 0.5586 - val_accuracy: 0.8675\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.83534 to 0.86753, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.60540 to 0.55860, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.5456 - accuracy: 0.8836 - val_loss: 0.5474 - val_accuracy: 0.8677\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86753 to 0.86773, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55860 to 0.54738, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.5185 - accuracy: 0.8956 - val_loss: 0.5143 - val_accuracy: 0.8921\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.86773 to 0.89211, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.54738 to 0.51431, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.4926 - accuracy: 0.9051 - val_loss: 0.4923 - val_accuracy: 0.8975\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89211 to 0.89755, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51431 to 0.49229, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.4687 - accuracy: 0.9127 - val_loss: 0.4717 - val_accuracy: 0.9016\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89755 to 0.90160, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49229 to 0.47169, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 162s 9ms/step - loss: 0.4473 - accuracy: 0.9177 - val_loss: 0.4596 - val_accuracy: 0.9035\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90160 to 0.90348, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47169 to 0.45957, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.4251 - accuracy: 0.9241 - val_loss: 0.4422 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90348 to 0.91072, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45957 to 0.44223, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.4057 - accuracy: 0.9287 - val_loss: 0.4190 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91072 to 0.91239, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44223 to 0.41898, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.3859 - accuracy: 0.9329 - val_loss: 0.4090 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91239 to 0.91329, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41898 to 0.40901, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.3666 - accuracy: 0.9369 - val_loss: 0.3920 - val_accuracy: 0.9169\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91329 to 0.91689, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40901 to 0.39196, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.3501 - accuracy: 0.9400 - val_loss: 0.3819 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91689 to 0.91980, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39196 to 0.38193, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 161s 9ms/step - loss: 0.3326 - accuracy: 0.9439 - val_loss: 0.3709 - val_accuracy: 0.9181\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91980\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38193 to 0.37094, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.3182 - accuracy: 0.9454 - val_loss: 0.3637 - val_accuracy: 0.9197\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91980\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37094 to 0.36371, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 154s 9ms/step - loss: 0.3031 - accuracy: 0.9491 - val_loss: 0.3511 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91980 to 0.92078, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36371 to 0.35115, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.2898 - accuracy: 0.9511 - val_loss: 0.3602 - val_accuracy: 0.9210\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92078 to 0.92102, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35115\n",
      "epoch 17\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.2754 - accuracy: 0.9535 - val_loss: 0.3366 - val_accuracy: 0.9201\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92102\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35115 to 0.33658, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.2646 - accuracy: 0.9551 - val_loss: 0.3376 - val_accuracy: 0.9181\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92102\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.33658\n",
      "epoch 19\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 158s 9ms/step - loss: 0.2514 - accuracy: 0.9578 - val_loss: 0.3320 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92102\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33658 to 0.33196, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.2406 - accuracy: 0.9597 - val_loss: 0.3317 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92102 to 0.92225, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33196 to 0.33172, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.2300 - accuracy: 0.9616 - val_loss: 0.3108 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92225 to 0.92470, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33172 to 0.31076, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.2206 - accuracy: 0.9629 - val_loss: 0.3119 - val_accuracy: 0.9204\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31076\n",
      "epoch 23\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.2114 - accuracy: 0.9642 - val_loss: 0.2989 - val_accuracy: 0.9246\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31076 to 0.29893, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.2018 - accuracy: 0.9664 - val_loss: 0.3046 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.29893\n",
      "epoch 25\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 161s 9ms/step - loss: 0.1943 - accuracy: 0.9676 - val_loss: 0.3070 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.29893\n",
      "epoch 26\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.1860 - accuracy: 0.9688 - val_loss: 0.2994 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.29893\n",
      "epoch 27\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 148s 9ms/step - loss: 0.1793 - accuracy: 0.9697 - val_loss: 0.3056 - val_accuracy: 0.9197\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.29893\n",
      "epoch 28\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.1724 - accuracy: 0.9711 - val_loss: 0.3026 - val_accuracy: 0.9235\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.29893\n",
      "epoch 29\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.1655 - accuracy: 0.9716 - val_loss: 0.2933 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29893 to 0.29330, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.1596 - accuracy: 0.9727 - val_loss: 0.2886 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29330 to 0.28861, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 31\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 155s 9ms/step - loss: 0.1528 - accuracy: 0.9740 - val_loss: 0.2855 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28861 to 0.28547, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 156s 9ms/step - loss: 0.1468 - accuracy: 0.9755 - val_loss: 0.2900 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28547\n",
      "epoch 33\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.1423 - accuracy: 0.9754 - val_loss: 0.3037 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28547\n",
      "epoch 34\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.1363 - accuracy: 0.9769 - val_loss: 0.2916 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28547\n",
      "epoch 35\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.1313 - accuracy: 0.9776 - val_loss: 0.2870 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28547\n",
      "epoch 36\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.1266 - accuracy: 0.9784 - val_loss: 0.2909 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28547\n",
      "epoch 37\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.1237 - accuracy: 0.9786 - val_loss: 0.2903 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28547\n",
      "epoch 38\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 161s 9ms/step - loss: 0.1241 - accuracy: 0.9769 - val_loss: 0.2842 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28547 to 0.28425, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 39\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.1205 - accuracy: 0.9773 - val_loss: 0.3003 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92470\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28425\n",
      "epoch 40\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.1130 - accuracy: 0.9798 - val_loss: 0.2877 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92470 to 0.92499, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28425\n",
      "epoch 41\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.1078 - accuracy: 0.9811 - val_loss: 0.2965 - val_accuracy: 0.9248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28425\n",
      "epoch 42\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.1031 - accuracy: 0.9821 - val_loss: 0.2816 - val_accuracy: 0.9242\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28425 to 0.28161, saving model to D:/mulocdeep/lv1_result22/fold1_big_lv1_loss-weights.hdf5\n",
      "epoch 43\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.1008 - accuracy: 0.9821 - val_loss: 0.2921 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 44\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 160s 9ms/step - loss: 0.0972 - accuracy: 0.9828 - val_loss: 0.2901 - val_accuracy: 0.9196\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 45\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.0937 - accuracy: 0.9834 - val_loss: 0.2963 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 46\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 148s 9ms/step - loss: 0.0918 - accuracy: 0.9835 - val_loss: 0.2895 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 47\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.0886 - accuracy: 0.9845 - val_loss: 0.3219 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 48\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0869 - accuracy: 0.9845 - val_loss: 0.2987 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 49\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.0840 - accuracy: 0.9849 - val_loss: 0.3114 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 50\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 163s 9ms/step - loss: 0.0812 - accuracy: 0.9853 - val_loss: 0.2929 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 51\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 152s 9ms/step - loss: 0.0797 - accuracy: 0.9855 - val_loss: 0.2871 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 52\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.0757 - accuracy: 0.9865 - val_loss: 0.2945 - val_accuracy: 0.9226\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 53\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.0726 - accuracy: 0.9874 - val_loss: 0.3201 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 54\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.0717 - accuracy: 0.9873 - val_loss: 0.3172 - val_accuracy: 0.9242\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 55\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0698 - accuracy: 0.9874 - val_loss: 0.3227 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 56\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.0699 - accuracy: 0.9868 - val_loss: 0.3049 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 57\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 161s 9ms/step - loss: 0.0683 - accuracy: 0.9873 - val_loss: 0.3082 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 58\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0667 - accuracy: 0.9875 - val_loss: 0.3046 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 59\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0626 - accuracy: 0.9889 - val_loss: 0.3178 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 60\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0612 - accuracy: 0.9891 - val_loss: 0.3188 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 61\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0608 - accuracy: 0.9886 - val_loss: 0.3262 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 62\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.0584 - accuracy: 0.9896 - val_loss: 0.3366 - val_accuracy: 0.9226\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 63\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 160s 9ms/step - loss: 0.0554 - accuracy: 0.9902 - val_loss: 0.3231 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 64\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0545 - accuracy: 0.9904 - val_loss: 0.3373 - val_accuracy: 0.9214\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 65\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 150s 9ms/step - loss: 0.0539 - accuracy: 0.9905 - val_loss: 0.3172 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 66\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.0524 - accuracy: 0.9907 - val_loss: 0.3491 - val_accuracy: 0.9204\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 67\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 152s 9ms/step - loss: 0.0519 - accuracy: 0.9904 - val_loss: 0.3391 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 68\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 154s 9ms/step - loss: 0.0497 - accuracy: 0.9909 - val_loss: 0.3329 - val_accuracy: 0.9212\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 69\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 160s 9ms/step - loss: 0.0482 - accuracy: 0.9914 - val_loss: 0.3471 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 70\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.0484 - accuracy: 0.9911 - val_loss: 0.3298 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 71\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.0458 - accuracy: 0.9922 - val_loss: 0.3492 - val_accuracy: 0.9213\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 72\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.0466 - accuracy: 0.9914 - val_loss: 0.3633 - val_accuracy: 0.9214\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 73\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.0463 - accuracy: 0.9914 - val_loss: 0.3447 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 74\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.0440 - accuracy: 0.9920 - val_loss: 0.3468 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 75\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 162s 9ms/step - loss: 0.0429 - accuracy: 0.9922 - val_loss: 0.3491 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 76\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.0419 - accuracy: 0.9923 - val_loss: 0.3522 - val_accuracy: 0.9215\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 77\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 151s 9ms/step - loss: 0.0410 - accuracy: 0.9927 - val_loss: 0.3428 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 78\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 152s 9ms/step - loss: 0.0409 - accuracy: 0.9925 - val_loss: 0.3467 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "epoch 79\n",
      "\n",
      "Train on 17138 samples, validate on 2445 samples\n",
      "Epoch 1/1\n",
      "17138/17138 [==============================] - 149s 9ms/step - loss: 0.0394 - accuracy: 0.9930 - val_loss: 0.3701 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28161\n",
      "doing 2th fold\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1000, 25)     0           dropout_13[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1000, 180)    223560      lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1000, 180)    720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1000, 180)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1000, 180)    0           dropout_14[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1000, 180)    390960      lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1000, 180)    720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1000, 180)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1000, 180)    0           dropout_15[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1000, 180)    390960      lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1000, 180)    720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1000, 180)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1000, 180)    0           dropout_16[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 181)    0           lambda_12[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 41, 180)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1000, 25)     0           dropout_13[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1000, 180)    223560      lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1000, 180)    720         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1000, 180)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1000, 180)    0           dropout_14[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1000, 180)    390960      lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1000, 180)    720         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1000, 180)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1000, 180)    0           dropout_15[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 1000, 180)    390960      lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1000, 180)    720         bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1000, 180)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1000, 180)    0           dropout_16[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 181)    0           lambda_12[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 41, 180), (N 81549       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 41, 180)      720         attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 41, 180)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7380)         0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 7380)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           590480      dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 8, 1)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 10, 8, 1)     4           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 8, 1)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 178s 10ms/step - loss: 0.7257 - accuracy: 0.7136 - val_loss: 0.6756 - val_accuracy: 0.8115\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81148, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67563, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 154s 9ms/step - loss: 0.6260 - accuracy: 0.8294 - val_loss: 0.6120 - val_accuracy: 0.8125\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81148 to 0.81245, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.67563 to 0.61204, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 153s 9ms/step - loss: 0.5757 - accuracy: 0.8644 - val_loss: 0.5567 - val_accuracy: 0.8784\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81245 to 0.87843, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.61204 to 0.55666, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 153s 9ms/step - loss: 0.5443 - accuracy: 0.8840 - val_loss: 0.5268 - val_accuracy: 0.8866\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87843 to 0.88662, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55666 to 0.52681, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 153s 9ms/step - loss: 0.5172 - accuracy: 0.8959 - val_loss: 0.5133 - val_accuracy: 0.8834\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.88662\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52681 to 0.51329, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.4921 - accuracy: 0.9041 - val_loss: 0.4866 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88662 to 0.90515, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51329 to 0.48659, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 162s 9ms/step - loss: 0.4689 - accuracy: 0.9118 - val_loss: 0.4683 - val_accuracy: 0.9052\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90515 to 0.90523, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48659 to 0.46831, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 154s 9ms/step - loss: 0.4478 - accuracy: 0.9165 - val_loss: 0.4464 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90523 to 0.90726, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46831 to 0.44638, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.4260 - accuracy: 0.9230 - val_loss: 0.4320 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90726 to 0.91418, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44638 to 0.43204, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 154s 9ms/step - loss: 0.4058 - accuracy: 0.9274 - val_loss: 0.4204 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91418 to 0.91444, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43204 to 0.42044, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.3870 - accuracy: 0.9311 - val_loss: 0.4102 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91444\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42044 to 0.41017, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.3692 - accuracy: 0.9345 - val_loss: 0.3884 - val_accuracy: 0.9190\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91444 to 0.91900, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41017 to 0.38844, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 159s 9ms/step - loss: 0.3504 - accuracy: 0.9393 - val_loss: 0.3747 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91900 to 0.92229, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38844 to 0.37469, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 153s 9ms/step - loss: 0.3348 - accuracy: 0.9413 - val_loss: 0.3637 - val_accuracy: 0.9212\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92229\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37469 to 0.36374, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 154s 9ms/step - loss: 0.3194 - accuracy: 0.9443 - val_loss: 0.3580 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92229\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36374 to 0.35797, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 153s 9ms/step - loss: 0.3055 - accuracy: 0.9467 - val_loss: 0.3457 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92229 to 0.92533, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35797 to 0.34565, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.2913 - accuracy: 0.9490 - val_loss: 0.3383 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92533\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34565 to 0.33828, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.2774 - accuracy: 0.9521 - val_loss: 0.3266 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92533 to 0.92761, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33828 to 0.32663, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 155s 9ms/step - loss: 0.2667 - accuracy: 0.9531 - val_loss: 0.3212 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92761\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32663 to 0.32115, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 159s 9ms/step - loss: 0.2546 - accuracy: 0.9554 - val_loss: 0.3127 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92761\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32115 to 0.31268, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.2437 - accuracy: 0.9576 - val_loss: 0.3012 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92761 to 0.92989, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31268 to 0.30121, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.2319 - accuracy: 0.9602 - val_loss: 0.3140 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30121\n",
      "epoch 22\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.2222 - accuracy: 0.9616 - val_loss: 0.3055 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30121\n",
      "epoch 23\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 153s 9ms/step - loss: 0.2137 - accuracy: 0.9626 - val_loss: 0.2913 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30121 to 0.29135, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.2054 - accuracy: 0.9645 - val_loss: 0.2886 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29135 to 0.28859, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 161s 9ms/step - loss: 0.1985 - accuracy: 0.9649 - val_loss: 0.2874 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28859 to 0.28738, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.1890 - accuracy: 0.9667 - val_loss: 0.2994 - val_accuracy: 0.9254\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28738\n",
      "epoch 27\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.1826 - accuracy: 0.9676 - val_loss: 0.2801 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28738 to 0.28005, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 28\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.1742 - accuracy: 0.9691 - val_loss: 0.2854 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28005\n",
      "epoch 29\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.1682 - accuracy: 0.9700 - val_loss: 0.2837 - val_accuracy: 0.9242\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28005\n",
      "epoch 30\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.1623 - accuracy: 0.9710 - val_loss: 0.2831 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28005\n",
      "epoch 31\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 161s 9ms/step - loss: 0.1567 - accuracy: 0.9722 - val_loss: 0.2876 - val_accuracy: 0.9255\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28005\n",
      "epoch 32\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 150s 9ms/step - loss: 0.1501 - accuracy: 0.9734 - val_loss: 0.2683 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28005 to 0.26832, saving model to D:/mulocdeep/lv1_result22/fold2_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.1448 - accuracy: 0.9743 - val_loss: 0.2857 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 34\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.1400 - accuracy: 0.9752 - val_loss: 0.2847 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 35\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.1331 - accuracy: 0.9765 - val_loss: 0.2868 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 36\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.1302 - accuracy: 0.9765 - val_loss: 0.2684 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 37\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 164s 10ms/step - loss: 0.1249 - accuracy: 0.9776 - val_loss: 0.2719 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 38\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.1210 - accuracy: 0.9783 - val_loss: 0.2804 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 39\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.1163 - accuracy: 0.9793 - val_loss: 0.2973 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 40\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 153s 9ms/step - loss: 0.1129 - accuracy: 0.9799 - val_loss: 0.2817 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 41\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.1100 - accuracy: 0.9799 - val_loss: 0.2793 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 42\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.1067 - accuracy: 0.9803 - val_loss: 0.2871 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 43\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 164s 10ms/step - loss: 0.1022 - accuracy: 0.9814 - val_loss: 0.2861 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 44\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0990 - accuracy: 0.9820 - val_loss: 0.2752 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 45\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.0965 - accuracy: 0.9825 - val_loss: 0.2719 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 46\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0929 - accuracy: 0.9830 - val_loss: 0.2700 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 47\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0911 - accuracy: 0.9832 - val_loss: 0.3046 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 48\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0879 - accuracy: 0.9839 - val_loss: 0.2801 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 49\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 161s 9ms/step - loss: 0.0862 - accuracy: 0.9843 - val_loss: 0.2879 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 50\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 155s 9ms/step - loss: 0.0824 - accuracy: 0.9849 - val_loss: 0.2913 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 51\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.0795 - accuracy: 0.9857 - val_loss: 0.2775 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 52\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0791 - accuracy: 0.9854 - val_loss: 0.2942 - val_accuracy: 0.9255\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 53\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0757 - accuracy: 0.9862 - val_loss: 0.2888 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 54\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0728 - accuracy: 0.9870 - val_loss: 0.2911 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 55\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 153s 9ms/step - loss: 0.0712 - accuracy: 0.9869 - val_loss: 0.2944 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 56\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 165s 10ms/step - loss: 0.0702 - accuracy: 0.9869 - val_loss: 0.2982 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 57\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.0669 - accuracy: 0.9883 - val_loss: 0.2933 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 58\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0646 - accuracy: 0.9884 - val_loss: 0.3014 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 59\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0639 - accuracy: 0.9884 - val_loss: 0.2977 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 60\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0629 - accuracy: 0.9882 - val_loss: 0.3072 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 61\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0602 - accuracy: 0.9893 - val_loss: 0.3178 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 62\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 165s 10ms/step - loss: 0.0585 - accuracy: 0.9896 - val_loss: 0.2979 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 63\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 153s 9ms/step - loss: 0.0579 - accuracy: 0.9893 - val_loss: 0.3082 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 64\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.0561 - accuracy: 0.9898 - val_loss: 0.3325 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 65\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.0565 - accuracy: 0.9892 - val_loss: 0.3348 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 66\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 153s 9ms/step - loss: 0.0548 - accuracy: 0.9900 - val_loss: 0.3142 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 67\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0520 - accuracy: 0.9905 - val_loss: 0.3198 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 68\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 163s 9ms/step - loss: 0.0508 - accuracy: 0.9908 - val_loss: 0.3260 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 69\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0491 - accuracy: 0.9914 - val_loss: 0.3260 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 70\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.0475 - accuracy: 0.9916 - val_loss: 0.3353 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 71\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0480 - accuracy: 0.9914 - val_loss: 0.3232 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 72\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.0455 - accuracy: 0.9921 - val_loss: 0.3216 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 73\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0451 - accuracy: 0.9919 - val_loss: 0.3239 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 74\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 163s 9ms/step - loss: 0.0442 - accuracy: 0.9923 - val_loss: 0.3279 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 75\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 151s 9ms/step - loss: 0.0447 - accuracy: 0.9916 - val_loss: 0.3220 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 76\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0416 - accuracy: 0.9929 - val_loss: 0.3396 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 77\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 152s 9ms/step - loss: 0.0414 - accuracy: 0.9926 - val_loss: 0.3380 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 78\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 154s 9ms/step - loss: 0.0415 - accuracy: 0.9926 - val_loss: 0.3278 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "epoch 79\n",
      "\n",
      "Train on 17214 samples, validate on 2369 samples\n",
      "Epoch 1/1\n",
      "17214/17214 [==============================] - 153s 9ms/step - loss: 0.0397 - accuracy: 0.9931 - val_loss: 0.3369 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26832\n",
      "doing 3th fold\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1000, 25)     0           dropout_19[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1000, 180)    223560      lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1000, 180)    720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 1000, 180)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1000, 180)    0           dropout_20[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1000, 180)    390960      lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1000, 180)    720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 1000, 180)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1000, 180)    0           dropout_21[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1000, 180)    390960      lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1000, 180)    720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 1000, 180)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1000, 180)    0           dropout_22[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1000, 181)    0           lambda_16[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 41, 180)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1000, 25)     0           dropout_19[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 1000, 180)    223560      lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1000, 180)    720         bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 1000, 180)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1000, 180)    0           dropout_20[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 1000, 180)    390960      lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1000, 180)    720         bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 1000, 180)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1000, 180)    0           dropout_21[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 1000, 180)    390960      lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1000, 180)    720         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 1000, 180)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1000, 180)    0           dropout_22[0][0]                 \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1000, 181)    0           lambda_16[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         [(None, 41, 180), (N 81549       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 41, 180)      720         attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 41, 180)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 7380)         0           dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 7380)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 80)           590480      dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 8, 1)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 8, 1)     4           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 8, 1)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 159s 9ms/step - loss: 0.7228 - accuracy: 0.7097 - val_loss: 0.6697 - val_accuracy: 0.8204\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82041, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66965, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 151s 9ms/step - loss: 0.6257 - accuracy: 0.8267 - val_loss: 0.6087 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.82041 to 0.84462, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66965 to 0.60874, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 153s 9ms/step - loss: 0.5782 - accuracy: 0.8641 - val_loss: 0.5693 - val_accuracy: 0.8596\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84462 to 0.85959, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.60874 to 0.56935, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 152s 9ms/step - loss: 0.5449 - accuracy: 0.8841 - val_loss: 0.5267 - val_accuracy: 0.8919\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85959 to 0.89189, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56935 to 0.52672, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 152s 9ms/step - loss: 0.5186 - accuracy: 0.8949 - val_loss: 0.5062 - val_accuracy: 0.8937\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89189 to 0.89367, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52672 to 0.50617, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 165s 10ms/step - loss: 0.4926 - accuracy: 0.9039 - val_loss: 0.4798 - val_accuracy: 0.9049\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89367 to 0.90487, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50617 to 0.47975, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 153s 9ms/step - loss: 0.4702 - accuracy: 0.9107 - val_loss: 0.4671 - val_accuracy: 0.9052\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90487 to 0.90519, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47975 to 0.46711, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 152s 9ms/step - loss: 0.4489 - accuracy: 0.9163 - val_loss: 0.4419 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90519 to 0.91623, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46711 to 0.44194, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 152s 9ms/step - loss: 0.4269 - accuracy: 0.9231 - val_loss: 0.4259 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91623 to 0.91696, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44194 to 0.42591, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 152s 9ms/step - loss: 0.4061 - accuracy: 0.9279 - val_loss: 0.4127 - val_accuracy: 0.9188\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91696 to 0.91882, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42591 to 0.41266, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 152s 9ms/step - loss: 0.3875 - accuracy: 0.9315 - val_loss: 0.3948 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91882 to 0.92381, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41266 to 0.39475, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 165s 10ms/step - loss: 0.3693 - accuracy: 0.9349 - val_loss: 0.3798 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92381 to 0.92669, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39475 to 0.37976, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 154s 9ms/step - loss: 0.3528 - accuracy: 0.9378 - val_loss: 0.3669 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92669 to 0.92795, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37976 to 0.36691, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 154s 9ms/step - loss: 0.3355 - accuracy: 0.9412 - val_loss: 0.3660 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92795\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36691 to 0.36595, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 151s 9ms/step - loss: 0.3196 - accuracy: 0.9443 - val_loss: 0.3510 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92795\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36595 to 0.35101, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 155s 9ms/step - loss: 0.3054 - accuracy: 0.9467 - val_loss: 0.3334 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92795 to 0.92941, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35101 to 0.33340, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 153s 9ms/step - loss: 0.2925 - accuracy: 0.9484 - val_loss: 0.3341 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92941\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.33340\n",
      "epoch 17\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 167s 10ms/step - loss: 0.2783 - accuracy: 0.9520 - val_loss: 0.3224 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92941\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33340 to 0.32242, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 154s 9ms/step - loss: 0.2667 - accuracy: 0.9532 - val_loss: 0.3097 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92941 to 0.93055, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32242 to 0.30966, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 152s 9ms/step - loss: 0.2552 - accuracy: 0.9555 - val_loss: 0.3085 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93055\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30966 to 0.30851, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 152s 9ms/step - loss: 0.2447 - accuracy: 0.9569 - val_loss: 0.3092 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93055\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30851\n",
      "epoch 21\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 152s 9ms/step - loss: 0.2329 - accuracy: 0.9597 - val_loss: 0.2984 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93055\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30851 to 0.29843, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 151s 9ms/step - loss: 0.2234 - accuracy: 0.9615 - val_loss: 0.2935 - val_accuracy: 0.9298\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93055\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29843 to 0.29353, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 164s 10ms/step - loss: 0.2149 - accuracy: 0.9622 - val_loss: 0.2920 - val_accuracy: 0.9322\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93055 to 0.93217, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29353 to 0.29203, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 156s 9ms/step - loss: 0.2062 - accuracy: 0.9642 - val_loss: 0.2818 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93217\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29203 to 0.28175, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 153s 9ms/step - loss: 0.1977 - accuracy: 0.9649 - val_loss: 0.2807 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93217\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28175 to 0.28069, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 152s 9ms/step - loss: 0.1895 - accuracy: 0.9668 - val_loss: 0.2836 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93217\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28069\n",
      "epoch 27\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 151s 9ms/step - loss: 0.1831 - accuracy: 0.9677 - val_loss: 0.2865 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93217\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28069\n",
      "epoch 28\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 153s 9ms/step - loss: 0.1757 - accuracy: 0.9688 - val_loss: 0.2769 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93217\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28069 to 0.27694, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 153s 9ms/step - loss: 0.1692 - accuracy: 0.9705 - val_loss: 0.2723 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93217\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27694 to 0.27234, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 172s 10ms/step - loss: 0.1635 - accuracy: 0.9711 - val_loss: 0.2790 - val_accuracy: 0.9315\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93217\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27234\n",
      "epoch 31\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 163s 9ms/step - loss: 0.1563 - accuracy: 0.9724 - val_loss: 0.2586 - val_accuracy: 0.9339\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93217 to 0.93391, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27234 to 0.25863, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 163s 10ms/step - loss: 0.1510 - accuracy: 0.9735 - val_loss: 0.2787 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 33\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 163s 10ms/step - loss: 0.1455 - accuracy: 0.9744 - val_loss: 0.2977 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 34\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 165s 10ms/step - loss: 0.1400 - accuracy: 0.9751 - val_loss: 0.2695 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 35\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 171s 10ms/step - loss: 0.1360 - accuracy: 0.9758 - val_loss: 0.2706 - val_accuracy: 0.9318\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 36\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 163s 10ms/step - loss: 0.1313 - accuracy: 0.9763 - val_loss: 0.2667 - val_accuracy: 0.9314\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 37\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 159s 9ms/step - loss: 0.1250 - accuracy: 0.9780 - val_loss: 0.2645 - val_accuracy: 0.9337\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 38\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 157s 9ms/step - loss: 0.1219 - accuracy: 0.9782 - val_loss: 0.2721 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 39\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 157s 9ms/step - loss: 0.1170 - accuracy: 0.9793 - val_loss: 0.2620 - val_accuracy: 0.9308\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 40\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 160s 9ms/step - loss: 0.1147 - accuracy: 0.9790 - val_loss: 0.2727 - val_accuracy: 0.9325\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 41\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17118/17118 [==============================] - 167s 10ms/step - loss: 0.1107 - accuracy: 0.9798 - val_loss: 0.2704 - val_accuracy: 0.9315\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 42\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 158s 9ms/step - loss: 0.1070 - accuracy: 0.9803 - val_loss: 0.2619 - val_accuracy: 0.9318\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 43\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 157s 9ms/step - loss: 0.1040 - accuracy: 0.9807 - val_loss: 0.2698 - val_accuracy: 0.9315\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 44\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 156s 9ms/step - loss: 0.1011 - accuracy: 0.9812 - val_loss: 0.2644 - val_accuracy: 0.9323\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 45\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 157s 9ms/step - loss: 0.0971 - accuracy: 0.9823 - val_loss: 0.2775 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 46\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 157s 9ms/step - loss: 0.0942 - accuracy: 0.9827 - val_loss: 0.2828 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 47\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 164s 10ms/step - loss: 0.0920 - accuracy: 0.9830 - val_loss: 0.2710 - val_accuracy: 0.9329\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 48\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 158s 9ms/step - loss: 0.0885 - accuracy: 0.9839 - val_loss: 0.2707 - val_accuracy: 0.9349\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93391 to 0.93489, saving model to D:/mulocdeep/lv1_result22/fold3_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 49\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 157s 9ms/step - loss: 0.0864 - accuracy: 0.9840 - val_loss: 0.2865 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 50\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 157s 9ms/step - loss: 0.0837 - accuracy: 0.9845 - val_loss: 0.2800 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 51\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 156s 9ms/step - loss: 0.0815 - accuracy: 0.9851 - val_loss: 0.2756 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 52\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 156s 9ms/step - loss: 0.0795 - accuracy: 0.9852 - val_loss: 0.2830 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 53\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 168s 10ms/step - loss: 0.0770 - accuracy: 0.9857 - val_loss: 0.2926 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 54\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 158s 9ms/step - loss: 0.0737 - accuracy: 0.9866 - val_loss: 0.2854 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 55\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 156s 9ms/step - loss: 0.0718 - accuracy: 0.9871 - val_loss: 0.2892 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 56\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 155s 9ms/step - loss: 0.0683 - accuracy: 0.9880 - val_loss: 0.2927 - val_accuracy: 0.9317\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 57\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 156s 9ms/step - loss: 0.0682 - accuracy: 0.9874 - val_loss: 0.2928 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 58\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 156s 9ms/step - loss: 0.0666 - accuracy: 0.9877 - val_loss: 0.2986 - val_accuracy: 0.9314\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 59\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 160s 9ms/step - loss: 0.0639 - accuracy: 0.9882 - val_loss: 0.2994 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 60\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 156s 9ms/step - loss: 0.0635 - accuracy: 0.9881 - val_loss: 0.3406 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 61\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 157s 9ms/step - loss: 0.0621 - accuracy: 0.9884 - val_loss: 0.3042 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 62\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 157s 9ms/step - loss: 0.0596 - accuracy: 0.9891 - val_loss: 0.3015 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 63\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 157s 9ms/step - loss: 0.0584 - accuracy: 0.9893 - val_loss: 0.3043 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 64\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 158s 9ms/step - loss: 0.0570 - accuracy: 0.9894 - val_loss: 0.3026 - val_accuracy: 0.9318\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 65\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 166s 10ms/step - loss: 0.0555 - accuracy: 0.9896 - val_loss: 0.2893 - val_accuracy: 0.9324\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 66\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 159s 9ms/step - loss: 0.0545 - accuracy: 0.9899 - val_loss: 0.3018 - val_accuracy: 0.9325\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 67\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17118/17118 [==============================] - 157s 9ms/step - loss: 0.0538 - accuracy: 0.9901 - val_loss: 0.3037 - val_accuracy: 0.9311\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 68\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 155s 9ms/step - loss: 0.0513 - accuracy: 0.9906 - val_loss: 0.2974 - val_accuracy: 0.9312\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 69\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 155s 9ms/step - loss: 0.0503 - accuracy: 0.9908 - val_loss: 0.2998 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 70\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 157s 9ms/step - loss: 0.0497 - accuracy: 0.9908 - val_loss: 0.3177 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 71\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 168s 10ms/step - loss: 0.0483 - accuracy: 0.9911 - val_loss: 0.3311 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 72\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 159s 9ms/step - loss: 0.0482 - accuracy: 0.9909 - val_loss: 0.3011 - val_accuracy: 0.9312\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 73\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 156s 9ms/step - loss: 0.0453 - accuracy: 0.9918 - val_loss: 0.3177 - val_accuracy: 0.9315\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 74\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 158s 9ms/step - loss: 0.0452 - accuracy: 0.9917 - val_loss: 0.3025 - val_accuracy: 0.9324\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 75\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 155s 9ms/step - loss: 0.0436 - accuracy: 0.9924 - val_loss: 0.3191 - val_accuracy: 0.9315\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 76\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 156s 9ms/step - loss: 0.0428 - accuracy: 0.9925 - val_loss: 0.3184 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 77\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 167s 10ms/step - loss: 0.0431 - accuracy: 0.9920 - val_loss: 0.3147 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 78\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 159s 9ms/step - loss: 0.0414 - accuracy: 0.9927 - val_loss: 0.3171 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "epoch 79\n",
      "\n",
      "Train on 17118 samples, validate on 2465 samples\n",
      "Epoch 1/1\n",
      "17118/17118 [==============================] - 155s 9ms/step - loss: 0.0390 - accuracy: 0.9935 - val_loss: 0.3223 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93489\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25863\n",
      "doing 4th fold\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1000, 25)     0           dropout_25[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1000, 180)    223560      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1000, 180)    720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1000, 180)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1000, 180)    0           dropout_26[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1000, 180)    390960      lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1000, 180)    720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1000, 180)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1000, 180)    0           dropout_27[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1000, 180)    390960      lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1000, 180)    720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1000, 180)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1000, 180)    0           dropout_28[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1000, 181)    0           lambda_20[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 41, 180)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1000, 25)     0           dropout_25[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 1000, 180)    223560      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1000, 180)    720         bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1000, 180)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1000, 180)    0           dropout_26[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 1000, 180)    390960      lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1000, 180)    720         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1000, 180)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1000, 180)    0           dropout_27[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 1000, 180)    390960      lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1000, 180)    720         bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1000, 180)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1000, 180)    0           dropout_28[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1000, 181)    0           lambda_20[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         [(None, 41, 180), (N 81549       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 41, 180)      720         attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 41, 180)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 7380)         0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 7380)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 80)           590480      dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 8, 1)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 10, 8, 1)     4           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 8, 1)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 163s 10ms/step - loss: 0.7163 - accuracy: 0.7198 - val_loss: 0.6615 - val_accuracy: 0.7770\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77703, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66152, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 166s 10ms/step - loss: 0.6248 - accuracy: 0.8248 - val_loss: 0.6188 - val_accuracy: 0.8518\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.77703 to 0.85183, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.66152 to 0.61877, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 160s 9ms/step - loss: 0.5778 - accuracy: 0.8632 - val_loss: 0.5613 - val_accuracy: 0.8726\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.85183 to 0.87259, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.61877 to 0.56129, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.5444 - accuracy: 0.8854 - val_loss: 0.5257 - val_accuracy: 0.8885\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87259 to 0.88847, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56129 to 0.52567, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.5171 - accuracy: 0.8947 - val_loss: 0.5031 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88847 to 0.88888, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52567 to 0.50311, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.4908 - accuracy: 0.9055 - val_loss: 0.4841 - val_accuracy: 0.8983\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88888 to 0.89831, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50311 to 0.48413, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.4671 - accuracy: 0.9125 - val_loss: 0.4768 - val_accuracy: 0.8997\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89831 to 0.89972, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48413 to 0.47681, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 161s 9ms/step - loss: 0.4453 - accuracy: 0.9182 - val_loss: 0.4464 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89972 to 0.91028, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47681 to 0.44643, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.4246 - accuracy: 0.9226 - val_loss: 0.4329 - val_accuracy: 0.9125\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91028 to 0.91245, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44643 to 0.43294, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 155s 9ms/step - loss: 0.4033 - accuracy: 0.9287 - val_loss: 0.4145 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91245 to 0.91503, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43294 to 0.41448, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 156s 9ms/step - loss: 0.3845 - accuracy: 0.9325 - val_loss: 0.3982 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91503 to 0.92181, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41448 to 0.39817, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 156s 9ms/step - loss: 0.3658 - accuracy: 0.9364 - val_loss: 0.3824 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92181 to 0.92245, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39817 to 0.38242, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 156s 9ms/step - loss: 0.3492 - accuracy: 0.9391 - val_loss: 0.3727 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92245\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38242 to 0.37270, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 160s 9ms/step - loss: 0.3326 - accuracy: 0.9427 - val_loss: 0.3673 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92245\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37270 to 0.36727, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 161s 9ms/step - loss: 0.3169 - accuracy: 0.9450 - val_loss: 0.3536 - val_accuracy: 0.9244\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92245 to 0.92443, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.36727 to 0.35356, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.3020 - accuracy: 0.9483 - val_loss: 0.3425 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92443\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35356 to 0.34246, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.2888 - accuracy: 0.9500 - val_loss: 0.3364 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92443 to 0.92503, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34246 to 0.33644, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.2763 - accuracy: 0.9525 - val_loss: 0.3415 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92503\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.33644\n",
      "epoch 18\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 156s 9ms/step - loss: 0.2625 - accuracy: 0.9554 - val_loss: 0.3256 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92503\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33644 to 0.32556, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 165s 10ms/step - loss: 0.2514 - accuracy: 0.9569 - val_loss: 0.3198 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92503 to 0.92664, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32556 to 0.31980, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 155s 9ms/step - loss: 0.2406 - accuracy: 0.9588 - val_loss: 0.3103 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92664\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31980 to 0.31033, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 156s 9ms/step - loss: 0.2312 - accuracy: 0.9601 - val_loss: 0.3050 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92664 to 0.92890, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31033 to 0.30498, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 156s 9ms/step - loss: 0.2202 - accuracy: 0.9621 - val_loss: 0.3038 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92890\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30498 to 0.30384, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 158s 9ms/step - loss: 0.2119 - accuracy: 0.9637 - val_loss: 0.3190 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92890\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30384\n",
      "epoch 24\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 156s 9ms/step - loss: 0.2039 - accuracy: 0.9648 - val_loss: 0.2892 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92890 to 0.93003, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30384 to 0.28923, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 25\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 163s 10ms/step - loss: 0.1944 - accuracy: 0.9668 - val_loss: 0.2913 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93003\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28923\n",
      "epoch 26\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 154s 9ms/step - loss: 0.1872 - accuracy: 0.9675 - val_loss: 0.2893 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93003\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28923\n",
      "epoch 27\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 158s 9ms/step - loss: 0.1800 - accuracy: 0.9692 - val_loss: 0.2913 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93003\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28923\n",
      "epoch 28\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 156s 9ms/step - loss: 0.1734 - accuracy: 0.9699 - val_loss: 0.2860 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93003\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28923 to 0.28602, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.1664 - accuracy: 0.9713 - val_loss: 0.2852 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93003\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28602 to 0.28519, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.1604 - accuracy: 0.9721 - val_loss: 0.2865 - val_accuracy: 0.9251\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93003\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28519\n",
      "epoch 31\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 162s 9ms/step - loss: 0.1552 - accuracy: 0.9727 - val_loss: 0.2818 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93003 to 0.93087, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28519 to 0.28180, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 156s 9ms/step - loss: 0.1510 - accuracy: 0.9731 - val_loss: 0.2929 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28180\n",
      "epoch 33\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.1483 - accuracy: 0.9725 - val_loss: 0.2795 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28180 to 0.27949, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 34\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 160s 9ms/step - loss: 0.1403 - accuracy: 0.9750 - val_loss: 0.2797 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27949\n",
      "epoch 35\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 159s 9ms/step - loss: 0.1341 - accuracy: 0.9766 - val_loss: 0.2825 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27949\n",
      "epoch 36\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 158s 9ms/step - loss: 0.1294 - accuracy: 0.9772 - val_loss: 0.2843 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27949\n",
      "epoch 37\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 164s 10ms/step - loss: 0.1249 - accuracy: 0.9776 - val_loss: 0.2822 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27949\n",
      "epoch 38\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 158s 9ms/step - loss: 0.1239 - accuracy: 0.9770 - val_loss: 0.2779 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27949 to 0.27793, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 39\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 158s 9ms/step - loss: 0.1193 - accuracy: 0.9780 - val_loss: 0.2884 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27793\n",
      "epoch 40\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 158s 9ms/step - loss: 0.1165 - accuracy: 0.9783 - val_loss: 0.2780 - val_accuracy: 0.9290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27793\n",
      "epoch 41\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 155s 9ms/step - loss: 0.1110 - accuracy: 0.9800 - val_loss: 0.2785 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27793\n",
      "epoch 42\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.1068 - accuracy: 0.9805 - val_loss: 0.2688 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27793 to 0.26875, saving model to D:/mulocdeep/lv1_result22/fold4_big_lv1_loss-weights.hdf5\n",
      "epoch 43\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 164s 10ms/step - loss: 0.1058 - accuracy: 0.9798 - val_loss: 0.2902 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 44\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 158s 9ms/step - loss: 0.1009 - accuracy: 0.9813 - val_loss: 0.2728 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 45\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.0972 - accuracy: 0.9822 - val_loss: 0.2848 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 46\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.0929 - accuracy: 0.9832 - val_loss: 0.2854 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 47\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.0906 - accuracy: 0.9837 - val_loss: 0.2911 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 48\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.0886 - accuracy: 0.9837 - val_loss: 0.2998 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 49\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 166s 10ms/step - loss: 0.0848 - accuracy: 0.9847 - val_loss: 0.2855 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 50\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 158s 9ms/step - loss: 0.0840 - accuracy: 0.9843 - val_loss: 0.2923 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 51\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 156s 9ms/step - loss: 0.0806 - accuracy: 0.9853 - val_loss: 0.2812 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 52\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.0786 - accuracy: 0.9858 - val_loss: 0.2896 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 53\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 159s 9ms/step - loss: 0.0763 - accuracy: 0.9860 - val_loss: 0.2874 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 54\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 156s 9ms/step - loss: 0.0747 - accuracy: 0.9863 - val_loss: 0.2914 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 55\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 165s 10ms/step - loss: 0.0726 - accuracy: 0.9866 - val_loss: 0.2922 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 56\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 156s 9ms/step - loss: 0.0715 - accuracy: 0.9862 - val_loss: 0.2871 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 57\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.0710 - accuracy: 0.9863 - val_loss: 0.2847 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 58\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 155s 9ms/step - loss: 0.0675 - accuracy: 0.9872 - val_loss: 0.2976 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 59\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.0636 - accuracy: 0.9886 - val_loss: 0.3053 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 60\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 160s 9ms/step - loss: 0.0633 - accuracy: 0.9883 - val_loss: 0.2948 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 61\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 161s 9ms/step - loss: 0.0620 - accuracy: 0.9886 - val_loss: 0.3108 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 62\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 153s 9ms/step - loss: 0.0614 - accuracy: 0.9886 - val_loss: 0.3296 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 63\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 152s 9ms/step - loss: 0.0587 - accuracy: 0.9890 - val_loss: 0.3244 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 64\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 155s 9ms/step - loss: 0.0571 - accuracy: 0.9894 - val_loss: 0.2996 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 65\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 152s 9ms/step - loss: 0.0562 - accuracy: 0.9896 - val_loss: 0.3076 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 66\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 151s 9ms/step - loss: 0.0551 - accuracy: 0.9897 - val_loss: 0.3079 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 67\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 149s 9ms/step - loss: 0.0528 - accuracy: 0.9904 - val_loss: 0.3238 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 68\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 149s 9ms/step - loss: 0.0534 - accuracy: 0.9898 - val_loss: 0.3136 - val_accuracy: 0.9248\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 69\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 151s 9ms/step - loss: 0.0511 - accuracy: 0.9906 - val_loss: 0.3337 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 70\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 150s 9ms/step - loss: 0.0498 - accuracy: 0.9909 - val_loss: 0.3180 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 71\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 150s 9ms/step - loss: 0.0486 - accuracy: 0.9911 - val_loss: 0.3169 - val_accuracy: 0.9259\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 72\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 151s 9ms/step - loss: 0.0482 - accuracy: 0.9910 - val_loss: 0.3019 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 73\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 157s 9ms/step - loss: 0.0469 - accuracy: 0.9912 - val_loss: 0.3495 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 74\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 154s 9ms/step - loss: 0.0462 - accuracy: 0.9914 - val_loss: 0.3265 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 75\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 154s 9ms/step - loss: 0.0457 - accuracy: 0.9914 - val_loss: 0.3180 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 76\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 156s 9ms/step - loss: 0.0441 - accuracy: 0.9919 - val_loss: 0.3211 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 77\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 154s 9ms/step - loss: 0.0426 - accuracy: 0.9921 - val_loss: 0.3321 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 78\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 154s 9ms/step - loss: 0.0412 - accuracy: 0.9925 - val_loss: 0.3345 - val_accuracy: 0.9254\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "epoch 79\n",
      "\n",
      "Train on 17102 samples, validate on 2481 samples\n",
      "Epoch 1/1\n",
      "17102/17102 [==============================] - 162s 9ms/step - loss: 0.0412 - accuracy: 0.9926 - val_loss: 0.3521 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93087\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26875\n",
      "doing 5th fold\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1000, 25)     0           dropout_31[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1000, 180)    223560      lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1000, 180)    720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 1000, 180)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1000, 180)    0           dropout_32[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 1000, 180)    390960      lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1000, 180)    720         bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 1000, 180)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1000, 180)    0           dropout_33[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 1000, 180)    390960      lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1000, 180)    720         bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 1000, 180)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1000, 180)    0           dropout_34[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1000, 181)    0           lambda_24[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 41, 180)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1000, 25)     0           dropout_31[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 1000, 180)    223560      lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1000, 180)    720         bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 1000, 180)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1000, 180)    0           dropout_32[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 1000, 180)    390960      lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1000, 180)    720         bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 1000, 180)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1000, 180)    0           dropout_33[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 1000, 180)    390960      lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1000, 180)    720         bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 1000, 180)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1000, 180)    0           dropout_34[0][0]                 \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1000, 181)    0           lambda_24[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         [(None, 41, 180), (N 81549       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 41, 180)      720         attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 41, 180)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7380)         0           dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 7380)         0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 80)           590480      dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 8, 1)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 10, 8, 1)     4           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 8, 1)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 168s 10ms/step - loss: 0.7228 - accuracy: 0.7126 - val_loss: 0.6526 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80512, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65257, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 160s 9ms/step - loss: 0.6192 - accuracy: 0.8363 - val_loss: 0.6098 - val_accuracy: 0.8406\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.80512 to 0.84061, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.65257 to 0.60980, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 161s 9ms/step - loss: 0.5760 - accuracy: 0.8658 - val_loss: 0.5603 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84061 to 0.87686, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.60980 to 0.56034, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 172s 10ms/step - loss: 0.5426 - accuracy: 0.8867 - val_loss: 0.5258 - val_accuracy: 0.8925\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87686 to 0.89249, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.56034 to 0.52580, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 168s 10ms/step - loss: 0.5154 - accuracy: 0.8982 - val_loss: 0.5073 - val_accuracy: 0.8959\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89249 to 0.89590, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52580 to 0.50729, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 161s 9ms/step - loss: 0.4907 - accuracy: 0.9060 - val_loss: 0.4876 - val_accuracy: 0.9047\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89590 to 0.90474, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.50729 to 0.48759, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.4672 - accuracy: 0.9137 - val_loss: 0.4649 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90474 to 0.90901, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.48759 to 0.46492, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.4448 - accuracy: 0.9199 - val_loss: 0.4542 - val_accuracy: 0.9043\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.90901\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46492 to 0.45416, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 162s 9ms/step - loss: 0.4245 - accuracy: 0.9247 - val_loss: 0.4305 - val_accuracy: 0.9181\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90901 to 0.91815, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.45416 to 0.43052, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 164s 9ms/step - loss: 0.4042 - accuracy: 0.9290 - val_loss: 0.4178 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91815\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.43052 to 0.41781, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 157s 9ms/step - loss: 0.3858 - accuracy: 0.9327 - val_loss: 0.4022 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91815\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41781 to 0.40223, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 161s 9ms/step - loss: 0.3669 - accuracy: 0.9371 - val_loss: 0.3954 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91815\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40223 to 0.39537, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 165s 10ms/step - loss: 0.3502 - accuracy: 0.9401 - val_loss: 0.3812 - val_accuracy: 0.9195\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91815 to 0.91951, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.39537 to 0.38116, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 161s 9ms/step - loss: 0.3329 - accuracy: 0.9437 - val_loss: 0.3706 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91951\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38116 to 0.37063, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.3175 - accuracy: 0.9465 - val_loss: 0.3578 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91951 to 0.92229, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37063 to 0.35777, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 167s 10ms/step - loss: 0.3024 - accuracy: 0.9496 - val_loss: 0.3566 - val_accuracy: 0.9215\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92229\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35777 to 0.35660, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 159s 9ms/step - loss: 0.2887 - accuracy: 0.9513 - val_loss: 0.3481 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92229\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35660 to 0.34813, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 157s 9ms/step - loss: 0.2753 - accuracy: 0.9540 - val_loss: 0.3317 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92229 to 0.92314, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34813 to 0.33171, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 157s 9ms/step - loss: 0.2645 - accuracy: 0.9557 - val_loss: 0.3286 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92314\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33171 to 0.32863, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 156s 9ms/step - loss: 0.2517 - accuracy: 0.9581 - val_loss: 0.3154 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92314 to 0.92622, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32863 to 0.31540, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 155s 9ms/step - loss: 0.2412 - accuracy: 0.9597 - val_loss: 0.3153 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92622 to 0.92656, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31540 to 0.31529, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 154s 9ms/step - loss: 0.2308 - accuracy: 0.9609 - val_loss: 0.3105 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92656\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31529 to 0.31047, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 156s 9ms/step - loss: 0.2202 - accuracy: 0.9639 - val_loss: 0.3009 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92656 to 0.92775, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31047 to 0.30091, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 168s 10ms/step - loss: 0.2122 - accuracy: 0.9645 - val_loss: 0.3147 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92775\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30091\n",
      "epoch 24\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 157s 9ms/step - loss: 0.2026 - accuracy: 0.9664 - val_loss: 0.3073 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92775\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30091\n",
      "epoch 25\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 157s 9ms/step - loss: 0.1946 - accuracy: 0.9675 - val_loss: 0.2819 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92775\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30091 to 0.28191, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 164s 10ms/step - loss: 0.1867 - accuracy: 0.9688 - val_loss: 0.2858 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92775\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28191\n",
      "epoch 27\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.1792 - accuracy: 0.9699 - val_loss: 0.2848 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92775\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28191\n",
      "epoch 28\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 168s 10ms/step - loss: 0.1718 - accuracy: 0.9711 - val_loss: 0.2956 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92775\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28191\n",
      "epoch 29\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 166s 10ms/step - loss: 0.1659 - accuracy: 0.9723 - val_loss: 0.2854 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92775\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28191\n",
      "epoch 30\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.1601 - accuracy: 0.9726 - val_loss: 0.2852 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92775\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28191\n",
      "epoch 31\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.1526 - accuracy: 0.9745 - val_loss: 0.2836 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92775\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28191\n",
      "epoch 32\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.1476 - accuracy: 0.9751 - val_loss: 0.2959 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92775\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28191\n",
      "epoch 33\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 162s 9ms/step - loss: 0.1419 - accuracy: 0.9761 - val_loss: 0.2738 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92775 to 0.92857, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28191 to 0.27382, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 34\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 166s 10ms/step - loss: 0.1370 - accuracy: 0.9768 - val_loss: 0.2697 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92857 to 0.93002, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27382 to 0.26966, saving model to D:/mulocdeep/lv1_result22/fold5_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 161s 9ms/step - loss: 0.1324 - accuracy: 0.9772 - val_loss: 0.2871 - val_accuracy: 0.9291\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 36\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.1275 - accuracy: 0.9783 - val_loss: 0.2986 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 37\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 164s 10ms/step - loss: 0.1237 - accuracy: 0.9788 - val_loss: 0.2919 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 38\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 165s 10ms/step - loss: 0.1192 - accuracy: 0.9794 - val_loss: 0.2808 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 39\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 164s 10ms/step - loss: 0.1145 - accuracy: 0.9804 - val_loss: 0.2768 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 40\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 172s 10ms/step - loss: 0.1109 - accuracy: 0.9810 - val_loss: 0.3082 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 41\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 168s 10ms/step - loss: 0.1088 - accuracy: 0.9812 - val_loss: 0.2785 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 42\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17241/17241 [==============================] - 162s 9ms/step - loss: 0.1043 - accuracy: 0.9818 - val_loss: 0.2752 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 43\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.1010 - accuracy: 0.9827 - val_loss: 0.2753 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 44\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.0987 - accuracy: 0.9826 - val_loss: 0.2918 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 45\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 164s 10ms/step - loss: 0.0950 - accuracy: 0.9834 - val_loss: 0.2879 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 46\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 171s 10ms/step - loss: 0.0921 - accuracy: 0.9837 - val_loss: 0.2792 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 47\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.0878 - accuracy: 0.9853 - val_loss: 0.2848 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 48\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 166s 10ms/step - loss: 0.0861 - accuracy: 0.9852 - val_loss: 0.2857 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 49\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 165s 10ms/step - loss: 0.0847 - accuracy: 0.9850 - val_loss: 0.3052 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 50\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 165s 10ms/step - loss: 0.0824 - accuracy: 0.9854 - val_loss: 0.2842 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 51\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 168s 10ms/step - loss: 0.0784 - accuracy: 0.9866 - val_loss: 0.2949 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 52\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.0783 - accuracy: 0.9861 - val_loss: 0.2989 - val_accuracy: 0.9248\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 53\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 164s 10ms/step - loss: 0.0760 - accuracy: 0.9864 - val_loss: 0.2868 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 54\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.0721 - accuracy: 0.9876 - val_loss: 0.2940 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 55\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 167s 10ms/step - loss: 0.0708 - accuracy: 0.9877 - val_loss: 0.2842 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 56\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 164s 10ms/step - loss: 0.0687 - accuracy: 0.9879 - val_loss: 0.3200 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 57\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 171s 10ms/step - loss: 0.0674 - accuracy: 0.9880 - val_loss: 0.3042 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 58\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 164s 10ms/step - loss: 0.0655 - accuracy: 0.9883 - val_loss: 0.2957 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 59\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 165s 10ms/step - loss: 0.0643 - accuracy: 0.9884 - val_loss: 0.3226 - val_accuracy: 0.9246\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 60\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 165s 10ms/step - loss: 0.0613 - accuracy: 0.9893 - val_loss: 0.3057 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 61\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 164s 9ms/step - loss: 0.0602 - accuracy: 0.9896 - val_loss: 0.3225 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 62\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 164s 10ms/step - loss: 0.0588 - accuracy: 0.9896 - val_loss: 0.3162 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 63\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 169s 10ms/step - loss: 0.0584 - accuracy: 0.9894 - val_loss: 0.3058 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 64\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.0569 - accuracy: 0.9897 - val_loss: 0.3191 - val_accuracy: 0.9254\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 65\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.0551 - accuracy: 0.9904 - val_loss: 0.3187 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 66\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 164s 9ms/step - loss: 0.0533 - accuracy: 0.9909 - val_loss: 0.3144 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 67\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 165s 10ms/step - loss: 0.0520 - accuracy: 0.9910 - val_loss: 0.3220 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 68\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 168s 10ms/step - loss: 0.0508 - accuracy: 0.9913 - val_loss: 0.3252 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 69\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.0504 - accuracy: 0.9912 - val_loss: 0.3468 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 70\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 165s 10ms/step - loss: 0.0487 - accuracy: 0.9916 - val_loss: 0.3251 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 71\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 165s 10ms/step - loss: 0.0475 - accuracy: 0.9917 - val_loss: 0.3266 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 72\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.0480 - accuracy: 0.9913 - val_loss: 0.3228 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 73\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 163s 9ms/step - loss: 0.0452 - accuracy: 0.9921 - val_loss: 0.3335 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 74\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 164s 10ms/step - loss: 0.0459 - accuracy: 0.9918 - val_loss: 0.3262 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 75\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 159s 9ms/step - loss: 0.0447 - accuracy: 0.9920 - val_loss: 0.3383 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 76\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 158s 9ms/step - loss: 0.0429 - accuracy: 0.9925 - val_loss: 0.3229 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 77\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 160s 9ms/step - loss: 0.0425 - accuracy: 0.9925 - val_loss: 0.3313 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 78\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 160s 9ms/step - loss: 0.0412 - accuracy: 0.9929 - val_loss: 0.3371 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "epoch 79\n",
      "\n",
      "Train on 17241 samples, validate on 2342 samples\n",
      "Epoch 1/1\n",
      "17241/17241 [==============================] - 161s 9ms/step - loss: 0.0403 - accuracy: 0.9929 - val_loss: 0.3425 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26966\n",
      "doing 6th fold\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1000, 25)     0           dropout_37[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 1000, 180)    223560      lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1000, 180)    720         bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1000, 180)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1000, 180)    0           dropout_38[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 1000, 180)    390960      lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1000, 180)    720         bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 1000, 180)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 1000, 180)    0           dropout_39[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 1000, 180)    390960      lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1000, 180)    720         bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 1000, 180)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1000, 180)    0           dropout_40[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 181)    0           lambda_28[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 41, 180)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1000, 25)     0           dropout_37[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 1000, 180)    223560      lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1000, 180)    720         bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 1000, 180)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1000, 180)    0           dropout_38[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 1000, 180)    390960      lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1000, 180)    720         bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 1000, 180)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 1000, 180)    0           dropout_39[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 1000, 180)    390960      lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1000, 180)    720         bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 1000, 180)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1000, 180)    0           dropout_40[0][0]                 \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 181)    0           lambda_28[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_7 (Attention)         [(None, 41, 180), (N 81549       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 41, 180)      720         attention_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 41, 180)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 7380)         0           dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 7380)         0           flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 80)           590480      dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 8, 1)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 10, 8, 1)     4           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 8, 1)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 168s 10ms/step - loss: 0.7183 - accuracy: 0.7258 - val_loss: 0.6868 - val_accuracy: 0.7878\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78779, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68678, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 159s 9ms/step - loss: 0.6263 - accuracy: 0.8287 - val_loss: 0.6046 - val_accuracy: 0.8433\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.78779 to 0.84334, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.68678 to 0.60459, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 158s 9ms/step - loss: 0.5782 - accuracy: 0.8633 - val_loss: 0.5571 - val_accuracy: 0.8719\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.84334 to 0.87195, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.60459 to 0.55713, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 160s 9ms/step - loss: 0.5457 - accuracy: 0.8831 - val_loss: 0.5193 - val_accuracy: 0.8964\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87195 to 0.89637, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55713 to 0.51934, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.5184 - accuracy: 0.8951 - val_loss: 0.4927 - val_accuracy: 0.9026\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89637 to 0.90259, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.51934 to 0.49273, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 155s 9ms/step - loss: 0.4931 - accuracy: 0.9047 - val_loss: 0.4735 - val_accuracy: 0.9100\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90259 to 0.91002, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49273 to 0.47353, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 156s 9ms/step - loss: 0.4693 - accuracy: 0.9120 - val_loss: 0.4638 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.91002\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47353 to 0.46383, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 157s 9ms/step - loss: 0.4473 - accuracy: 0.9180 - val_loss: 0.4460 - val_accuracy: 0.9121\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91002 to 0.91209, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46383 to 0.44604, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 156s 9ms/step - loss: 0.4261 - accuracy: 0.9223 - val_loss: 0.4265 - val_accuracy: 0.9176\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91209 to 0.91760, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44604 to 0.42648, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 157s 9ms/step - loss: 0.4064 - accuracy: 0.9283 - val_loss: 0.4086 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91760 to 0.92526, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42648 to 0.40863, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 167s 10ms/step - loss: 0.3871 - accuracy: 0.9317 - val_loss: 0.4071 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92526\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40863 to 0.40715, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 167s 10ms/step - loss: 0.3690 - accuracy: 0.9357 - val_loss: 0.3816 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92526\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40715 to 0.38157, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 167s 10ms/step - loss: 0.3524 - accuracy: 0.9390 - val_loss: 0.3728 - val_accuracy: 0.9244\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92526\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.38157 to 0.37284, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 13\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 170s 10ms/step - loss: 0.3358 - accuracy: 0.9417 - val_loss: 0.3563 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92526 to 0.92777, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37284 to 0.35633, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 172s 10ms/step - loss: 0.3196 - accuracy: 0.9453 - val_loss: 0.3451 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92777\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.35633 to 0.34505, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 167s 10ms/step - loss: 0.3048 - accuracy: 0.9478 - val_loss: 0.3364 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92777 to 0.92813, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34505 to 0.33639, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 176s 10ms/step - loss: 0.2904 - accuracy: 0.9502 - val_loss: 0.3330 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92813\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33639 to 0.33298, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 164s 10ms/step - loss: 0.2774 - accuracy: 0.9524 - val_loss: 0.3220 - val_accuracy: 0.9303\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92813 to 0.93033, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33298 to 0.32197, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 18\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.2649 - accuracy: 0.9546 - val_loss: 0.3174 - val_accuracy: 0.9296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93033\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32197 to 0.31738, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 163s 10ms/step - loss: 0.2521 - accuracy: 0.9571 - val_loss: 0.3167 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93033\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31738 to 0.31673, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.2409 - accuracy: 0.9593 - val_loss: 0.3046 - val_accuracy: 0.9312\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93033 to 0.93121, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31673 to 0.30456, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 21\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 171s 10ms/step - loss: 0.2313 - accuracy: 0.9603 - val_loss: 0.2985 - val_accuracy: 0.9308\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30456 to 0.29851, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.2225 - accuracy: 0.9613 - val_loss: 0.3041 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.29851\n",
      "epoch 23\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 165s 10ms/step - loss: 0.2127 - accuracy: 0.9629 - val_loss: 0.2924 - val_accuracy: 0.9291\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29851 to 0.29235, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.2032 - accuracy: 0.9645 - val_loss: 0.2924 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.29235\n",
      "epoch 25\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 169s 10ms/step - loss: 0.1941 - accuracy: 0.9668 - val_loss: 0.2939 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.29235\n",
      "epoch 26\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.1884 - accuracy: 0.9668 - val_loss: 0.2819 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29235 to 0.28195, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 27\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 171s 10ms/step - loss: 0.1794 - accuracy: 0.9693 - val_loss: 0.2779 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28195 to 0.27788, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 28\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 164s 10ms/step - loss: 0.1731 - accuracy: 0.9698 - val_loss: 0.2786 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27788\n",
      "epoch 29\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 164s 10ms/step - loss: 0.1667 - accuracy: 0.9709 - val_loss: 0.2745 - val_accuracy: 0.9303\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27788 to 0.27447, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 163s 10ms/step - loss: 0.1597 - accuracy: 0.9720 - val_loss: 0.3005 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27447\n",
      "epoch 31\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 164s 10ms/step - loss: 0.1538 - accuracy: 0.9729 - val_loss: 0.2714 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27447 to 0.27137, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 164s 10ms/step - loss: 0.1478 - accuracy: 0.9742 - val_loss: 0.2866 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27137\n",
      "epoch 33\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 173s 10ms/step - loss: 0.1425 - accuracy: 0.9751 - val_loss: 0.2978 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27137\n",
      "epoch 34\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.1376 - accuracy: 0.9756 - val_loss: 0.2775 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27137\n",
      "epoch 35\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 165s 10ms/step - loss: 0.1330 - accuracy: 0.9766 - val_loss: 0.2748 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27137\n",
      "epoch 36\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.1278 - accuracy: 0.9773 - val_loss: 0.2709 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27137 to 0.27089, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 37\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.1246 - accuracy: 0.9776 - val_loss: 0.2668 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27089 to 0.26683, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_loss-weights.hdf5\n",
      "epoch 38\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 164s 10ms/step - loss: 0.1196 - accuracy: 0.9788 - val_loss: 0.2817 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 39\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 176s 10ms/step - loss: 0.1154 - accuracy: 0.9791 - val_loss: 0.2803 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 40\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.1107 - accuracy: 0.9802 - val_loss: 0.2678 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 41\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 164s 10ms/step - loss: 0.1083 - accuracy: 0.9806 - val_loss: 0.2700 - val_accuracy: 0.9314\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93121 to 0.93140, saving model to D:/mulocdeep/lv1_result22/fold6_big_lv1_acc-weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 42\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 164s 10ms/step - loss: 0.1046 - accuracy: 0.9809 - val_loss: 0.2721 - val_accuracy: 0.9298\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 43\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 165s 10ms/step - loss: 0.1014 - accuracy: 0.9817 - val_loss: 0.2905 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 44\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 164s 10ms/step - loss: 0.0978 - accuracy: 0.9825 - val_loss: 0.2905 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 45\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 176s 10ms/step - loss: 0.0950 - accuracy: 0.9826 - val_loss: 0.2748 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 46\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 165s 10ms/step - loss: 0.0914 - accuracy: 0.9834 - val_loss: 0.2887 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 47\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 165s 10ms/step - loss: 0.0873 - accuracy: 0.9846 - val_loss: 0.2932 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 48\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 165s 10ms/step - loss: 0.0863 - accuracy: 0.9842 - val_loss: 0.2940 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 49\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 164s 10ms/step - loss: 0.0852 - accuracy: 0.9841 - val_loss: 0.2830 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 50\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 171s 10ms/step - loss: 0.0802 - accuracy: 0.9857 - val_loss: 0.2976 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 51\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 164s 10ms/step - loss: 0.0785 - accuracy: 0.9856 - val_loss: 0.2765 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 52\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.0752 - accuracy: 0.9864 - val_loss: 0.2791 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 53\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 165s 10ms/step - loss: 0.0724 - accuracy: 0.9871 - val_loss: 0.3013 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 54\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.0705 - accuracy: 0.9877 - val_loss: 0.3072 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 55\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 165s 10ms/step - loss: 0.0694 - accuracy: 0.9875 - val_loss: 0.2811 - val_accuracy: 0.9298\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 56\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 169s 10ms/step - loss: 0.0671 - accuracy: 0.9882 - val_loss: 0.2965 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 57\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.0663 - accuracy: 0.9878 - val_loss: 0.3023 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 58\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 164s 10ms/step - loss: 0.0628 - accuracy: 0.9888 - val_loss: 0.2834 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 59\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 166s 10ms/step - loss: 0.0620 - accuracy: 0.9888 - val_loss: 0.2950 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 60\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 168s 10ms/step - loss: 0.0607 - accuracy: 0.9891 - val_loss: 0.2989 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 61\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 171s 10ms/step - loss: 0.0588 - accuracy: 0.9896 - val_loss: 0.3174 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 62\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 169s 10ms/step - loss: 0.0573 - accuracy: 0.9898 - val_loss: 0.2905 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 63\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 163s 10ms/step - loss: 0.0564 - accuracy: 0.9897 - val_loss: 0.3183 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 64\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 160s 9ms/step - loss: 0.0538 - accuracy: 0.9903 - val_loss: 0.3071 - val_accuracy: 0.9291\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 65\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 162s 9ms/step - loss: 0.0526 - accuracy: 0.9907 - val_loss: 0.2962 - val_accuracy: 0.9291\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 66\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 162s 9ms/step - loss: 0.0527 - accuracy: 0.9903 - val_loss: 0.3023 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 67\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 171s 10ms/step - loss: 0.0502 - accuracy: 0.9908 - val_loss: 0.3215 - val_accuracy: 0.9242\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 68\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17077/17077 [==============================] - 163s 10ms/step - loss: 0.0490 - accuracy: 0.9912 - val_loss: 0.3114 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 69\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 162s 9ms/step - loss: 0.0477 - accuracy: 0.9916 - val_loss: 0.3134 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 70\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 161s 9ms/step - loss: 0.0477 - accuracy: 0.9913 - val_loss: 0.3144 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 71\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 162s 10ms/step - loss: 0.0452 - accuracy: 0.9920 - val_loss: 0.3264 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 72\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 163s 10ms/step - loss: 0.0445 - accuracy: 0.9921 - val_loss: 0.3187 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 73\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 162s 9ms/step - loss: 0.0438 - accuracy: 0.9921 - val_loss: 0.3231 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 74\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 163s 10ms/step - loss: 0.0430 - accuracy: 0.9924 - val_loss: 0.3322 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 75\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 162s 9ms/step - loss: 0.0427 - accuracy: 0.9924 - val_loss: 0.3457 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 76\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 164s 10ms/step - loss: 0.0414 - accuracy: 0.9928 - val_loss: 0.3289 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 77\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 173s 10ms/step - loss: 0.0400 - accuracy: 0.9931 - val_loss: 0.3267 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 78\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 169s 10ms/step - loss: 0.0386 - accuracy: 0.9935 - val_loss: 0.3418 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "epoch 79\n",
      "\n",
      "Train on 17077 samples, validate on 2506 samples\n",
      "Epoch 1/1\n",
      "17077/17077 [==============================] - 173s 10ms/step - loss: 0.0385 - accuracy: 0.9933 - val_loss: 0.3256 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93140\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26683\n",
      "doing 7th fold\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 1000, 25)     0           dropout_43[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 1000, 180)    223560      lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1000, 180)    720         bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 1000, 180)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1000, 180)    0           dropout_44[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 1000, 180)    390960      lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1000, 180)    720         bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 1000, 180)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 1000, 180)    0           dropout_45[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 1000, 180)    390960      lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1000, 180)    720         bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 1000, 180)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1000, 180)    0           dropout_46[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1000, 181)    0           lambda_32[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 41, 180)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 1000, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 1000, 25)     0           Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 1000, 25)     0           dropout_43[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 1000, 180)    223560      lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1000, 180)    720         bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 1000, 180)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1000, 180)    0           dropout_44[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 1000, 180)    390960      lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1000, 180)    720         bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 1000, 180)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 1000, 180)    0           dropout_45[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 1000, 180)    390960      lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1000, 180)    720         bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 1000, 180)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1000, 180)    0           dropout_46[0][0]                 \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1000, 181)    0           lambda_32[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         [(None, 41, 180), (N 81549       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 41, 180)      720         attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 41, 180)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 7380)         0           dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 7380)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 80)           590480      dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 8, 1)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 10, 8, 1)     4           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 8, 1)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 1, 1)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lev1 (Reshape)                  (None, 10, 8)        0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "1ev2 (Reshape)                  (None, 10)           0           max_pooling2d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,680,393\n",
      "Trainable params: 1,678,951\n",
      "Non-trainable params: 1,442\n",
      "__________________________________________________________________________________________________\n",
      "epoch 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 184s 11ms/step - loss: 0.7228 - accuracy: 0.7020 - val_loss: 0.6390 - val_accuracy: 0.8147\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81466, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63902, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 1\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 183s 11ms/step - loss: 0.6225 - accuracy: 0.8336 - val_loss: 0.6016 - val_accuracy: 0.8181\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81466 to 0.81814, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.63902 to 0.60158, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 2\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 168s 10ms/step - loss: 0.5785 - accuracy: 0.8626 - val_loss: 0.5558 - val_accuracy: 0.8710\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.81814 to 0.87103, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.60158 to 0.55581, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 3\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 170s 10ms/step - loss: 0.5469 - accuracy: 0.8810 - val_loss: 0.5232 - val_accuracy: 0.8863\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.87103 to 0.88632, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.55581 to 0.52323, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 4\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 168s 10ms/step - loss: 0.5189 - accuracy: 0.8940 - val_loss: 0.4962 - val_accuracy: 0.8987\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.88632 to 0.89866, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.52323 to 0.49623, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 5\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 171s 10ms/step - loss: 0.4947 - accuracy: 0.9019 - val_loss: 0.4786 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.89866 to 0.90071, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.49623 to 0.47860, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 6\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 169s 10ms/step - loss: 0.4698 - accuracy: 0.9106 - val_loss: 0.4622 - val_accuracy: 0.9076\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90071 to 0.90763, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.47860 to 0.46223, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 7\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 175s 10ms/step - loss: 0.4480 - accuracy: 0.9153 - val_loss: 0.4424 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.90763 to 0.91700, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.46223 to 0.44242, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 8\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 170s 10ms/step - loss: 0.4267 - accuracy: 0.9214 - val_loss: 0.4251 - val_accuracy: 0.9206\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.91700 to 0.92059, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.44242 to 0.42512, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 9\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 173s 10ms/step - loss: 0.4060 - accuracy: 0.9263 - val_loss: 0.4116 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92059 to 0.92229, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.42512 to 0.41164, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 10\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 178s 10ms/step - loss: 0.3874 - accuracy: 0.9304 - val_loss: 0.4038 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92229\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.41164 to 0.40378, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 11\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 172s 10ms/step - loss: 0.3693 - accuracy: 0.9342 - val_loss: 0.3791 - val_accuracy: 0.9251\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92229 to 0.92510, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.40378 to 0.37912, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 12\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 174s 10ms/step - loss: 0.3511 - accuracy: 0.9381 - val_loss: 0.3819 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.92510\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.37912\n",
      "epoch 13\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 172s 10ms/step - loss: 0.3349 - accuracy: 0.9408 - val_loss: 0.3706 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92510 to 0.92621, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37912 to 0.37059, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 14\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 168s 10ms/step - loss: 0.3196 - accuracy: 0.9436 - val_loss: 0.3469 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92621 to 0.92735, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.37059 to 0.34691, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 15\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 170s 10ms/step - loss: 0.3051 - accuracy: 0.9464 - val_loss: 0.3394 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92735 to 0.92901, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.34691 to 0.33941, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 16\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 170s 10ms/step - loss: 0.2916 - accuracy: 0.9487 - val_loss: 0.3257 - val_accuracy: 0.9314\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.92901 to 0.93142, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33941 to 0.32568, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 17\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 169s 10ms/step - loss: 0.2796 - accuracy: 0.9502 - val_loss: 0.3284 - val_accuracy: 0.9279\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32568\n",
      "epoch 18\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 177s 10ms/step - loss: 0.2672 - accuracy: 0.9525 - val_loss: 0.3170 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32568 to 0.31696, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 19\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 169s 10ms/step - loss: 0.2561 - accuracy: 0.9549 - val_loss: 0.3056 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31696 to 0.30558, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 20\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 168s 10ms/step - loss: 0.2435 - accuracy: 0.9577 - val_loss: 0.3095 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30558\n",
      "epoch 21\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 168s 10ms/step - loss: 0.2337 - accuracy: 0.9587 - val_loss: 0.3010 - val_accuracy: 0.9266\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30558 to 0.30098, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 22\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 167s 10ms/step - loss: 0.2247 - accuracy: 0.9600 - val_loss: 0.2928 - val_accuracy: 0.9311\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30098 to 0.29282, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 23\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 175s 10ms/step - loss: 0.2142 - accuracy: 0.9623 - val_loss: 0.2872 - val_accuracy: 0.9314\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93142 to 0.93142, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.29282 to 0.28718, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 24\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 169s 10ms/step - loss: 0.2064 - accuracy: 0.9631 - val_loss: 0.3110 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28718\n",
      "epoch 25\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 167s 10ms/step - loss: 0.1993 - accuracy: 0.9647 - val_loss: 0.2770 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.28718 to 0.27696, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 26\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 170s 10ms/step - loss: 0.1911 - accuracy: 0.9658 - val_loss: 0.2820 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27696\n",
      "epoch 27\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 170s 10ms/step - loss: 0.1832 - accuracy: 0.9678 - val_loss: 0.2812 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27696\n",
      "epoch 28\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 169s 10ms/step - loss: 0.1763 - accuracy: 0.9683 - val_loss: 0.2766 - val_accuracy: 0.9280\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27696 to 0.27660, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 29\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 167s 10ms/step - loss: 0.1704 - accuracy: 0.9691 - val_loss: 0.2765 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27660 to 0.27653, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 30\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 161s 9ms/step - loss: 0.1626 - accuracy: 0.9711 - val_loss: 0.2771 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27653\n",
      "epoch 31\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 161s 9ms/step - loss: 0.1597 - accuracy: 0.9707 - val_loss: 0.2704 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27653 to 0.27044, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 32\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 162s 9ms/step - loss: 0.1535 - accuracy: 0.9720 - val_loss: 0.2668 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27044 to 0.26680, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 33\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 162s 10ms/step - loss: 0.1474 - accuracy: 0.9733 - val_loss: 0.2747 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26680\n",
      "epoch 34\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 163s 10ms/step - loss: 0.1424 - accuracy: 0.9742 - val_loss: 0.2644 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26680 to 0.26437, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 35\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 166s 10ms/step - loss: 0.1359 - accuracy: 0.9755 - val_loss: 0.2677 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93142\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26437\n",
      "epoch 36\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 162s 9ms/step - loss: 0.1325 - accuracy: 0.9759 - val_loss: 0.2644 - val_accuracy: 0.9323\n",
      "\n",
      "Epoch 00001: val_accuracy improved from 0.93142 to 0.93225, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_acc-weights.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26437 to 0.26437, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 37\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 162s 9ms/step - loss: 0.1270 - accuracy: 0.9770 - val_loss: 0.2609 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26437 to 0.26090, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 38\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 162s 9ms/step - loss: 0.1240 - accuracy: 0.9773 - val_loss: 0.2682 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26090\n",
      "epoch 39\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 157s 9ms/step - loss: 0.1190 - accuracy: 0.9783 - val_loss: 0.2777 - val_accuracy: 0.9296\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26090\n",
      "epoch 40\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17053/17053 [==============================] - 159s 9ms/step - loss: 0.1151 - accuracy: 0.9788 - val_loss: 0.2573 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26090 to 0.25728, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 41\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 154s 9ms/step - loss: 0.1126 - accuracy: 0.9792 - val_loss: 0.2572 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25728 to 0.25724, saving model to D:/mulocdeep/lv1_result22/fold7_big_lv1_loss-weights.hdf5\n",
      "epoch 42\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 154s 9ms/step - loss: 0.1080 - accuracy: 0.9804 - val_loss: 0.2616 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 43\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 148s 9ms/step - loss: 0.1034 - accuracy: 0.9814 - val_loss: 0.2708 - val_accuracy: 0.9303\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 44\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 148s 9ms/step - loss: 0.1031 - accuracy: 0.9808 - val_loss: 0.2677 - val_accuracy: 0.9291\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 45\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 149s 9ms/step - loss: 0.0992 - accuracy: 0.9815 - val_loss: 0.2663 - val_accuracy: 0.9289\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 46\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 147s 9ms/step - loss: 0.0954 - accuracy: 0.9829 - val_loss: 0.2640 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 47\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 160s 9ms/step - loss: 0.0925 - accuracy: 0.9829 - val_loss: 0.2723 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 48\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 151s 9ms/step - loss: 0.0900 - accuracy: 0.9834 - val_loss: 0.2696 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 49\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 150s 9ms/step - loss: 0.0873 - accuracy: 0.9840 - val_loss: 0.2723 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 50\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 150s 9ms/step - loss: 0.0845 - accuracy: 0.9844 - val_loss: 0.2766 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 51\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 148s 9ms/step - loss: 0.0833 - accuracy: 0.9842 - val_loss: 0.2857 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 52\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 149s 9ms/step - loss: 0.0795 - accuracy: 0.9855 - val_loss: 0.2835 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 53\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 160s 9ms/step - loss: 0.0783 - accuracy: 0.9854 - val_loss: 0.2846 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 54\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 149s 9ms/step - loss: 0.0765 - accuracy: 0.9857 - val_loss: 0.2857 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 55\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 148s 9ms/step - loss: 0.0746 - accuracy: 0.9861 - val_loss: 0.2768 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 56\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 148s 9ms/step - loss: 0.0729 - accuracy: 0.9861 - val_loss: 0.2826 - val_accuracy: 0.9303\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 57\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 150s 9ms/step - loss: 0.0700 - accuracy: 0.9871 - val_loss: 0.2812 - val_accuracy: 0.9311\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 58\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 148s 9ms/step - loss: 0.0688 - accuracy: 0.9872 - val_loss: 0.2814 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 59\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 159s 9ms/step - loss: 0.0667 - accuracy: 0.9875 - val_loss: 0.2892 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 60\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 148s 9ms/step - loss: 0.0651 - accuracy: 0.9879 - val_loss: 0.2796 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 61\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 150s 9ms/step - loss: 0.0631 - accuracy: 0.9883 - val_loss: 0.2815 - val_accuracy: 0.9322\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 62\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 150s 9ms/step - loss: 0.0618 - accuracy: 0.9885 - val_loss: 0.2908 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 63\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 149s 9ms/step - loss: 0.0606 - accuracy: 0.9886 - val_loss: 0.2886 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 64\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 149s 9ms/step - loss: 0.0589 - accuracy: 0.9890 - val_loss: 0.2844 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 65\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 150s 9ms/step - loss: 0.0577 - accuracy: 0.9893 - val_loss: 0.2954 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 66\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17053/17053 [==============================] - 151s 9ms/step - loss: 0.0559 - accuracy: 0.9898 - val_loss: 0.2856 - val_accuracy: 0.9311\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 67\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 149s 9ms/step - loss: 0.0537 - accuracy: 0.9902 - val_loss: 0.2786 - val_accuracy: 0.9308\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 68\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 149s 9ms/step - loss: 0.0532 - accuracy: 0.9902 - val_loss: 0.2876 - val_accuracy: 0.9308\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 69\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 162s 9ms/step - loss: 0.0523 - accuracy: 0.9903 - val_loss: 0.3129 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 70\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 151s 9ms/step - loss: 0.0521 - accuracy: 0.9901 - val_loss: 0.2988 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 71\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 148s 9ms/step - loss: 0.0505 - accuracy: 0.9904 - val_loss: 0.2949 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 72\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 148s 9ms/step - loss: 0.0484 - accuracy: 0.9912 - val_loss: 0.3098 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 73\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 150s 9ms/step - loss: 0.0479 - accuracy: 0.9911 - val_loss: 0.3101 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 74\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 150s 9ms/step - loss: 0.0458 - accuracy: 0.9916 - val_loss: 0.2998 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 75\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 158s 9ms/step - loss: 0.0458 - accuracy: 0.9911 - val_loss: 0.3058 - val_accuracy: 0.9298\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 76\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 152s 9ms/step - loss: 0.0452 - accuracy: 0.9917 - val_loss: 0.3147 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 77\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 150s 9ms/step - loss: 0.0444 - accuracy: 0.9917 - val_loss: 0.3142 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 78\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 150s 9ms/step - loss: 0.0427 - accuracy: 0.9920 - val_loss: 0.3294 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n",
      "epoch 79\n",
      "\n",
      "Train on 17053 samples, validate on 2530 samples\n",
      "Epoch 1/1\n",
      "17053/17053 [==============================] - 149s 9ms/step - loss: 0.0430 - accuracy: 0.9919 - val_loss: 0.3057 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.93225\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25724\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-accused",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
